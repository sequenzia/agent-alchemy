{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Agent Alchemy","text":"<p>A plugin suite and developer toolkit that extends Claude Code into a structured development platform \u2014 from specs to tasks to autonomous execution.</p>"},{"location":"#what-is-agent-alchemy","title":"What is Agent Alchemy?","text":"<p>Agent Alchemy is an open-source toolkit for AI and software engineers who use Claude Code. It adds structured development workflows through markdown-as-code plugins, a real-time task dashboard, and a VS Code extension \u2014 all designed to work together as an integrated pipeline.</p> <pre><code>graph LR\n    Spec[\"/create-spec\"] --&gt; Analyze[\"/analyze-spec\"]\n    Analyze --&gt; Tasks[\"/create-tasks\"]\n    Tasks --&gt; Execute[\"/execute-tasks\"]\n    Execute --&gt; Dashboard[\"Task Manager\"]\n\n    style Spec fill:#7c4dff,color:#fff\n    style Analyze fill:#7c4dff,color:#fff\n    style Tasks fill:#7c4dff,color:#fff\n    style Execute fill:#7c4dff,color:#fff\n    style Dashboard fill:#00bcd4,color:#fff</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Spec-Driven Development \u2014 Transform ideas into structured specifications through adaptive interviews, then decompose specs into dependency-ordered tasks that execute autonomously (SDD Tools)</li> <li>Test-Driven Development \u2014 RED-GREEN-REFACTOR workflows with framework auto-detection for pytest, Jest, and Vitest (TDD Tools)</li> <li>Deep Codebase Analysis \u2014 Multi-agent hub-and-spoke exploration with intelligent caching (Core Tools)</li> <li>Feature Development \u2014 Structured implementation with architect and reviewer agent teams (Dev Tools)</li> <li>Hypothesis-Driven Debugging \u2014 Systematic bug investigation with triage-based routing, parallel agent exploration, and automatic learning capture (Dev Tools)</li> <li>Real-Time Task Dashboard \u2014 Kanban board that visualizes task execution as it happens (Task Manager)</li> <li>Plugin Authoring \u2014 Schema validation and autocomplete for building your own plugins (VS Code Extension)</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Install Claude Code plugins\nclaude plugins install agent-alchemy/agent-alchemy-sdd-tools\nclaude plugins install agent-alchemy/agent-alchemy-core-tools\nclaude plugins install agent-alchemy/agent-alchemy-dev-tools\nclaude plugins install agent-alchemy/agent-alchemy-tdd-tools\nclaude plugins install agent-alchemy/agent-alchemy-git-tools\n</code></pre> <p>Then try:</p> <pre><code>/create-spec           # Start a spec interview\n/deep-analysis         # Explore a codebase\n/feature-dev           # Implement a feature\n/bug-killer            # Debug with hypothesis-driven investigation\n/generate-tests        # Generate tests from code\n</code></pre> <p>For a full walkthrough, see the Getting Started guide.</p>"},{"location":"#documentation","title":"Documentation","text":"Section Description Getting Started Installation, prerequisites, and first steps Architecture System design, plugin composition, and data flow Plugins All 6 plugin groups with skills, agents, and usage guides Task Manager Real-time Kanban dashboard setup and API reference VS Code Extension Schema validation and autocomplete for plugin authoring Configuration Settings reference for all plugin behaviors Contributing Development setup, conventions, and how to help"},{"location":"#project-status","title":"Project Status","text":"<p>Agent Alchemy is in active development. Current plugin versions:</p> Plugin Version Status Core Tools 0.2.0 Stable Dev Tools 0.3.0 Stable SDD Tools 0.2.0 Stable TDD Tools 0.2.0 Stable Git Tools 0.1.0 Stable Plugin Tools 0.1.1 Stable"},{"location":"#license","title":"License","text":"<p>MIT \u2014 see LICENSE for details.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>Agent Alchemy extends Claude Code into a structured development platform through three integrated pillars: a markdown-as-code plugin system, a real-time task dashboard, and a VS Code authoring extension. This page explains how these components are designed, how they interact, and the key patterns that hold the system together.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>At a high level, Agent Alchemy is a monorepo organized around three independent but complementary subsystems. The plugin system defines development workflows as markdown files that Claude Code executes directly. The task manager provides visibility into those workflows through a real-time Kanban board. The VS Code extension supports plugin authoring with schema validation and autocompletion.</p> <pre><code>graph TB\n    subgraph Plugins[\"Plugin System (claude/)\"]\n        direction TB\n        CT[core-tools]\n        DT[dev-tools]\n        ST[sdd-tools]\n        TT[tdd-tools]\n        GT[git-tools]\n    end\n\n    subgraph Apps[\"Task Dashboard (apps/)\"]\n        TM[Task Manager&lt;br/&gt;Next.js 16]\n    end\n\n    subgraph Extensions[\"Authoring (extensions/)\"]\n        VS[VS Code Extension&lt;br/&gt;Schema Validation]\n    end\n\n    CC[Claude Code CLI] --&gt;|loads &amp; executes| Plugins\n    CC --&gt;|reads &amp; writes| FS[\"~/.claude/tasks/*.json\"]\n    FS --&gt;|file watcher| TM\n    VS --&gt;|validates| Plugins\n\n    style Plugins fill:#7c3aed,color:#fff\n    style Apps fill:#06b6d4,color:#fff\n    style Extensions fill:#059669,color:#fff\n    style CC fill:#1e293b,color:#fff</code></pre>"},{"location":"architecture/#repository-structure","title":"Repository Structure","text":"<pre><code>agent-alchemy/\n\u251c\u2500\u2500 claude/                        # Plugin system (markdown-as-code)\n\u2502   \u251c\u2500\u2500 .claude-plugin/            # Plugin marketplace registry\n\u2502   \u251c\u2500\u2500 core-tools/                # Codebase analysis, deep exploration\n\u2502   \u2502   \u251c\u2500\u2500 skills/                # deep-analysis, codebase-analysis, ...\n\u2502   \u2502   \u251c\u2500\u2500 agents/                # code-explorer, code-synthesizer, code-architect\n\u2502   \u2502   \u2514\u2500\u2500 hooks/                 # Lifecycle hooks (auto-approve)\n\u2502   \u251c\u2500\u2500 dev-tools/                 # Feature dev, code review, docs\n\u2502   \u2502   \u251c\u2500\u2500 skills/                # feature-dev, docs-manager, ...\n\u2502   \u2502   \u2514\u2500\u2500 agents/                # code-reviewer, changelog-manager, ...\n\u2502   \u251c\u2500\u2500 sdd-tools/                 # Spec-Driven Development pipeline\n\u2502   \u2502   \u251c\u2500\u2500 skills/                # create-spec, create-tasks, execute-tasks, ...\n\u2502   \u2502   \u2514\u2500\u2500 agents/                # researcher, spec-analyzer, task-executor\n\u2502   \u251c\u2500\u2500 tdd-tools/                 # Test-Driven Development workflows\n\u2502   \u2502   \u251c\u2500\u2500 skills/                # tdd-cycle, generate-tests, analyze-coverage\n\u2502   \u2502   \u2514\u2500\u2500 agents/                # tdd-executor, test-writer, test-reviewer\n\u2502   \u251c\u2500\u2500 git-tools/                 # Git commit automation\n\u2502   \u2502   \u2514\u2500\u2500 skills/                # git-commit\n\u2502   \u2514\u2500\u2500 plugin-tools/              # Plugin porting and ecosystem health\n\u2502       \u251c\u2500\u2500 skills/                # port-plugin, validate-adapter, ...\n\u2502       \u2514\u2500\u2500 agents/                # researcher, port-converter\n\u251c\u2500\u2500 apps/\n\u2502   \u2514\u2500\u2500 task-manager/              # Next.js 16 real-time Kanban dashboard\n\u251c\u2500\u2500 extensions/\n\u2502   \u2514\u2500\u2500 vscode/                    # VS Code extension for plugin authoring\n\u2514\u2500\u2500 internal/                      # Internal documentation and analysis\n</code></pre>"},{"location":"architecture/#markdown-as-code","title":"Markdown-as-Code","text":"<p>Agent Alchemy's core innovation is encoding AI agent instructions, workflows, and team coordination logic in plain markdown files. Instead of writing code to orchestrate agents, you write structured markdown that Claude Code interprets and executes directly.</p>"},{"location":"architecture/#why-markdown","title":"Why Markdown?","text":"<p>Traditional agent frameworks require you to write orchestration code in Python, TypeScript, or another programming language. Agent Alchemy takes a different approach: the markdown is the program. This means:</p> <ul> <li>No runtime dependencies \u2014 plugins are just files, no build step required</li> <li>Human-readable workflows \u2014 anyone can read a SKILL.md and understand what it does</li> <li>Version-controlled prompts \u2014 skills live alongside code and evolve with <code>git</code></li> <li>Composable by design \u2014 skills load other skills through file reads, like imports</li> </ul>"},{"location":"architecture/#skills-and-agents","title":"Skills and Agents","text":"<p>The plugin system is built on two primitives: skills and agents.</p> Skill (SKILL.md)Agent ({name}.md) <p>A skill is a workflow definition. The YAML frontmatter declares metadata, tool permissions, and invocation rules. The markdown body contains the step-by-step instructions Claude Code follows.</p> claude/git-tools/skills/git-commit/SKILL.md<pre><code>---\nname: git-commit\ndescription: Commit staged changes with conventional commit message.\nmodel: haiku\nuser-invocable: true\ndisable-model-invocation: false\nallowed-tools: Bash, AskUserQuestion\n---\n\n# Git Commit\n\nCreate a commit with a conventional commit message...\n\n## Workflow\n### Step 1: Check Repository State\n...\n</code></pre> <p>An agent is a specialized worker that a skill can spawn. The frontmatter declares the model tier, available tools, and skills the agent loads into its context.</p> claude/core-tools/agents/code-explorer.md<pre><code>---\nname: code-explorer\ndescription: Explores codebases to find relevant files and map architecture\nmodel: sonnet\ntools:\n  - Read\n  - Glob\n  - Grep\n  - Bash\n  - SendMessage\n  - TaskUpdate\n  - TaskGet\n  - TaskList\nskills:\n  - project-conventions\n  - language-patterns\n---\n\n# Code Explorer Agent\n\nYou are a code exploration specialist working as part of a\ncollaborative analysis team...\n</code></pre>"},{"location":"architecture/#progressive-knowledge-loading","title":"Progressive Knowledge Loading","text":"<p>Large knowledge bases are externalized into <code>references/</code> subdirectories within each skill. Rather than loading everything upfront, skills load reference material on demand as specific phases require it. The project contains 30+ reference files across skills, keeping individual skill files focused while making detailed guidance available when needed.</p> <pre><code>claude/sdd-tools/skills/create-spec/\n\u251c\u2500\u2500 SKILL.md                              # Main workflow (664 lines)\n\u2514\u2500\u2500 references/\n    \u251c\u2500\u2500 interview-questions.md            # Loaded during interview phase\n    \u251c\u2500\u2500 recommendation-triggers.md        # Loaded when generating recommendations\n    \u2514\u2500\u2500 recommendation-format.md          # Loaded when formatting output\n</code></pre> <p>Plugin Inventory</p> <p>The platform ships with 6 plugin groups, 28 skills, 16 agents, and 30+ reference files. See the Plugins documentation for the full catalog.</p>"},{"location":"architecture/#plugin-composition-patterns","title":"Plugin Composition Patterns","text":"<p>Skills do not compose through function calls or import statements. Instead, a skill loads another skill's markdown file at runtime, injecting its full instructions into the current context. This is composition through prompt injection.</p>"},{"location":"architecture/#skill-loading-via-prompt-injection","title":"Skill Loading via Prompt Injection","text":"<p>When <code>feature-dev</code> needs codebase exploration, it reads the <code>deep-analysis</code> SKILL.md and follows its workflow as if it were part of its own instructions:</p> claude/dev-tools/skills/feature-dev/SKILL.md (Phase 2)<pre><code>## Phase 2: Codebase Exploration\n\n1. **Run deep-analysis workflow:**\n   - Read `${CLAUDE_PLUGIN_ROOT}/../core-tools/skills/deep-analysis/SKILL.md`\n     and follow its workflow\n   - Pass the feature description from Phase 1 as the analysis context\n</code></pre> <p>The <code>${CLAUDE_PLUGIN_ROOT}</code> variable resolves to the current plugin's root directory at runtime. Cross-plugin references use the <code>/../{source-dir-name}/</code> pattern to navigate between plugin groups.</p> <p>Cross-Plugin Reference Convention</p> <p>Always use <code>${CLAUDE_PLUGIN_ROOT}/../{source-dir-name}/</code> for cross-plugin references (e.g., <code>/../core-tools/</code>). Same-plugin references use <code>${CLAUDE_PLUGIN_ROOT}/</code> directly. Never use full marketplace names in path references.</p>"},{"location":"architecture/#hub-and-spoke-team-coordination","title":"Hub-and-Spoke Team Coordination","text":"<p>The <code>deep-analysis</code> skill implements a hub-and-spoke pattern for parallel codebase exploration. A lead agent (the skill executor) performs reconnaissance, composes a team plan, spawns N explorer agents and 1 synthesizer agent, then coordinates their work:</p> <pre><code>graph TD\n    Lead[\"Lead Agent&lt;br/&gt;(Skill Executor)\"]\n\n    Lead --&gt;|\"spawns &amp; assigns\"| E1[\"Explorer 1&lt;br/&gt;(Sonnet)\"]\n    Lead --&gt;|\"spawns &amp; assigns\"| E2[\"Explorer 2&lt;br/&gt;(Sonnet)\"]\n    Lead --&gt;|\"spawns &amp; assigns\"| E3[\"Explorer 3&lt;br/&gt;(Sonnet)\"]\n    Lead --&gt;|\"spawns &amp; assigns\"| Syn[\"Synthesizer&lt;br/&gt;(Opus)\"]\n\n    E1 --&gt;|\"findings\"| Syn\n    E2 --&gt;|\"findings\"| Syn\n    E3 --&gt;|\"findings\"| Syn\n    Syn -.-&gt;|\"follow-up questions\"| E1\n    Syn -.-&gt;|\"follow-up questions\"| E2\n    Syn -.-&gt;|\"follow-up questions\"| E3\n    Syn --&gt;|\"unified analysis\"| Lead\n\n    style Lead fill:#7c3aed,color:#fff\n    style E1 fill:#06b6d4,color:#fff\n    style E2 fill:#06b6d4,color:#fff\n    style E3 fill:#06b6d4,color:#fff\n    style Syn fill:#f59e0b,color:#000</code></pre> <p>Key characteristics:</p> <ul> <li>Explorers work independently \u2014 no cross-worker messaging (hub-and-spoke topology)</li> <li>Synthesizer can ask follow-ups \u2014 resolves conflicts and fills gaps by messaging specific explorers</li> <li>Synthesizer has Bash access \u2014 can investigate git history, dependency trees, and run static analysis when file reads are insufficient</li> <li>Task dependencies enforce order \u2014 the synthesis task is blocked by all exploration tasks</li> </ul>"},{"location":"architecture/#phase-workflows-with-completeness-enforcement","title":"Phase Workflows with Completeness Enforcement","text":"<p>Complex skills use numbered phases with explicit enforcement directives to prevent Claude from stopping prematurely. This is a critical pattern because language models tend to treat intermediate outputs as final results.</p> Phase enforcement pattern<pre><code>**CRITICAL: Complete ALL 7 phases.** The workflow is not complete until\nPhase 7: Summary is finished. After completing each phase, immediately\nproceed to the next phase without waiting for user prompts.\n</code></pre> <p>Skills using this pattern:</p> Skill Phases Purpose <code>feature-dev</code> 7 Discovery through Exploration, Design, Implementation, Review, and Summary <code>deep-analysis</code> 6 Session Setup through Recon, Approval, Assembly, Exploration, and Synthesis <code>tdd-cycle</code> 7 Discovery through Analysis, Plan, RED, GREEN, REFACTOR, and Report <code>bug-killer</code> 5 Triage through Investigation, Root Cause, Fix &amp; Verify, and Wrap-up"},{"location":"architecture/#agent-tool-restrictions","title":"Agent Tool Restrictions","text":"<p>Agents enforce separation of concerns through their tool permissions. Architect and reviewer agents are read-only \u2014 they can analyze code but cannot modify it. This ensures design and review phases cannot accidentally alter the codebase:</p> Agent Model Tools Access Level <code>code-explorer</code> Sonnet Read, Glob, Grep, Bash, SendMessage Read-only <code>code-synthesizer</code> Opus Read, Glob, Grep, Bash, SendMessage Read-only <code>code-architect</code> (core-tools) Opus Read, Glob, Grep, SendMessage Read-only <code>code-reviewer</code> (dev-tools) Opus Read, Glob, Grep, SendMessage Read-only <code>bug-investigator</code> (dev-tools) Sonnet Read, Glob, Grep, Bash, SendMessage Read-only <code>task-executor</code> \u2014 Read, Write, Edit, Glob, Grep, Bash Full access <code>tdd-executor</code> Opus Read, Write, Edit, Glob, Grep, Bash Full access"},{"location":"architecture/#askuserquestion-enforcement","title":"AskUserQuestion Enforcement","text":"<p>All interactive skills route user interaction through the <code>AskUserQuestion</code> tool rather than plain text output. This ensures structured, parseable responses and prevents skills from continuing without explicit user input when a decision point is reached.</p>"},{"location":"architecture/#model-tiering-strategy","title":"Model Tiering Strategy","text":"<p>Agent Alchemy assigns Claude models to agents based on the cognitive demands of their task. This balances quality against cost and latency.</p> <pre><code>graph LR\n    subgraph Opus[\"Opus \u2014 High Reasoning\"]\n        S1[Synthesis]\n        S2[Architecture Design]\n        S3[Code Review]\n        S4[TDD Execution]\n    end\n\n    subgraph Sonnet[\"Sonnet \u2014 Parallel Workers\"]\n        W1[Code Exploration]\n        W2[Test Writing]\n        W3[Research]\n    end\n\n    subgraph Haiku[\"Haiku \u2014 Simple Tasks\"]\n        H1[Git Commits]\n    end\n\n    style Opus fill:#f59e0b,color:#000\n    style Sonnet fill:#06b6d4,color:#fff\n    style Haiku fill:#10b981,color:#fff</code></pre> Tier Model Used For Rationale Opus Most capable Synthesis, architecture, review, TDD execution Tasks requiring deep reasoning, cross-cutting analysis, and judgment calls Sonnet Balanced Exploration, test writing, research Parallelizable tasks that benefit from broad search rather than deep reasoning Haiku Fastest Git commits Simple, well-defined tasks where speed matters more than reasoning depth <p>Cost Optimization</p> <p>The hub-and-spoke pattern in <code>deep-analysis</code> uses Sonnet for N parallel explorers (the expensive, parallelized part) and reserves a single Opus instance for the synthesizer. This keeps costs proportional to codebase complexity while maintaining synthesis quality.</p>"},{"location":"architecture/#cross-plugin-dependency-graph","title":"Cross-Plugin Dependency Graph","text":"<p>The <code>deep-analysis</code> skill in <code>core-tools</code> is the keystone skill of the entire platform. Four skills across three plugin groups depend on it for codebase understanding:</p> <pre><code>graph TD\n    subgraph core-tools\n        DA[deep-analysis]\n        CA[codebase-analysis]\n    end\n\n    subgraph dev-tools\n        FD[feature-dev]\n        DM[docs-manager]\n    end\n\n    subgraph sdd-tools\n        CS[create-spec]\n    end\n\n    CA --&gt;|wraps with reporting| DA\n    FD --&gt;|Phase 2: exploration| DA\n    DM --&gt;|codebase understanding| DA\n    CS -.-&gt;|optional: new feature specs| DA\n\n    FD --&gt;|Phase 4| AR[code-architect x2-3&lt;br/&gt;&lt;i&gt;core-tools&lt;/i&gt;]\n    FD --&gt;|Phase 6| CR[code-reviewer x3]\n    DA --&gt;|spawns| EX[code-explorer x N]\n    DA --&gt;|spawns| SY[code-synthesizer x 1]\n\n    style DA fill:#7c3aed,color:#fff\n    style CA fill:#7c3aed,color:#fff\n    style FD fill:#06b6d4,color:#fff\n    style DM fill:#06b6d4,color:#fff\n    style CS fill:#059669,color:#fff</code></pre>"},{"location":"architecture/#key-composition-chains","title":"Key Composition Chains","text":"<p>The full end-to-end workflows chain multiple skills and agents together:</p> <pre><code>feature-dev\n  \u2514\u2500 deep-analysis (Phase 2)\n       \u251c\u2500 code-explorer (Sonnet) x N  \u2014 parallel exploration\n       \u2514\u2500 code-synthesizer (Opus) x 1 \u2014 merge + investigate\n  \u2514\u2500 code-architect (core-tools, Opus) x 2-3 \u2014 competing designs (Phase 4)\n  \u2514\u2500 code-reviewer (Opus) x 3        \u2014 parallel review focuses (Phase 6)\n\ncreate-spec\n  \u2514\u2500 deep-analysis (optional)        \u2014 codebase context for new features\n  \u2514\u2500 researcher agent                \u2014 technical research\n\ncreate-tasks \u2192 reads spec \u2192 generates task JSON\nexecute-tasks \u2192 task-executor agent x N per wave\n\ntdd-cycle \u2192 tdd-executor (Opus) x 1 per feature\n  \u2514\u2500 7-phase RED-GREEN-REFACTOR lifecycle\n\nbug-killer (quick track)\n  \u2514\u2500 read error location, targeted investigation\n  \u2514\u2500 fix + regression test \u2192 project-learnings\n\nbug-killer (deep track)\n  \u2514\u2500 code-explorer (core-tools, Sonnet) x 2-3\n  \u2514\u2500 bug-investigator (Sonnet) x 1-3\n  \u2514\u2500 code-quality for fix validation\n  \u2514\u2500 project-learnings\n</code></pre>"},{"location":"architecture/#real-time-data-flow-task-manager","title":"Real-Time Data Flow (Task Manager)","text":"<p>The task manager provides a real-time Kanban board that visualizes task files written by Claude Code during workflow execution. It uses a file-system-first architecture \u2014 no database, no message queue. The file system is the data store.</p> <pre><code>sequenceDiagram\n    participant CC as Claude Code\n    participant FS as File System&lt;br/&gt;(~/.claude/tasks/)\n    participant CK as Chokidar&lt;br/&gt;(File Watcher)\n    participant SSE as SSE Endpoint&lt;br/&gt;(Route Handler)\n    participant TQ as TanStack Query&lt;br/&gt;(Client Cache)\n    participant UI as React UI&lt;br/&gt;(Kanban Board)\n\n    CC-&gt;&gt;FS: Write/update task JSON\n    CK-&gt;&gt;FS: Detect change (300ms polling)\n    CK-&gt;&gt;SSE: Emit taskEvent\n    SSE-&gt;&gt;TQ: Push SSE event\n    TQ-&gt;&gt;TQ: Invalidate query cache\n    TQ-&gt;&gt;UI: Trigger re-render\n    UI-&gt;&gt;UI: Update board columns</code></pre>"},{"location":"architecture/#pipeline-components","title":"Pipeline Components","text":"<p>File Watcher (Server-Side)</p> <p>The <code>FileWatcher</code> class uses Chokidar to monitor <code>~/.claude/tasks/</code> with 300ms polling. It emits typed events (<code>task:created</code>, <code>task:updated</code>, <code>task:deleted</code>) when JSON files change:</p> apps/task-manager/src/lib/fileWatcher.ts<pre><code>// Global singleton pattern for development hot reload\n// Prevents multiple file watchers during Next.js HMR\nconst globalForWatcher = globalThis as unknown as {\n  fileWatcher: FileWatcher | undefined\n}\n\nexport const fileWatcher = globalForWatcher.fileWatcher ?? new FileWatcher()\n\nif (process.env.NODE_ENV !== 'production') {\n  globalForWatcher.fileWatcher = fileWatcher\n}\n</code></pre> <p>GlobalThis Singleton</p> <p>The <code>globalThis</code> pattern is essential for Next.js development. Without it, every hot module replacement cycle would create a new <code>FileWatcher</code>, leaking file handles and producing duplicate events.</p> <p>SSE Bridge (Server to Client)</p> <p>A Next.js Route Handler at <code>/api/events</code> converts <code>FileWatcher</code> events into Server-Sent Events. Each connected client receives a persistent stream scoped to a specific task list.</p> <p>Cache Invalidation (Client-Side)</p> <p>The <code>useSSE</code> hook listens for SSE events and invalidates the relevant TanStack Query cache entries, triggering React to re-fetch and re-render:</p> apps/task-manager/src/hooks/useSSE.ts<pre><code>const handleTaskEvent = () =&gt; {\n  queryClient.invalidateQueries({ queryKey: taskKeys.list(taskListId) })\n  queryClient.invalidateQueries({ queryKey: taskListKeys.all })\n  router.refresh()\n}\n\neventSource.addEventListener('task:created', handleTaskEvent)\neventSource.addEventListener('task:updated', handleTaskEvent)\neventSource.addEventListener('task:deleted', handleTaskEvent)\n</code></pre>"},{"location":"architecture/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<p>Plugins can register lifecycle hooks that run before or after Claude Code tool invocations. Hooks are defined in <code>hooks/hooks.json</code> within a plugin group and execute shell commands with a timeout.</p> claude/core-tools/hooks/hooks.json<pre><code>{\n  \"hooks\": {\n    \"PreToolUse\": [\n      {\n        \"matcher\": \"Write|Edit|Bash\",\n        \"hooks\": [\n          {\n            \"type\": \"command\",\n            \"command\": \"bash ${CLAUDE_PLUGIN_ROOT}/hooks/auto-approve-da-session.sh\",\n            \"timeout\": 5\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre> <p>In this example, the <code>core-tools</code> plugin auto-approves file operations targeting deep-analysis session directories (<code>~/.claude/sessions/</code>), so checkpointing and cache writes do not require manual user confirmation.</p>"},{"location":"architecture/#technology-stack","title":"Technology Stack","text":""},{"location":"architecture/#plugin-system","title":"Plugin System","text":"Component Technology Purpose Skill definitions YAML frontmatter + Markdown Workflow instructions and metadata Agent definitions YAML frontmatter + Markdown Worker specialization and tool permissions Reference files Markdown Progressive knowledge loading Lifecycle hooks JSON config + shell scripts Pre/post tool-use automation Runtime Claude Code CLI Skill execution, agent spawning, team coordination"},{"location":"architecture/#task-manager","title":"Task Manager","text":"Component Technology Purpose Framework Next.js 16 App Router, Server Components, Route Handlers UI Library React 19 Component rendering State TanStack Query 5 Server state caching and invalidation Styling Tailwind CSS 4 Utility-first CSS Components shadcn/ui (Radix) Accessible UI primitives File watching Chokidar 5 File system change detection Theming next-themes SSR-safe dark/light mode"},{"location":"architecture/#vs-code-extension","title":"VS Code Extension","text":"Component Technology Purpose Validation engine Ajv JSON Schema validation for YAML frontmatter Schema format JSON Schema 7 schemas for plugin file types Build tool esbuild Fast extension bundling Activation <code>workspaceContains</code> Auto-activates in plugin workspaces <p>Validated File Types</p> <p>The VS Code extension validates seven file types: skill frontmatter, agent frontmatter, <code>plugin.json</code>, <code>hooks.json</code>, <code>.mcp.json</code>, <code>.lsp.json</code>, and <code>marketplace.json</code>. See VS Code Extension for details.</p>"},{"location":"architecture/#design-decisions","title":"Design Decisions","text":""},{"location":"architecture/#markdown-over-code-for-agent-orchestration","title":"Markdown over code for agent orchestration","text":"<p>Agent instructions are inherently natural language. Encoding them in markdown eliminates the impedance mismatch between \"what you want the agent to do\" and \"how you express it.\" Skills are readable by humans and executable by Claude Code without a compilation step.</p>"},{"location":"architecture/#file-system-as-the-integration-layer","title":"File system as the integration layer","text":"<p>The task manager reads JSON files that Claude Code writes to disk. This avoids coupling the dashboard to Claude Code's internals. Any process that writes correctly-shaped JSON to <code>~/.claude/tasks/</code> becomes visible on the board, and the task manager never writes back \u2014 it is purely observational.</p>"},{"location":"architecture/#separation-of-analysis-and-execution","title":"Separation of analysis and execution","text":"<p>Read-only agents (explorers, architects, reviewers) cannot modify the codebase. Write-capable agents (executors) cannot make architectural decisions. This separation enforces a review-then-act workflow and prevents accidental changes during analysis phases.</p>"},{"location":"architecture/#model-tiering-for-cost-control","title":"Model tiering for cost control","text":"<p>Running Opus for every agent would be prohibitively expensive at scale. By reserving Opus for synthesis and judgment tasks while using Sonnet for parallelizable exploration, the system keeps costs proportional to the depth of reasoning required rather than the breadth of search.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>Plugin behavior is configured via <code>.claude/agent-alchemy.local.md</code> \u2014 a YAML frontmatter file that is not committed to version control, allowing per-project or per-user settings.</p>"},{"location":"configuration/#file-location","title":"File Location","text":"<pre><code>your-project/\n\u2514\u2500\u2500 .claude/\n    \u2514\u2500\u2500 agent-alchemy.local.md    # Plugin settings (gitignored)\n</code></pre>"},{"location":"configuration/#file-format","title":"File Format","text":"<p>The file uses YAML frontmatter with nested key-value pairs:</p> <pre><code>---\nauthor: Your Name\nspec-output-path: specs/\ndeep-analysis:\n  - direct-invocation-approval: true\n  - invocation-by-skill-approval: false\nexecute-tasks:\n  - max_parallel: 5\ntdd:\n  framework: auto\n  coverage-threshold: 80\n  strictness: normal\n  test-review-threshold: 70\n  test-review-on-generate: false\n---\n</code></pre>"},{"location":"configuration/#settings-reference","title":"Settings Reference","text":""},{"location":"configuration/#global-settings","title":"Global Settings","text":"Setting Used By Default Description <code>author</code> sdd-tools \u2014 Author name for spec attribution and task metadata <code>spec-output-path</code> sdd-tools <code>specs/</code> Default directory for spec file output"},{"location":"configuration/#deep-analysis-settings","title":"Deep Analysis Settings","text":"<p>Under the <code>deep-analysis</code> key:</p> Setting Default Description <code>direct-invocation-approval</code> <code>true</code> Require user approval of the team plan when invoking <code>/deep-analysis</code> directly <code>invocation-by-skill-approval</code> <code>false</code> Require approval when deep-analysis is loaded by another skill <code>cache-ttl-hours</code> <code>24</code> Hours before exploration cache expires. Set to <code>0</code> to disable caching. <code>enable-checkpointing</code> <code>true</code> Write session checkpoints at phase boundaries for recovery <code>enable-progress-indicators</code> <code>true</code> Display <code>[Phase N/6]</code> progress messages during execution"},{"location":"configuration/#task-execution-settings","title":"Task Execution Settings","text":"<p>Under the <code>execute-tasks</code> key:</p> Setting Default Description <code>max_parallel</code> <code>5</code> Maximum concurrent task-executor agents per wave. CLI <code>--max-parallel</code> takes precedence. Set to <code>1</code> for sequential execution."},{"location":"configuration/#tdd-settings","title":"TDD Settings","text":"<p>Under the <code>tdd</code> key:</p> Setting Default Options Description <code>framework</code> <code>auto</code> <code>auto</code>, <code>pytest</code>, <code>jest</code>, <code>vitest</code> Override test framework auto-detection <code>coverage-threshold</code> <code>80</code> <code>0</code>-<code>100</code> Target coverage percentage for <code>/analyze-coverage</code> <code>strictness</code> <code>normal</code> <code>strict</code>, <code>normal</code>, <code>relaxed</code> RED phase enforcement level in TDD cycle <code>test-review-threshold</code> <code>70</code> <code>0</code>-<code>100</code> Minimum test quality score <code>test-review-on-generate</code> <code>false</code> <code>true</code>, <code>false</code> Auto-run test-reviewer after <code>/generate-tests</code>"},{"location":"configuration/#plugin-tools-settings","title":"Plugin Tools Settings","text":"<p>Under the <code>plugin-tools.dependency-checker</code> key:</p> Setting Default Options Description <code>severity-threshold</code> <code>low</code> <code>critical</code>, <code>high</code>, <code>medium</code>, <code>low</code> Minimum severity level to include in report <code>check-docs-drift</code> <code>true</code> <code>true</code>, <code>false</code> Run Phase 4 CLAUDE.md/README cross-referencing <code>line-count-tolerance</code> <code>10</code> <code>0</code>-<code>100</code> Percentage tolerance for line count drift detection"},{"location":"configuration/#precedence-rules","title":"Precedence Rules","text":"<p>Settings follow this precedence order (highest to lowest):</p> <ol> <li>CLI arguments \u2014 e.g., <code>--max-parallel 3</code> overrides <code>execute-tasks.max_parallel</code></li> <li><code>.claude/agent-alchemy.local.md</code> \u2014 project/user settings</li> <li>Built-in defaults \u2014 hardcoded in each skill</li> </ol> <p>Per-Project Customization</p> <p>Since the settings file is gitignored, each developer can have their own preferences without affecting the team. This is useful for adjusting parallelism, approval requirements, or TDD strictness.</p>"},{"location":"configuration/#example-configurations","title":"Example Configurations","text":"MinimalFull ControlCI/Headless <pre><code>---\nauthor: Jane Smith\n---\n</code></pre> <pre><code>---\nauthor: Jane Smith\nspec-output-path: docs/specs/\ndeep-analysis:\n  - direct-invocation-approval: true\n  - invocation-by-skill-approval: true\n  - cache-ttl-hours: 48\n  - enable-checkpointing: true\nexecute-tasks:\n  - max_parallel: 3\ntdd:\n  framework: vitest\n  coverage-threshold: 90\n  strictness: strict\n  test-review-on-generate: true\nplugin-tools:\n  dependency-checker:\n    severity-threshold: medium\n    check-docs-drift: true\n    line-count-tolerance: 15\n---\n</code></pre> <pre><code>---\ndeep-analysis:\n  - direct-invocation-approval: false\n  - invocation-by-skill-approval: false\n  - enable-progress-indicators: false\nexecute-tasks:\n  - max_parallel: 1\n---\n</code></pre>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to Agent Alchemy! This guide covers the development setup, conventions, and workflow.</p>"},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude Code CLI</li> <li>Node.js &gt;= 18.0.0</li> <li>pnpm &gt;= 8.0.0</li> <li>Python 3.x (for MkDocs documentation site)</li> </ul>"},{"location":"contributing/#repository-setup","title":"Repository Setup","text":"<pre><code>git clone https://github.com/sequenzia/agent-alchemy.git\ncd agent-alchemy\npnpm install\n</code></pre>"},{"location":"contributing/#development-commands","title":"Development Commands","text":"<pre><code># Task Manager\npnpm dev:task-manager          # Start dev server on port 3030\npnpm build:task-manager        # Production build\n\n# VS Code Extension\ncd extensions/vscode\nnpm install\nnpm run build                  # Build with esbuild\nnpm run watch                  # Watch mode for development\nnpm run package                # Package VSIX\n\n# Linting\npnpm lint                      # Lint all packages\n\n# Documentation\nmkdocs serve                   # Preview docs site locally\nmkdocs build --strict          # Build with strict validation\n</code></pre>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"Directory What Lives Here <code>claude/core-tools/</code> Core analysis and exploration plugins <code>claude/dev-tools/</code> Development lifecycle plugins <code>claude/sdd-tools/</code> Spec-Driven Development plugins <code>claude/tdd-tools/</code> Test-Driven Development plugins <code>claude/git-tools/</code> Git automation plugins <code>claude/plugin-tools/</code> Plugin porting and ecosystem health <code>apps/task-manager/</code> Next.js real-time dashboard <code>extensions/vscode/</code> VS Code extension <code>docs/</code> MkDocs documentation source <code>internal/</code> Internal documentation and analysis"},{"location":"contributing/#conventions","title":"Conventions","text":""},{"location":"contributing/#git-commits","title":"Git Commits","text":"<p>We use Conventional Commits:</p> <pre><code>type(scope): description\n</code></pre> Type When to Use <code>feat</code> New feature <code>fix</code> Bug fix <code>docs</code> Documentation changes <code>style</code> Code style (formatting, not CSS) <code>refactor</code> Code restructuring without behavior change <code>test</code> Adding or updating tests <code>chore</code> Build process, tooling, dependencies <p>Examples:</p> <pre><code>feat(sdd-tools): add TDD task pair generation\nfix(task-manager): resolve SSE reconnection on network drop\ndocs(core-tools): update deep-analysis phase descriptions\nchore(vscode): bump Ajv to v8.17\n</code></pre> <p>Use the Plugin</p> <p>You can use <code>/git-commit</code> to auto-generate conventional commit messages from your staged changes.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<ul> <li>TypeScript: Strict mode, functional patterns preferred</li> <li>Styling: Tailwind CSS v4 with shadcn/ui components</li> <li>Naming: Self-documenting names over comments</li> <li>Comments: Only when the \"why\" isn't obvious from the code</li> </ul>"},{"location":"contributing/#plugin-development","title":"Plugin Development","text":"<p>When creating or modifying plugins:</p> <ul> <li>Skills are defined in <code>skills/{name}/SKILL.md</code> with YAML frontmatter</li> <li>Agents are defined in <code>agents/{name}.md</code> with YAML frontmatter</li> <li>Hooks are configured in <code>hooks/hooks.json</code></li> <li>Cross-plugin references use <code>${CLAUDE_PLUGIN_ROOT}/../{source-dir-name}/</code></li> <li>Same-plugin references use <code>${CLAUDE_PLUGIN_ROOT}/</code></li> </ul> <p>See the Plugin Overview for detailed architecture guidance.</p>"},{"location":"contributing/#making-changes","title":"Making Changes","text":"<ol> <li>Create a branch from <code>main</code></li> <li>Make your changes following the conventions above</li> <li>Test your changes \u2014 run linting, build checks, and manual testing</li> <li>Commit with a conventional commit message</li> <li>Open a pull request against <code>main</code></li> </ol>"},{"location":"contributing/#areas-where-help-is-needed","title":"Areas Where Help is Needed","text":"Area Priority Details VS Code extension tests High Zero test coverage \u2014 Ajv compilation, path detection, and line-number mapping need tests Schema synchronization Medium No CI validation ensures JSON schemas match actual plugin frontmatter usage Documentation improvements Medium Always welcome \u2014 typos, clarity, examples"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide walks you through installing Agent Alchemy's plugins, running the Task Manager, and trying your first workflow.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Claude Code CLI installed and authenticated</li> <li>Node.js &gt;= 18.0.0</li> <li>pnpm &gt;= 8.0.0</li> </ul>"},{"location":"getting-started/#install-plugins","title":"Install Plugins","text":"<p>Install the plugin groups you want to use. Each plugin is independent \u2014 pick only what you need, or install them all:</p> <pre><code># The SDD pipeline (specs \u2192 tasks \u2192 execution)\nclaude plugins install agent-alchemy/agent-alchemy-sdd-tools\n\n# Codebase analysis and exploration\nclaude plugins install agent-alchemy/agent-alchemy-core-tools\n\n# Feature dev, code review, docs, changelog\nclaude plugins install agent-alchemy/agent-alchemy-dev-tools\n\n# TDD workflows (RED-GREEN-REFACTOR)\nclaude plugins install agent-alchemy/agent-alchemy-tdd-tools\n\n# Git commit automation\nclaude plugins install agent-alchemy/agent-alchemy-git-tools\n\n# Plugin porting, validation, and ecosystem analysis\nclaude plugins install agent-alchemy/agent-alchemy-plugin-tools\n</code></pre> <p>Verify your installation:</p> <pre><code>claude plugins list\n</code></pre> <p>You should see the installed plugins with their versions and skill counts.</p> <p>Plugin Dependencies</p> <p>Most plugins work independently. The exceptions: SDD Tools' TDD variant skills (<code>/create-tdd-tasks</code>, <code>/execute-tdd-tasks</code>) require TDD Tools to be installed. Several skills across dev-tools and sdd-tools optionally use Core Tools' <code>/deep-analysis</code> for codebase exploration.</p>"},{"location":"getting-started/#run-the-task-manager","title":"Run the Task Manager","text":"<p>The Task Manager provides a real-time Kanban view of task execution. To use it, clone the repository and start the dev server:</p> <pre><code>git clone https://github.com/sequenzia/agent-alchemy.git\ncd agent-alchemy\npnpm install\npnpm dev:task-manager\n</code></pre> <p>Open http://localhost:3030 in your browser. The dashboard automatically picks up task files from <code>~/.claude/tasks/</code> and displays them in real time via SSE.</p> <p>For details on the dashboard features and API, see the Task Manager guide.</p>"},{"location":"getting-started/#your-first-workflow","title":"Your First Workflow","text":""},{"location":"getting-started/#option-1-explore-a-codebase","title":"Option 1: Explore a Codebase","text":"<p>Navigate to any project and run deep analysis:</p> <pre><code>/deep-analysis\n</code></pre> <p>This launches a multi-agent exploration team that maps architecture, traces execution paths, and produces a structured synthesis of the codebase. Results are cached for 24 hours.</p> <p>See Core Tools for full details.</p>"},{"location":"getting-started/#option-2-create-a-spec-and-execute-it","title":"Option 2: Create a Spec and Execute It","text":"<p>The SDD pipeline is Agent Alchemy's core workflow. Start by creating a spec:</p> <pre><code>/create-spec\n</code></pre> <p>This launches an adaptive interview that gathers requirements and produces a structured specification. Then decompose it into tasks and execute:</p> <pre><code>/create-tasks specs/SPEC-My-Feature.md\n/execute-tasks --task-group my-feature\n</code></pre> <p>The executor launches autonomous agents in dependency-ordered waves. Open the Task Manager to watch progress in real time.</p> <p>See SDD Tools for the full pipeline guide.</p>"},{"location":"getting-started/#option-3-generate-tests","title":"Option 3: Generate Tests","text":"<p>Point the test generator at acceptance criteria or source files:</p> <pre><code>/generate-tests\n</code></pre> <p>It auto-detects your test framework (pytest, Jest, or Vitest) and spawns parallel test-writer agents. For a full RED-GREEN-REFACTOR cycle on a specific feature, use:</p> <pre><code>/tdd-cycle\n</code></pre> <p>See TDD Tools for all TDD workflows.</p>"},{"location":"getting-started/#configuration","title":"Configuration","text":"<p>Plugin behavior is customized via <code>.claude/agent-alchemy.local.md</code> in your project root. This file is not committed to version control, so each project (or developer) can have different settings.</p> <p>Common settings to configure first:</p> Setting Default What It Controls <code>deep-analysis.cache-ttl-hours</code> <code>24</code> How long exploration cache lasts <code>tdd.framework</code> <code>auto</code> Override test framework detection <code>execute-tasks.max_parallel</code> <code>5</code> Max concurrent agents per wave <p>See Configuration for the full settings reference.</p>"},{"location":"getting-started/#vs-code-extension","title":"VS Code Extension","text":"<p>If you're building your own Claude Code plugins, install the VS Code extension for schema validation and autocomplete:</p> <ol> <li>Clone the repo and build the VSIX:     <pre><code>cd extensions/vscode\nnpm install\nnpm run package\n</code></pre></li> <li>Install in VS Code: <code>Extensions \u2192 Install from VSIX...</code></li> <li>Open any workspace with a <code>.claude-plugin/plugin.json</code> file \u2014 the extension activates automatically</li> </ol> <p>See VS Code Extension for details.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"Want to... Go to... Understand the system design Architecture Browse all plugins and skills Plugin Overview Build a feature with agent teams Dev Tools \u2192 <code>/feature-dev</code> Contribute to Agent Alchemy Contributing"},{"location":"task-manager/","title":"Task Manager","text":"<p>The Task Manager is a real-time Kanban dashboard that visualizes autonomous task execution driven by the SDD Tools pipeline. It watches <code>~/.claude/tasks/</code> for JSON task files produced by <code>execute-tasks</code> and <code>execute-tdd-tasks</code>, displaying each task's status, dependencies, metadata, and execution artifacts as they update in near real-time.</p>"},{"location":"task-manager/#overview","title":"Overview","text":"<p>When the SDD tools execute a task plan, they write individual JSON files into <code>~/.claude/tasks/&lt;list-name&gt;/</code>. The Task Manager picks up every file creation, update, and deletion through a filesystem watcher and pushes changes over Server-Sent Events (SSE) to the browser. The result is a live view of task progress without polling or manual refresh.</p> <pre><code>graph LR\n    A[\"execute-tasks skill\"] --&gt;|writes JSON| B[\"~/.claude/tasks/\"]\n    B --&gt;|Chokidar watcher| C[\"Next.js API routes\"]\n    C --&gt;|SSE stream| D[\"Browser UI\"]\n    D --&gt;|TanStack Query| E[\"Kanban Board\"]</code></pre> <p>Key capabilities:</p> <ul> <li>Three-column Kanban board \u2014 tasks grouped into Pending, In Progress, and Completed</li> <li>Live updates \u2014 filesystem changes appear in the UI within ~300ms</li> <li>Execution context viewer \u2014 tabbed display of session artifacts (plan, log, context, progress, summary)</li> <li>Task detail dialog \u2014 full task metadata with dependency navigation</li> <li>Search filtering \u2014 filter tasks by subject or description text</li> <li>Dark mode \u2014 system-aware theme toggle, defaults to dark</li> </ul>"},{"location":"task-manager/#getting-started","title":"Getting Started","text":""},{"location":"task-manager/#prerequisites","title":"Prerequisites","text":"Requirement Version Node.js &gt;= 18 pnpm &gt;= 8 <p>The Task Manager reads from <code>~/.claude/tasks/</code>. This directory is created automatically when you run the <code>execute-tasks</code> or <code>execute-tdd-tasks</code> skills from SDD Tools. You can also create it manually for testing.</p>"},{"location":"task-manager/#installation-and-running","title":"Installation and Running","text":"<pre><code># From the repository root\npnpm install\n\n# Start the development server on port 3030\npnpm dev:task-manager\n</code></pre> <p>Open http://localhost:3030 in your browser.</p> <p>First launch with no tasks</p> <p>If <code>~/.claude/tasks/</code> is empty or does not exist, the dashboard shows a message prompting you to create task files. Run <code>/execute-tasks</code> against a spec to populate the directory, or create a sample task list manually (see Task File Format below).</p>"},{"location":"task-manager/#production-build","title":"Production Build","text":"<pre><code>pnpm build:task-manager\ncd apps/task-manager &amp;&amp; pnpm start\n</code></pre>"},{"location":"task-manager/#ui-features","title":"UI Features","text":""},{"location":"task-manager/#kanban-board","title":"Kanban Board","text":"<p>The main view is a three-column board that groups tasks by status:</p> Column Status Color Pending <code>pending</code> Slate In Progress <code>in_progress</code> Blue Completed <code>completed</code> Green <p>Each task card shows:</p> <ul> <li>Task ID \u2014 monospace <code>#id</code> identifier</li> <li>Subject \u2014 the task title, truncated to two lines</li> <li>Active badge \u2014 appears when the task has an <code>activeForm</code> value (currently being worked on)</li> <li>Dependency indicators \u2014 red \"Blocked by N\" and orange \"Blocks N\" counts</li> </ul>"},{"location":"task-manager/#summary-statistics-bar","title":"Summary Statistics Bar","text":"<p>A horizontal stat bar appears above the board when tasks are loaded, displaying:</p> <ul> <li>Total task count</li> <li>Pending count</li> <li>In Progress count</li> <li>Completed count</li> <li>Blocked count (tasks with non-empty <code>blockedBy</code>)</li> <li>Completion rate as a percentage</li> </ul>"},{"location":"task-manager/#search","title":"Search","text":"<p>The search input in the header filters tasks across all three columns by matching against <code>subject</code> and <code>description</code> fields. The filter is case-insensitive and updates instantly as you type. Click the X button or clear the input to reset.</p>"},{"location":"task-manager/#task-detail-dialog","title":"Task Detail Dialog","text":"<p>Click any task card to open a detail dialog showing:</p> <ul> <li>Status badge with color-coded styling</li> <li>Description \u2014 full task description, preserving whitespace</li> <li>Active Form \u2014 what the agent is currently doing (if present)</li> <li>Blocked By / Blocks \u2014 clickable task ID links that navigate to the referenced task</li> <li>Metadata \u2014 priority badge, complexity badge, phase indicator, and all custom metadata fields</li> <li>View Execution Context button \u2014 opens the execution details dialog (when execution data is available)</li> </ul> <p>Dependency Navigation</p> <p>Clicking a <code>#id</code> link in the Blocked By or Blocks sections switches the detail dialog to that task, letting you trace dependency chains without closing the dialog.</p>"},{"location":"task-manager/#task-list-selector","title":"Task List Selector","text":"<p>The dropdown in the header lists all task lists found in <code>~/.claude/tasks/</code>. Each entry shows the list name and task count. Selecting a list navigates to <code>/lists/&lt;listId&gt;</code>, loading that list's tasks via a Server Component.</p>"},{"location":"task-manager/#execution-context-viewer","title":"Execution Context Viewer","text":"<p>When an execution session is active (indicated by an <code>execution_pointer.md</code> file in the task list directory), the execution dialog becomes available. It renders session artifacts as tabbed content:</p> Tab Artifact File Description Plan <code>execution_plan.md</code> The wave-based execution plan Progress <code>progress.md</code> Live wave/task status with active and completed indicators Context <code>execution_context.md</code> Session-level context and configuration Log <code>task_log.md</code> Chronological execution log Summary <code>session_summary.md</code> Final session results <p>The Progress tab has a dedicated view showing:</p> <ul> <li>Execution status badge (Initializing, Executing, Complete)</li> <li>Current wave number out of total waves</li> <li>Maximum parallelism setting</li> <li>Active tasks with animated pulse indicators</li> <li>Completed tasks with PASS/FAIL result badges</li> </ul> <p>All markdown artifacts are rendered with full GitHub-flavored Markdown support, including tables and code blocks.</p>"},{"location":"task-manager/#execution-progress-bar","title":"Execution Progress Bar","text":"<p>When a session is actively executing, a compact progress indicator appears in the header:</p> <ul> <li>Animated green pulse dot</li> <li>Current wave / total waves</li> <li>Active task count</li> <li>Completed task count</li> </ul> <p>Clicking this bar opens the full Execution Context Viewer.</p>"},{"location":"task-manager/#dark-mode","title":"Dark Mode","text":"<p>The theme toggle in the header switches between light, dark, and system themes. The default is dark mode. The implementation uses <code>next-themes</code> with SSR-safe hydration.</p>"},{"location":"task-manager/#architecture","title":"Architecture","text":""},{"location":"task-manager/#data-flow-pipeline","title":"Data Flow Pipeline","text":"<pre><code>flowchart TD\n    subgraph Filesystem\n        A[\"~/.claude/tasks/&amp;lt;list&amp;gt;/*.json\"]\n        B[\"execution_pointer.md\"]\n        C[\"Session artifacts (.md)\"]\n    end\n\n    subgraph Server [\"Next.js Server (Node.js)\"]\n        D[\"FileWatcher singleton&lt;br/&gt;(Chokidar v5, 300ms polling)\"]\n        E[\"taskService.ts&lt;br/&gt;(file reading + parsing)\"]\n        F[\"API Route Handlers\"]\n        G[\"SSE Route&lt;br/&gt;(ReadableStream)\"]\n    end\n\n    subgraph Client [\"Browser\"]\n        H[\"EventSource&lt;br/&gt;(useSSE hook)\"]\n        I[\"TanStack Query&lt;br/&gt;(cache + invalidation)\"]\n        J[\"Server Components&lt;br/&gt;(initial data)\"]\n        K[\"Client Components&lt;br/&gt;(Kanban, Dialogs)\"]\n    end\n\n    A --&gt;|watch| D\n    C --&gt;|watch| D\n    D --&gt;|emit events| G\n    A --&gt;|read| E\n    B --&gt;|resolve| E\n    C --&gt;|read| E\n    E --&gt;|serve| F\n    F --&gt;|initial fetch| J\n    G --&gt;|stream| H\n    H --&gt;|invalidate| I\n    J --&gt;|hydrate| K\n    I --&gt;|re-render| K</code></pre>"},{"location":"task-manager/#key-technical-patterns","title":"Key Technical Patterns","text":""},{"location":"task-manager/#global-singleton-filewatcher","title":"Global Singleton FileWatcher","text":"<p>The <code>FileWatcher</code> class extends Node.js <code>EventEmitter</code> and is stored on <code>globalThis</code> to survive Next.js hot module replacement during development. Only one Chokidar instance runs regardless of how many times the module is re-evaluated.</p> src/lib/fileWatcher.ts<pre><code>const globalForWatcher = globalThis as unknown as {\n  fileWatcher: FileWatcher | undefined\n}\n\nexport const fileWatcher = globalForWatcher.fileWatcher ?? new FileWatcher()\n\nif (process.env.NODE_ENV !== 'production') {\n  globalForWatcher.fileWatcher = fileWatcher\n}\n</code></pre>"},{"location":"task-manager/#sse-streaming","title":"SSE Streaming","text":"<p>The <code>/api/events</code> route creates a <code>ReadableStream</code> that subscribes to the <code>FileWatcher</code> singleton. Events are filtered by <code>taskListId</code> and sent as named SSE events (<code>task:created</code>, <code>task:updated</code>, <code>task:deleted</code>, <code>execution:updated</code>). A 30-second heartbeat keeps the connection alive.</p>"},{"location":"task-manager/#query-invalidation-cycle","title":"Query Invalidation Cycle","text":"<p>The <code>useSSE</code> hook connects an <code>EventSource</code> to the SSE endpoint and invalidates the appropriate TanStack Query cache keys when events arrive. This triggers a refetch of the data, which the Kanban board picks up through its reactive subscription to the query.</p> src/hooks/useSSE.ts<pre><code>eventSource.addEventListener('task:updated', () =&gt; {\n  queryClient.invalidateQueries({ queryKey: taskKeys.list(taskListId) })\n  queryClient.invalidateQueries({ queryKey: taskListKeys.all })\n  router.refresh()  // Also refresh Server Component data\n})\n</code></pre>"},{"location":"task-manager/#path-traversal-protection","title":"Path Traversal Protection","text":"<p>Both the <code>/api/tasks/[listId]</code> and <code>/api/execution-context/[listId]</code> routes reject <code>listId</code> values containing <code>..</code> or <code>/</code>. The <code>resolveExecutionDir</code> function in <code>taskService.ts</code> additionally validates that the resolved execution pointer path does not escape the user's home directory.</p>"},{"location":"task-manager/#serverclient-component-boundary","title":"Server/Client Component Boundary","text":"<p>The list page (<code>/lists/[listId]/page.tsx</code>) is a Server Component that fetches tasks, task lists, and execution context in parallel via <code>Promise.all</code>. This data is passed as <code>initialData</code> to TanStack Query in the <code>TaskBoardClient</code> client component, enabling instant rendering with no loading flash.</p>"},{"location":"task-manager/#api-reference","title":"API Reference","text":"<p>All routes are read-only (GET). There are no mutation endpoints \u2014 task state is managed entirely through the filesystem by the SDD tools.</p>"},{"location":"task-manager/#get-apihealth","title":"<code>GET /api/health</code>","text":"<p>Health check endpoint.</p> <p>Response:</p> <pre><code>{\n  \"status\": \"ok\",\n  \"timestamp\": \"2026-02-15T12:00:00.000Z\"\n}\n</code></pre>"},{"location":"task-manager/#get-apitask-lists","title":"<code>GET /api/task-lists</code>","text":"<p>Returns all task lists found in <code>~/.claude/tasks/</code>. Each subdirectory containing at least one <code>.json</code> file is treated as a task list.</p> <p>Response:</p> <pre><code>{\n  \"taskLists\": [\n    { \"id\": \"my-feature\", \"name\": \"my-feature\", \"taskCount\": 12 }\n  ]\n}\n</code></pre>"},{"location":"task-manager/#get-apitaskslistid","title":"<code>GET /api/tasks/:listId</code>","text":"<p>Returns all tasks for a specific list, sorted numerically by ID.</p> <p>Parameters:</p> Parameter Location Required Description <code>listId</code> Path Yes Task list directory name <p>Path Traversal Validation</p> <p>The <code>listId</code> is validated to reject values containing <code>..</code> or <code>/</code>. Invalid values return a <code>400</code> response.</p> <p>Response:</p> <pre><code>{\n  \"tasks\": [\n    {\n      \"id\": \"1\",\n      \"subject\": \"Implement authentication middleware\",\n      \"description\": \"Add JWT validation to API routes\",\n      \"status\": \"in_progress\",\n      \"activeForm\": \"Writing middleware function\",\n      \"blocks\": [\"2\", \"3\"],\n      \"blockedBy\": [],\n      \"metadata\": {\n        \"priority\": \"high\",\n        \"complexity\": \"M\",\n        \"task_uid\": \"auth-middleware-001\"\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"task-manager/#get-apievents","title":"<code>GET /api/events</code>","text":"<p>Server-Sent Events stream for real-time task and execution updates.</p> <p>Parameters:</p> Parameter Location Required Description <code>taskListId</code> Query No Filter events to a specific list <p>Event Types:</p> Event Data Trigger <code>connected</code> <code>{}</code> Initial connection <code>task:created</code> <code>FileWatcherEvent</code> New <code>.json</code> file in watched directory <code>task:updated</code> <code>FileWatcherEvent</code> Existing <code>.json</code> file modified <code>task:deleted</code> <code>FileWatcherEvent</code> <code>.json</code> file removed <code>execution:updated</code> <code>ExecutionWatcherEvent</code> <code>.md</code> or <code>.txt</code> file changed in execution directory <p>The stream sends a heartbeat comment (<code>:heartbeat</code>) every 30 seconds to maintain the connection.</p>"},{"location":"task-manager/#get-apiexecution-contextlistid","title":"<code>GET /api/execution-context/:listId</code>","text":"<p>Returns execution session artifacts for a task list. Requires an <code>execution_pointer.md</code> file in the task list directory that contains the absolute path to the session folder.</p> <p>Parameters:</p> Parameter Location Required Description <code>listId</code> Path Yes Task list directory name <p>Response:</p> <pre><code>{\n  \"executionContext\": {\n    \"executionDir\": \"/Users/you/.claude/sessions/__live_session__\",\n    \"artifacts\": [\n      {\n        \"name\": \"execution_plan\",\n        \"content\": \"# Execution Plan\\n...\",\n        \"lastModified\": 1739612400000\n      }\n    ],\n    \"progress\": {\n      \"status\": \"Executing\",\n      \"wave\": 2,\n      \"totalWaves\": 4,\n      \"maxParallel\": 3,\n      \"activeTasks\": [\n        { \"id\": \"5\", \"subject\": \"Add error handling\", \"phase\": \"Implementation\" }\n      ],\n      \"completedTasks\": [\n        { \"id\": \"3\", \"subject\": \"Create data model\", \"result\": \"PASS\" }\n      ]\n    }\n  }\n}\n</code></pre> <p>Returns <code>{ \"executionContext\": null }</code> when no execution pointer exists or the session directory is not found.</p>"},{"location":"task-manager/#task-file-format","title":"Task File Format","text":"<p>Task files are JSON stored in <code>~/.claude/tasks/&lt;list-name&gt;/&lt;id&gt;.json</code>. The <code>taskService.ts</code> parser is lenient: it normalizes missing fields and coerces types where possible.</p> ~/.claude/tasks/my-feature/1.json<pre><code>{\n  \"id\": \"1\",\n  \"subject\": \"Implement user authentication\",\n  \"description\": \"Add JWT-based authentication to all API routes\",\n  \"status\": \"pending\",\n  \"blocks\": [\"2\", \"3\"],\n  \"blockedBy\": [],\n  \"activeForm\": null,\n  \"metadata\": {\n    \"priority\": \"high\",\n    \"complexity\": \"M\",\n    \"phase\": 1,\n    \"task_uid\": \"auth-impl-001\",\n    \"source_section\": \"Authentication Requirements\"\n  }\n}\n</code></pre> <p>Field Reference:</p> Field Type Required Description <code>id</code> <code>string</code> Yes Unique identifier (falls back to filename without extension) <code>subject</code> <code>string</code> Yes Task title <code>description</code> <code>string</code> No Detailed description <code>status</code> <code>string</code> No <code>pending</code>, <code>in_progress</code>, or <code>completed</code> (defaults to <code>pending</code>) <code>blocks</code> <code>string[]</code> No IDs of tasks this task blocks <code>blockedBy</code> <code>string[]</code> No IDs of tasks blocking this task <code>activeForm</code> <code>string</code> No What the agent is currently doing <code>metadata.priority</code> <code>string</code> No <code>critical</code>, <code>high</code>, <code>medium</code>, or <code>low</code> <code>metadata.complexity</code> <code>string</code> No <code>XS</code>, <code>S</code>, <code>M</code>, <code>L</code>, or <code>XL</code> <code>metadata.phase</code> <code>number</code> No Execution wave/phase number <code>metadata.task_uid</code> <code>string</code> No Globally unique task identifier from SDD tools <code>metadata.*</code> <code>unknown</code> No Any additional metadata fields are displayed in the detail dialog"},{"location":"task-manager/#integration-with-sdd-tools","title":"Integration with SDD Tools","text":"<p>The Task Manager is the visual counterpart to the SDD execution pipeline. Here is how the pieces connect:</p> <pre><code>sequenceDiagram\n    participant User\n    participant create-tasks\n    participant execute-tasks\n    participant FileSystem as ~/.claude/tasks/\n    participant TaskManager as Task Manager UI\n\n    User-&gt;&gt;create-tasks: Run against spec\n    create-tasks-&gt;&gt;FileSystem: Write task JSON files\n    FileSystem--&gt;&gt;TaskManager: Chokidar detects new files\n    TaskManager-&gt;&gt;TaskManager: Board shows pending tasks\n\n    User-&gt;&gt;execute-tasks: Start execution\n    execute-tasks-&gt;&gt;FileSystem: Write execution_pointer.md\n    execute-tasks-&gt;&gt;FileSystem: Update task status to in_progress\n    FileSystem--&gt;&gt;TaskManager: SSE: task:updated\n    TaskManager-&gt;&gt;TaskManager: Card moves to In Progress\n\n    execute-tasks-&gt;&gt;FileSystem: Write progress.md, task_log.md\n    FileSystem--&gt;&gt;TaskManager: SSE: execution:updated\n    TaskManager-&gt;&gt;TaskManager: Progress bar updates\n\n    execute-tasks-&gt;&gt;FileSystem: Update task status to completed\n    FileSystem--&gt;&gt;TaskManager: SSE: task:updated\n    TaskManager-&gt;&gt;TaskManager: Card moves to Completed</code></pre>"},{"location":"task-manager/#execution-pointer","title":"Execution Pointer","text":"<p>When <code>execute-tasks</code> starts a session, it writes <code>execution_pointer.md</code> into the task list directory. This file contains a single line: the absolute path to the session's artifact folder. The Task Manager reads this pointer to locate and display execution artifacts.</p> <p>Session Lifecycle</p> <p>The execution pointer persists after a session ends, so you can review artifacts from completed sessions. Starting a new session overwrites the pointer with the new session path.</p>"},{"location":"task-manager/#technology-stack","title":"Technology Stack","text":"Technology Version Role Next.js 16 App Router framework with Server Components React 19 UI rendering TanStack Query 5 Client-side data caching and invalidation Tailwind CSS 4 Utility-first styling shadcn/ui \u2014 Radix-based component library (new-york variant) Chokidar 5 Cross-platform filesystem watching next-themes \u2014 SSR-safe dark/light theme switching react-markdown \u2014 Markdown rendering for execution artifacts"},{"location":"task-manager/#project-structure","title":"Project Structure","text":"<pre><code>apps/task-manager/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 layout.tsx                          # Root layout with Providers\n\u2502   \u2502   \u251c\u2500\u2500 page.tsx                            # Redirects to first task list\n\u2502   \u2502   \u251c\u2500\u2500 lists/[listId]/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 page.tsx                        # Server Component \u2014 parallel data fetch\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 loading.tsx                     # Loading skeleton\n\u2502   \u2502   \u2514\u2500\u2500 api/\n\u2502   \u2502       \u251c\u2500\u2500 health/route.ts                 # Health check\n\u2502   \u2502       \u251c\u2500\u2500 task-lists/route.ts             # List task lists\n\u2502   \u2502       \u251c\u2500\u2500 tasks/[listId]/route.ts         # Tasks for a list\n\u2502   \u2502       \u251c\u2500\u2500 events/route.ts                 # SSE stream\n\u2502   \u2502       \u2514\u2500\u2500 execution-context/[listId]/route.ts  # Execution artifacts\n\u2502   \u251c\u2500\u2500 components/\n\u2502   \u2502   \u251c\u2500\u2500 TaskBoardClient.tsx                 # Main client wrapper\n\u2502   \u2502   \u251c\u2500\u2500 KanbanBoard.tsx                     # Three-column board\n\u2502   \u2502   \u251c\u2500\u2500 TaskDetail.tsx                      # Task detail dialog\n\u2502   \u2502   \u251c\u2500\u2500 ExecutionDialog.tsx                 # Execution context viewer\n\u2502   \u2502   \u251c\u2500\u2500 ExecutionProgressBar.tsx            # Header progress indicator\n\u2502   \u2502   \u251c\u2500\u2500 SummaryStats.tsx                    # Statistics bar\n\u2502   \u2502   \u2514\u2500\u2500 ui/                                 # shadcn/ui primitives\n\u2502   \u251c\u2500\u2500 hooks/\n\u2502   \u2502   \u251c\u2500\u2500 useSSE.ts                           # SSE connection + query invalidation\n\u2502   \u2502   \u251c\u2500\u2500 useTasks.ts                         # TanStack Query for tasks\n\u2502   \u2502   \u251c\u2500\u2500 useTaskLists.ts                     # TanStack Query for task lists\n\u2502   \u2502   \u2514\u2500\u2500 useExecutionContext.ts              # TanStack Query for execution data\n\u2502   \u251c\u2500\u2500 lib/\n\u2502   \u2502   \u251c\u2500\u2500 taskService.ts                      # Server-side file reading + parsing\n\u2502   \u2502   \u251c\u2500\u2500 fileWatcher.ts                      # Chokidar singleton + event emission\n\u2502   \u2502   \u2514\u2500\u2500 api.ts                              # Client-side fetch functions\n\u2502   \u2514\u2500\u2500 types/\n\u2502       \u251c\u2500\u2500 task.ts                             # Task, TaskList, SSE event types\n\u2502       \u2514\u2500\u2500 execution.ts                        # ExecutionContext types\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 next.config.ts\n\u2514\u2500\u2500 tsconfig.json\n</code></pre>"},{"location":"vscode-extension/","title":"VS Code Extension","text":"<p>Version: 0.1.1 | Publisher: agent-alchemy</p> <p>The Claude Code Plugin Schemas extension provides schema validation, YAML frontmatter autocomplete, and hover documentation for Claude Code plugin development.</p>"},{"location":"vscode-extension/#features","title":"Features","text":""},{"location":"vscode-extension/#yaml-frontmatter-validation","title":"YAML Frontmatter Validation","text":"<p>Real-time validation of YAML frontmatter in skill (<code>SKILL.md</code>) and agent (<code>.md</code>) files using Ajv compiled schemas. Catches invalid fields, wrong types, and missing required properties as you type.</p> <p>Validated frontmatter fields for skills:</p> <ul> <li><code>name</code>, <code>description</code>, <code>argument-hint</code></li> <li><code>user-invocable</code>, <code>disable-model-invocation</code></li> <li><code>model</code>, <code>allowed-tools</code></li> </ul> <p>Validated frontmatter fields for agents:</p> <ul> <li><code>name</code>, <code>description</code>, <code>model</code></li> <li><code>tools</code>, <code>skills</code></li> </ul>"},{"location":"vscode-extension/#json-schema-validation","title":"JSON Schema Validation","text":"<p>Native VS Code JSON schema validation for 5 configuration file types:</p> File Schema Purpose <code>.claude-plugin/plugin.json</code> <code>plugin.schema.json</code> Plugin manifest structure <code>hooks/hooks.json</code> <code>hooks.schema.json</code> Lifecycle hook configuration <code>.mcp.json</code> <code>mcp.schema.json</code> MCP server configuration <code>.lsp.json</code> <code>lsp.schema.json</code> LSP server configuration <code>marketplace.json</code> <code>marketplace.schema.json</code> Plugin marketplace registry"},{"location":"vscode-extension/#autocomplete-and-hover","title":"Autocomplete and Hover","text":"<ul> <li>Autocomplete \u2014 Suggests valid frontmatter fields and enum values as you type</li> <li>Hover documentation \u2014 Shows field descriptions and allowed values on hover</li> </ul>"},{"location":"vscode-extension/#installation","title":"Installation","text":""},{"location":"vscode-extension/#from-source","title":"From Source","text":"<pre><code>cd extensions/vscode\nnpm install\nnpm run build\nnpm run package    # Creates .vsix file\n</code></pre> <p>Then install the <code>.vsix</code> file via VS Code: Extensions &gt; \"...\" menu &gt; \"Install from VSIX...\"</p>"},{"location":"vscode-extension/#activation","title":"Activation","text":"<p>The extension auto-activates when it detects:</p> <ul> <li>A workspace containing <code>.claude-plugin/plugin.json</code></li> <li>Any open Markdown file</li> </ul>"},{"location":"vscode-extension/#architecture","title":"Architecture","text":"<pre><code>extensions/vscode/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 extension.ts           # Entry point, registers providers\n\u2502   \u251c\u2500\u2500 frontmatter/\n\u2502   \u2502   \u251c\u2500\u2500 validator.ts       # Ajv-based YAML validation\n\u2502   \u2502   \u251c\u2500\u2500 completionProvider.ts  # Autocomplete suggestions\n\u2502   \u2502   \u2514\u2500\u2500 hoverProvider.ts   # Hover documentation\n\u2502   \u2514\u2500\u2500 utils/\n\u2502       \u2514\u2500\u2500 fileDetection.ts   # Path-based file type detection\n\u251c\u2500\u2500 schemas/                   # 7 JSON schemas\n\u2502   \u251c\u2500\u2500 skill-frontmatter.schema.json\n\u2502   \u251c\u2500\u2500 agent-frontmatter.schema.json\n\u2502   \u251c\u2500\u2500 plugin.schema.json\n\u2502   \u251c\u2500\u2500 hooks.schema.json\n\u2502   \u251c\u2500\u2500 mcp.schema.json\n\u2502   \u251c\u2500\u2500 lsp.schema.json\n\u2502   \u2514\u2500\u2500 marketplace.schema.json\n\u2514\u2500\u2500 package.json               # Extension manifest\n</code></pre> <p>Key implementation details:</p> <ul> <li>Ajv compilation \u2014 Schemas are compiled once at activation for fast validation</li> <li>Path-based detection \u2014 Files are classified by their directory path (<code>skills/</code> \u2192 skill, <code>agents/</code> \u2192 agent)</li> <li>Line-number mapping \u2014 Validation errors are mapped back to YAML source lines for accurate diagnostics</li> <li>esbuild bundling \u2014 Single-file output for fast extension loading</li> </ul> <p>Known Limitation</p> <p>The extension currently has zero test coverage. The Ajv compilation, path detection, and line-number mapping logic are untested. This is flagged as a high-severity known challenge.</p>"},{"location":"vscode-extension/#technology-stack","title":"Technology Stack","text":"Component Technology Runtime VS Code Extension API (^1.85.0) Validation Ajv (JSON Schema validator) YAML Parsing js-yaml Bundler esbuild Language TypeScript (strict mode)"},{"location":"plugins/","title":"Plugin Overview","text":"<p>Agent Alchemy extends Claude Code through six plugin groups, each targeting a different phase of the development lifecycle. Plugins are installed independently \u2014 pick only what you need.</p>"},{"location":"plugins/#at-a-glance","title":"At a Glance","text":"Plugin Focus Skills Agents Version Core Tools Codebase analysis and exploration 4 3 0.2.0 Dev Tools Feature development, review, docs 9 4 0.3.0 SDD Tools Spec-Driven Development pipeline 4 4 0.2.0 TDD Tools Test-Driven Development workflows 5 3 0.2.0 Git Tools Git commit automation 1 0 0.1.0 Plugin Tools Plugin porting and ecosystem health 5 2 0.1.1"},{"location":"plugins/#how-plugins-work","title":"How Plugins Work","text":"<p>Plugins are markdown-as-code \u2014 skills, agents, and hooks are all defined as markdown files with YAML frontmatter. Claude Code loads them at runtime and executes the instructions directly, with no compilation or build step.</p> <p>Each plugin contains up to four component types:</p> Component Format Purpose Skills <code>skills/{name}/SKILL.md</code> Multi-step workflows invoked as slash commands Agents <code>agents/{name}.md</code> Specialized subagents with defined tools and models Hooks <code>hooks/hooks.json</code> Event-driven lifecycle automation References <code>skills/{name}/references/</code> Supporting materials loaded on demand <p>For details on the underlying architecture, see the Architecture page.</p>"},{"location":"plugins/#installation","title":"Installation","text":"<p>Install plugins individually via the Claude Code CLI:</p> <pre><code># Core analysis and exploration\nclaude plugins install agent-alchemy/agent-alchemy-core-tools\n\n# Development lifecycle (feature dev, review, docs)\nclaude plugins install agent-alchemy/agent-alchemy-dev-tools\n\n# Spec-Driven Development pipeline\nclaude plugins install agent-alchemy/agent-alchemy-sdd-tools\n\n# Test-Driven Development workflows\nclaude plugins install agent-alchemy/agent-alchemy-tdd-tools\n\n# Git commit automation\nclaude plugins install agent-alchemy/agent-alchemy-git-tools\n\n# Plugin porting, validation, and ecosystem analysis\nclaude plugins install agent-alchemy/agent-alchemy-plugin-tools\n</code></pre>"},{"location":"plugins/#plugin-groups","title":"Plugin Groups","text":""},{"location":"plugins/#core-tools","title":"Core Tools","text":"<p>The foundation layer. Provides deep codebase exploration via multi-agent hub-and-spoke teams, language-specific patterns, and project convention discovery. The deep-analysis skill is the keystone \u2014 loaded by 4 other skills across 3 plugin groups.</p> <p>Key skills: <code>/deep-analysis</code>, <code>/codebase-analysis</code></p> <p>Read the full Core Tools guide \u2192</p>"},{"location":"plugins/#dev-tools","title":"Dev Tools","text":"<p>The development lifecycle toolkit. Covers feature implementation with architect/reviewer agent teams, documentation generation (MkDocs and standalone markdown), code quality patterns, and changelog management.</p> <p>Key skills: <code>/feature-dev</code>, <code>/docs-manager</code>, <code>/changelog-format</code></p> <p>Read the full Dev Tools guide \u2192</p>"},{"location":"plugins/#sdd-tools","title":"SDD Tools","text":"<p>The structured development pipeline. Transforms ideas into specs via adaptive interviews, decomposes specs into dependency-ordered tasks, and executes them autonomously with wave-based parallelism.</p> <p>Key skills: <code>/create-spec</code> \u2192 <code>/analyze-spec</code> \u2192 <code>/create-tasks</code> \u2192 <code>/execute-tasks</code></p> <p>Read the full SDD Tools guide \u2192</p>"},{"location":"plugins/#tdd-tools","title":"TDD Tools","text":"<p>Test-Driven Development workflows. Automates the RED-GREEN-REFACTOR cycle, generates behavior-driven tests from acceptance criteria or source code, analyzes test coverage, and orchestrates TDD task execution with wave-based parallelism. Auto-detects pytest, Jest, and Vitest.</p> <p>Key skills: <code>/tdd-cycle</code>, <code>/generate-tests</code>, <code>/analyze-coverage</code>, <code>/create-tdd-tasks</code>, <code>/execute-tdd-tasks</code></p> <p>Read the full TDD Tools guide \u2192</p>"},{"location":"plugins/#git-tools","title":"Git Tools","text":"<p>Lightweight git automation. A single skill that analyzes staged changes and generates conventional commit messages using the Haiku model for fast, low-cost operation.</p> <p>Key skill: <code>/git-commit</code></p> <p>Read the full Git Tools guide \u2192</p>"},{"location":"plugins/#plugin-tools","title":"Plugin Tools","text":"<p>Plugin lifecycle management. Ports Agent Alchemy plugins to other platforms using an adapter framework with live research, validates adapters against current platform documentation, applies incremental updates to ported plugins, and analyzes ecosystem health across all plugin groups.</p> <p>Key skills: <code>/port-plugin</code>, <code>/validate-adapter</code>, <code>/dependency-checker</code>, <code>/bump-plugin-version</code></p> <p>Read the full Plugin Tools guide \u2192</p>"},{"location":"plugins/#cross-plugin-dependencies","title":"Cross-Plugin Dependencies","text":"<p>Plugins are designed to be independent, but some skills compose across boundaries:</p> <pre><code>graph TD\n    DA[\"deep-analysis&lt;br/&gt;(core-tools)\"] --&gt; CA[\"codebase-analysis&lt;br/&gt;(core-tools)\"]\n    DA --&gt; FD[\"feature-dev&lt;br/&gt;(dev-tools)\"]\n    DA --&gt; DM[\"docs-manager&lt;br/&gt;(dev-tools)\"]\n    DA --&gt; CS[\"create-spec&lt;br/&gt;(sdd-tools)\"]\n\n    ETT[\"execute-tdd-tasks&lt;br/&gt;(tdd-tools)\"] -.-&gt;|\"soft dep\"| TE[\"task-executor&lt;br/&gt;(sdd-tools)\"]\n\n    DC[\"dependency-checker&lt;br/&gt;(plugin-tools)\"] -.-&gt;|\"reads all\"| DA\n    DC -.-&gt;|\"reads all\"| FD\n    DC -.-&gt;|\"reads all\"| CS\n    DC -.-&gt;|\"reads all\"| TDD[\"tdd-executor&lt;br/&gt;(tdd-tools)\"]\n\n    style DA fill:#7c4dff,color:#fff\n    style CA fill:#7c4dff,color:#fff\n    style FD fill:#00bcd4,color:#fff\n    style DM fill:#00bcd4,color:#fff\n    style CS fill:#f44336,color:#fff\n    style TE fill:#f44336,color:#fff\n    style ETT fill:#4caf50,color:#fff\n    style TDD fill:#4caf50,color:#fff\n    style DC fill:#ff9800,color:#fff</code></pre> <ul> <li>deep-analysis (core-tools) is loaded by 4 skills across core-tools, dev-tools, and sdd-tools</li> <li>execute-tdd-tasks (tdd-tools) has a soft dependency on <code>task-executor</code> from sdd-tools for non-TDD task routing</li> <li>dependency-checker (plugin-tools) reads all plugin groups to build its dependency graph</li> <li>All other cross-references are optional \u2014 skills degrade gracefully when dependencies are missing</li> </ul>"},{"location":"plugins/#model-usage","title":"Model Usage","text":"<p>Plugins use three model tiers to balance quality and cost:</p> Tier Model Used For Examples High Opus Synthesis, architecture, review code-synthesizer, code-architect, code-reviewer, tdd-executor Medium Sonnet Exploration, parallel workers code-explorer, test-writer, researcher (plugin-tools) Low Haiku Simple, fast tasks git-commit"},{"location":"plugins/core-tools/","title":"Core Tools","text":"<p>Core Tools (v0.2.0) provides the foundational analysis and exploration capabilities for Agent Alchemy. It contains the deep-analysis skill \u2014 the keystone of the entire plugin ecosystem \u2014 along with supporting skills and agents that power codebase understanding across all plugin groups.</p>"},{"location":"plugins/core-tools/#overview","title":"Overview","text":"Version 0.2.0 Skills 4 (2 user-invocable, 2 agent-loaded) Agents 3 (code-explorer, code-synthesizer, code-architect) Hooks 1 (auto-approve session file operations) <p>Core Tools is the most composed plugin in Agent Alchemy. Its <code>deep-analysis</code> skill is loaded by four other skills across three different plugin groups, making it the engine behind every workflow that needs to understand a codebase before acting on it.</p> <pre><code>graph TD\n    DA[deep-analysis&lt;br/&gt;&lt;i&gt;core-tools&lt;/i&gt;]\n    CA[codebase-analysis&lt;br/&gt;&lt;i&gt;core-tools&lt;/i&gt;]\n    FD[feature-dev&lt;br/&gt;&lt;i&gt;dev-tools&lt;/i&gt;]\n    DM[docs-manager&lt;br/&gt;&lt;i&gt;dev-tools&lt;/i&gt;]\n    CS[create-spec&lt;br/&gt;&lt;i&gt;sdd-tools&lt;/i&gt;]\n\n    CA --&gt;|wraps| DA\n    FD --&gt;|loads in Phase 2| DA\n    DM --&gt;|loads for understanding| DA\n    CS --&gt;|optional, new features| DA\n\n    style DA fill:#7c3aed,color:#fff,stroke:#5b21b6\n    style CA fill:#6366f1,color:#fff,stroke:#4f46e5\n    style FD fill:#06b6d4,color:#fff,stroke:#0891b2\n    style DM fill:#06b6d4,color:#fff,stroke:#0891b2\n    style CS fill:#f59e0b,color:#fff,stroke:#d97706</code></pre>"},{"location":"plugins/core-tools/#skills","title":"Skills","text":""},{"location":"plugins/core-tools/#deep-analysis-the-keystone-skill","title":"<code>/deep-analysis</code> \u2014 The Keystone Skill","text":"<p>Quick Reference</p> <ul> <li>Invocable: <code>/deep-analysis &lt;analysis-context or focus-area&gt;</code></li> <li>Lines: 521</li> <li>Phases: 6 (Session Setup through Completion)</li> <li>Team pattern: Hub-and-spoke (N explorers + 1 synthesizer)</li> <li>Source: <code>claude/core-tools/skills/deep-analysis/SKILL.md</code></li> </ul> <p>Deep-analysis is the core engine that powers codebase understanding across Agent Alchemy. It performs rapid reconnaissance, dynamically plans focus areas tailored to the actual codebase structure, assembles a team of explorer and synthesizer agents, and produces a unified analysis.</p>"},{"location":"plugins/core-tools/#the-6-phases","title":"The 6 Phases","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant L as Lead (You)\n    participant E1 as Explorer 1&lt;br/&gt;(Sonnet)\n    participant E2 as Explorer 2&lt;br/&gt;(Sonnet)\n    participant EN as Explorer N&lt;br/&gt;(Sonnet)\n    participant S as Synthesizer&lt;br/&gt;(Opus)\n\n    Note over L: Phase 0: Session Setup\n    L-&gt;&gt;L: Check exploration cache\n    L-&gt;&gt;L: Check for interrupted session\n    L-&gt;&gt;L: Initialize session directory\n\n    Note over L: Phase 1: Reconnaissance &amp; Planning\n    L-&gt;&gt;L: Rapid codebase mapping&lt;br/&gt;(Glob, Grep, Read)\n    L-&gt;&gt;L: Generate dynamic focus areas\n    L-&gt;&gt;L: Compose team plan\n\n    Note over U,L: Phase 2: Review &amp; Approval\n    L-&gt;&gt;U: Present team plan\n    U-&gt;&gt;L: Approve / Modify / Regenerate\n\n    Note over L,S: Phase 3: Team Assembly\n    L-&gt;&gt;E1: Spawn + assign Focus Area 1\n    L-&gt;&gt;E2: Spawn + assign Focus Area 2\n    L-&gt;&gt;EN: Spawn + assign Focus Area N\n    L-&gt;&gt;S: Spawn synthesizer (waits)\n\n    Note over E1,EN: Phase 4: Focused Exploration\n    par Independent Exploration\n        E1-&gt;&gt;E1: Explore assigned area\n        E2-&gt;&gt;E2: Explore assigned area\n        EN-&gt;&gt;EN: Explore assigned area\n    end\n    E1-&gt;&gt;L: Findings complete\n    E2-&gt;&gt;L: Findings complete\n    EN-&gt;&gt;L: Findings complete\n\n    Note over L,S: Phase 5: Evaluation &amp; Synthesis\n    L-&gt;&gt;S: All findings ready \u2014 begin synthesis\n    S-&gt;&gt;S: Merge findings\n    S-&gt;&gt;S: Deep investigation (Bash)\n    S--&gt;&gt;E1: Follow-up question (optional)\n    E1--&gt;&gt;S: Clarification\n    S-&gt;&gt;S: Evaluate completeness\n    S-&gt;&gt;L: Unified analysis complete\n\n    Note over L: Phase 6: Completion + Cleanup\n    L-&gt;&gt;L: Cache results\n    L-&gt;&gt;U: Present analysis\n    L-&gt;&gt;E1: Shutdown\n    L-&gt;&gt;E2: Shutdown\n    L-&gt;&gt;EN: Shutdown\n    L-&gt;&gt;S: Shutdown\n    L-&gt;&gt;L: Archive session, delete team</code></pre>"},{"location":"plugins/core-tools/#phase-0-session-setup","title":"Phase 0: Session Setup","text":"<p>Before any exploration begins, deep-analysis checks for existing work:</p> <ol> <li> <p>Exploration Cache Check \u2014 If caching is enabled (<code>cache-ttl-hours &gt; 0</code>), it looks for a valid cached analysis in <code>.claude/sessions/exploration-cache/manifest.md</code>. A cache hit is valid when the analysis context matches, the codebase path matches, the timestamp is within the TTL, and config files haven't been modified. In skill-invoked mode, valid caches are auto-accepted. In direct invocation, the user is offered a choice.</p> </li> <li> <p>Interrupted Session Check \u2014 If checkpointing is enabled, it looks for <code>.claude/sessions/__da_live__/checkpoint.md</code> to detect a prior run that didn't complete. The user can resume from the last completed phase or start fresh.</p> </li> <li> <p>Session Initialization \u2014 Creates the <code>.claude/sessions/__da_live__/</code> directory with <code>checkpoint.md</code> and <code>progress.md</code> files to track the run.</p> </li> </ol> <p>Skipping Phase 0</p> <p>If both caching and checkpointing are disabled (<code>cache-ttl-hours: 0</code> and <code>enable-checkpointing: false</code>), Phase 0 is skipped entirely for faster startup.</p>"},{"location":"plugins/core-tools/#phase-1-reconnaissance-planning","title":"Phase 1: Reconnaissance &amp; Planning","text":"<p>The lead performs a rapid (1-2 minute) codebase scan:</p> <ul> <li>Directory structure \u2014 <code>Glob</code> maps top-level layout</li> <li>Language/framework detection \u2014 Reads <code>package.json</code>, <code>tsconfig.json</code>, <code>pyproject.toml</code>, etc.</li> <li>File distribution \u2014 Gauges size and shape of different areas</li> <li>Key documentation \u2014 Reads <code>README.md</code>, <code>CLAUDE.md</code> for project context</li> <li>Hotspot identification \u2014 For feature-focused analysis, <code>Grep</code> finds feature-related code; for general analysis, identifies the most architecturally significant directories</li> </ul> <p>From these findings, the lead generates dynamic focus areas (typically 2-4, based on codebase size) with specific directories, starting files, search terms, and complexity estimates. Static fallback templates are available if reconnaissance fails.</p> <p>Dynamic Focus Area Example</p> <pre><code>#### Focus Area 1: API layer in src/api/\n- **Directories:** src/api/, src/middleware/\n- **Starting files:** src/api/routes.ts, src/api/auth.ts\n- **Search patterns:** \"router\", \"middleware\", \"authenticate\"\n- **Complexity:** Medium\n- **Assigned to:** explorer-1 (sonnet)\n</code></pre>"},{"location":"plugins/core-tools/#phase-2-review-approval","title":"Phase 2: Review &amp; Approval","text":"<p>The team plan is presented for user review. Approval behavior depends on how deep-analysis was invoked:</p> Invocation Mode Default Behavior Setting Direct (<code>/deep-analysis</code>) Requires approval <code>direct-invocation-approval: true</code> Loaded by another skill Auto-approved <code>invocation-by-skill-approval: false</code> <p>When approval is required, the user can Approve, Modify (up to 3 cycles), or Regenerate (up to 2 cycles) the plan.</p>"},{"location":"plugins/core-tools/#phase-3-team-assembly","title":"Phase 3: Team Assembly","text":"<p>Using the approved plan, the lead:</p> <ol> <li>Creates a team via <code>TeamCreate</code> named <code>deep-analysis-{timestamp}</code></li> <li>Spawns N explorer agents (Sonnet) \u2014 one per focus area</li> <li>Spawns 1 synthesizer agent (Opus)</li> <li>Creates tasks for each focus area and a blocked synthesis task</li> <li>Assigns exploration tasks with a status guard \u2014 tasks are only assigned if <code>status === pending</code> and <code>owner === empty</code>, preventing duplicate work</li> </ol>"},{"location":"plugins/core-tools/#phase-4-focused-exploration","title":"Phase 4: Focused Exploration","text":"<p>Explorers work independently in a hub-and-spoke topology:</p> <ul> <li>No cross-worker communication \u2014 each explorer handles its assigned focus area</li> <li>The lead monitors progress by checking task statuses</li> <li>Completed findings are checkpointed to <code>.claude/sessions/__da_live__/explorer-{N}-findings.md</code></li> <li>The lead waits for all exploration tasks to complete before proceeding</li> </ul> <p>Duplicate Prevention</p> <p>The status-guard pattern is the primary mechanism for preventing duplicate work. The lead never re-assigns a task that is <code>completed</code> or <code>in_progress</code>. If a task is <code>pending</code> with an owner set, the explorer received the assignment but hasn't started \u2014 the lead waits without re-sending.</p>"},{"location":"plugins/core-tools/#phase-5-evaluation-synthesis","title":"Phase 5: Evaluation &amp; Synthesis","text":"<p>The synthesizer (Opus) performs a multi-step process:</p> <ol> <li>Structural completeness check \u2014 Verifies all explorers produced content. Failed explorations trigger follow-up tasks.</li> <li>Merge findings \u2014 Deduplicates and reconciles reports across explorers</li> <li>Deep investigation \u2014 Uses Bash for git history, dependency trees, and static analysis</li> <li>Follow-up questions \u2014 Messages explorers to resolve conflicts or fill gaps</li> <li>Completeness evaluation \u2014 Assesses confidence and notes open questions</li> </ol>"},{"location":"plugins/core-tools/#phase-6-completion-cleanup","title":"Phase 6: Completion + Cleanup","text":"<ol> <li>Writes the exploration cache (for future reuse within the TTL window)</li> <li>Presents results to the user (standalone) or returns to the calling skill</li> <li>Sends shutdown requests to all agents</li> <li>Archives the session directory and deletes the team</li> </ol>"},{"location":"plugins/core-tools/#codebase-analysis-structured-analysis-wrapper","title":"<code>/codebase-analysis</code> \u2014 Structured Analysis Wrapper","text":"<p>Quick Reference</p> <ul> <li>Invocable: <code>/codebase-analysis &lt;analysis-context or feature-description&gt;</code></li> <li>Phases: 3 (Deep Analysis, Reporting, Post-Analysis Actions)</li> <li>Source: <code>claude/core-tools/skills/codebase-analysis/SKILL.md</code></li> </ul> <p>Codebase-analysis wraps deep-analysis with structured reporting and interactive post-analysis actions. It is the primary user-facing entry point for codebase understanding.</p>"},{"location":"plugins/core-tools/#workflow","title":"Workflow","text":"<pre><code>flowchart LR\n    P1[Phase 1&lt;br/&gt;Deep Analysis] --&gt; P2[Phase 2&lt;br/&gt;Reporting]\n    P2 --&gt; P3[Phase 3&lt;br/&gt;Post-Analysis Actions]\n\n    style P1 fill:#7c3aed,color:#fff\n    style P2 fill:#6366f1,color:#fff\n    style P3 fill:#06b6d4,color:#fff</code></pre> <p>Phase 1: Deep Analysis \u2014 Loads and executes the deep-analysis skill. Since it's skill-invoked, the team plan is auto-approved by default and cache hits are auto-accepted.</p> <p>Phase 2: Reporting \u2014 Structures the synthesis into a report with these sections:</p> <ul> <li>Executive Summary</li> <li>Architecture Overview</li> <li>Critical Files (5-10 most important)</li> <li>Patterns &amp; Conventions</li> <li>Relationship Map</li> <li>Challenges &amp; Risks</li> <li>Recommendations</li> </ul> <p>Phase 3: Post-Analysis Actions \u2014 Presents an interactive menu (multi-select) of follow-up actions:</p> Action Description Save report as Markdown Writes the full report to a file Update README.md Adds architecture/structure insights Update CLAUDE.md Adds patterns/conventions for AI context Keep condensed summary in memory Retains a quick reference in conversation Address actionable insights Fix challenges and implement recommendations interactively <p>Action Ordering</p> <p>\"Address actionable insights\" always runs last, since code changes could invalidate analysis if documentation is generated afterward. It is also the most interactive action.</p>"},{"location":"plugins/core-tools/#language-patterns-language-specific-best-practices","title":"<code>language-patterns</code> \u2014 Language-Specific Best Practices","text":"<p>Agent Skill</p> <p>This skill is not user-invocable. It is loaded by the <code>code-explorer</code> and <code>code-synthesizer</code> agents to inform their work.</p> <p>Provides patterns and idioms for three languages/frameworks:</p> TypeScriptPythonReact <ul> <li>Type safety (<code>unknown</code> over <code>any</code>, discriminated unions, type guards)</li> <li>Null handling (optional chaining, nullish coalescing)</li> <li>Async patterns (<code>async</code>/<code>await</code>, <code>Promise.all</code>, <code>Promise.allSettled</code>)</li> <li>Import organization (external, internal, relative)</li> </ul> <ul> <li>Type hints and dataclasses</li> <li>Pydantic validation</li> <li>Pythonic patterns (comprehensions, context managers, <code>pathlib</code>)</li> <li>Custom error hierarchies</li> </ul> <ul> <li>Functional components with hooks</li> <li>Custom hooks for logic reuse</li> <li>State management hierarchy (local, lifted, context, external store)</li> <li>Performance (memoization, lazy loading, error boundaries)</li> </ul> <p>Source: <code>claude/core-tools/skills/language-patterns/SKILL.md</code></p>"},{"location":"plugins/core-tools/#project-conventions-convention-discovery-guide","title":"<code>project-conventions</code> \u2014 Convention Discovery Guide","text":"<p>Agent Skill</p> <p>This skill is not user-invocable. It is loaded by the <code>code-explorer</code> and <code>code-synthesizer</code> agents.</p> <p>Guides agents through a structured process for discovering project-specific conventions:</p> <ol> <li>Project Configuration \u2014 Reads <code>.eslintrc</code>, <code>.prettierrc</code>, <code>tsconfig.json</code>, <code>pyproject.toml</code>, <code>CONTRIBUTING.md</code>, etc.</li> <li>Existing Code Patterns \u2014 Studies file organization, naming patterns, and import styles from the actual codebase</li> <li>Similar Features \u2014 Finds features analogous to the analysis target and studies their implementation</li> </ol> <p>The skill also provides a Convention Application Checklist covering code style, structure, patterns, testing, and documentation \u2014 ensuring agents match the project's existing practices rather than imposing generic standards.</p> <p>Source: <code>claude/core-tools/skills/project-conventions/SKILL.md</code></p>"},{"location":"plugins/core-tools/#agents","title":"Agents","text":""},{"location":"plugins/core-tools/#code-architect-opus","title":"code-architect (Opus)","text":"<p>The blueprint designer. Spawned by feature-dev (dev-tools) to generate competing implementation approaches.</p> Property Value Model Opus Tools Read, Glob, Grep, SendMessage, TaskUpdate, TaskGet, TaskList Loaded Skills None Source <code>claude/core-tools/agents/code-architect.md</code> <p>Read-Only by Design</p> <p>Like the explorer and synthesizer, the architect has no Write or Edit access. It designs blueprints but never modifies code \u2014 only the lead (feature-dev) applies changes.</p> <p>Design approaches:</p> <ol> <li>Minimal/Simple \u2014 Fewest files changed, direct implementation, inline solutions</li> <li>Flexible/Extensible \u2014 Abstractions where reuse is likely, extension points</li> <li>Project-Aligned \u2014 Match existing patterns exactly, follow team conventions</li> </ol> <p>Output format: Implementation blueprints with files to create/modify, data flow, API changes, error handling, risks/mitigations, and testing strategy.</p>"},{"location":"plugins/core-tools/#code-explorer-sonnet","title":"code-explorer (Sonnet)","text":"<p>The exploration workhorse of the deep-analysis team. Each instance is assigned a single focus area and works independently.</p> Property Value Model Sonnet Tools Read, Glob, Grep, Bash, SendMessage, TaskUpdate, TaskGet, TaskList Loaded Skills <code>project-conventions</code>, <code>language-patterns</code> Source <code>claude/core-tools/agents/code-explorer.md</code> <p>Read-Only by Design</p> <p>Explorers use Read, Glob, Grep, and Bash for investigation \u2014 they do not have Write or Edit access. This enforces separation of concerns: explorers observe, they do not modify.</p> <p>Exploration strategies:</p> <ol> <li>Start from entry points \u2014 Routes, CLI commands, UI components, then trace execution paths</li> <li>Follow the data \u2014 Models, schemas, validation, transformation, persistence</li> <li>Find similar features \u2014 Search for analogous implementations to understand patterns</li> <li>Map dependencies \u2014 Shared utilities, configuration, external dependencies</li> </ol> <p>Output format: Structured markdown with Key Files table, Code Patterns, Important Functions/Classes, Integration Points, Potential Challenges, and Recommendations.</p> <p>Team communication:</p> <ul> <li>Acknowledges task assignments immediately</li> <li>Prevents duplicate work by checking task status before re-exploring</li> <li>Responds to follow-up questions from the synthesizer with specific file paths, function names, and line numbers</li> </ul>"},{"location":"plugins/core-tools/#code-synthesizer-opus","title":"code-synthesizer (Opus)","text":"<p>The analytical brain of the deep-analysis team. Merges findings from all explorers into a unified analysis with deep investigation capabilities.</p> Property Value Model Opus Tools Read, Glob, Grep, Bash, SendMessage, TaskUpdate, TaskGet, TaskList Loaded Skills <code>project-conventions</code>, <code>language-patterns</code> Source <code>claude/core-tools/agents/code-synthesizer.md</code> <p>Synthesis process (8 steps):</p> <ol> <li>Merge findings \u2014 Combine and deduplicate across all explorer reports</li> <li>Identify conflicts and gaps \u2014 Flag disagreements, thin coverage, missing connections</li> <li>Read critical files \u2014 Verify by reading high-relevance files directly</li> <li>Deep investigation \u2014 Use Bash for git history, dependency trees, static analysis</li> <li>Map relationships \u2014 Trace imports, calls, data flow between components</li> <li>Identify patterns \u2014 Catalog conventions, shared abstractions, deviations</li> <li>Assess challenges \u2014 Technical risks, coupling hotspots, test coverage gaps</li> <li>Evaluate completeness \u2014 Confirm all critical areas are covered, note confidence levels</li> </ol> <p>Deep investigation capabilities (via Bash):</p> Investigation Type Example Commands Git history <code>git blame</code>, <code>git log --stat</code>, <code>git diff branch..HEAD</code> Dependency trees <code>npm ls</code>, <code>pip show</code>, <code>cargo tree</code> Static analysis Linters, type checkers, build config inspection Cross-cutting concerns Tracing patterns across 3+ modules Security audit Auth flows, secret handling, common vulnerabilities Performance N+1 queries, hot paths, bundle sizes <p>Interactive Synthesis</p> <p>Unlike a passive aggregator, the synthesizer can message explorers with targeted follow-up questions to resolve conflicts. If an explorer is unresponsive, the synthesizer investigates directly rather than blocking.</p>"},{"location":"plugins/core-tools/#hub-and-spoke-coordination-pattern","title":"Hub-and-Spoke Coordination Pattern","text":"<p>The deep-analysis team uses a hub-and-spoke topology \u2014 not a mesh. This is a deliberate architectural choice.</p> <pre><code>graph TD\n    Lead[Lead&lt;br/&gt;&lt;i&gt;Plans &amp; coordinates&lt;/i&gt;]\n    E1[Explorer 1&lt;br/&gt;&lt;i&gt;Sonnet&lt;/i&gt;]\n    E2[Explorer 2&lt;br/&gt;&lt;i&gt;Sonnet&lt;/i&gt;]\n    E3[Explorer N&lt;br/&gt;&lt;i&gt;Sonnet&lt;/i&gt;]\n    Syn[Synthesizer&lt;br/&gt;&lt;i&gt;Opus&lt;/i&gt;]\n\n    Lead --&gt;|assigns| E1\n    Lead --&gt;|assigns| E2\n    Lead --&gt;|assigns| E3\n    Lead --&gt;|assigns| Syn\n\n    E1 --&gt;|findings| Lead\n    E2 --&gt;|findings| Lead\n    E3 --&gt;|findings| Lead\n\n    Syn -.-&gt;|follow-up| E1\n    Syn -.-&gt;|follow-up| E2\n    Syn -.-&gt;|follow-up| E3\n    Syn --&gt;|synthesis| Lead\n\n    style Lead fill:#7c3aed,color:#fff,stroke:#5b21b6\n    style E1 fill:#6366f1,color:#fff,stroke:#4f46e5\n    style E2 fill:#6366f1,color:#fff,stroke:#4f46e5\n    style E3 fill:#6366f1,color:#fff,stroke:#4f46e5\n    style Syn fill:#f59e0b,color:#fff,stroke:#d97706</code></pre> Role Communicates With Never Communicates With Lead All agents \u2014 Explorer Lead, Synthesizer (when asked) Other explorers Synthesizer Lead, any explorer (follow-ups) \u2014 <p>Why hub-and-spoke?</p> <ul> <li>Predictability \u2014 No emergent cross-worker conversations that could diverge</li> <li>Efficiency \u2014 Explorers focus purely on their assigned area without coordination overhead</li> <li>Fault isolation \u2014 One explorer failing doesn't cascade to others</li> <li>Duplicate prevention \u2014 The lead is the single source of truth for task assignment</li> </ul>"},{"location":"plugins/core-tools/#hooks","title":"Hooks","text":"<p>Core Tools includes one lifecycle hook that auto-approves file operations targeting deep-analysis session directories:</p> claude/core-tools/hooks/auto-approve-da-session.sh<pre><code># Auto-approves Write/Edit/Bash operations targeting:\n#   .claude/sessions/__da_live__/*         (active session)\n#   .claude/sessions/exploration-cache/*   (cached results)\n#   .claude/sessions/da-*/*               (archived sessions)\n</code></pre> <p>This hook is registered in <code>claude/core-tools/hooks/hooks.json</code> as a <code>PreToolUse</code> hook matching <code>Write|Edit|Bash</code> tools. It enables autonomous session management without prompting the user for every checkpoint write or cache update.</p> <p>Safety Design</p> <p>The hook never exits non-zero. If it encounters an unexpected error, it exits cleanly with no output (the \"no opinion\" response), allowing the normal permission prompt to appear. Operations outside session directories are always passed through to the standard permission flow.</p>"},{"location":"plugins/core-tools/#cross-plugin-dependency-map","title":"Cross-Plugin Dependency Map","text":"<p>Deep-analysis is the keystone skill \u2014 the most-composed building block in Agent Alchemy. Understanding how it integrates with other plugins is essential for understanding the platform.</p> Consumer Skill Plugin How It Uses Deep-Analysis <code>codebase-analysis</code> core-tools Wraps it with reporting and post-analysis actions <code>feature-dev</code> dev-tools Loads in Phase 2 for codebase exploration before architecture planning <code>docs-manager</code> dev-tools Loads for codebase understanding before generating documentation <code>create-spec</code> sdd-tools Optionally loads for \"new feature\" type specs that need codebase context <p>Cross-plugin reference convention:</p> <p>Skills reference deep-analysis using the relative path pattern:</p> <pre><code>${CLAUDE_PLUGIN_ROOT}/../core-tools/skills/deep-analysis/SKILL.md\n</code></pre> <p>Same-plugin references (like <code>codebase-analysis</code> loading <code>deep-analysis</code>) use:</p> <pre><code>${CLAUDE_PLUGIN_ROOT}/skills/deep-analysis/SKILL.md\n</code></pre> <p>Never Use Marketplace Names in Paths</p> <p>Path references always use the short source directory name (<code>core-tools</code>, <code>dev-tools</code>, <code>sdd-tools</code>), never the full marketplace name (<code>agent-alchemy-core-tools</code>).</p>"},{"location":"plugins/core-tools/#configuration","title":"Configuration","text":"<p>All deep-analysis settings are stored in <code>.claude/agent-alchemy.local.md</code> (not committed to version control). Settings are read at the start of every deep-analysis run.</p>"},{"location":"plugins/core-tools/#settings-reference","title":"Settings Reference","text":"Setting Default Description <code>direct-invocation-approval</code> <code>true</code> Require user approval of the team plan when <code>/deep-analysis</code> is invoked directly <code>invocation-by-skill-approval</code> <code>false</code> Require approval when deep-analysis is loaded by another skill (e.g., <code>feature-dev</code>) <code>cache-ttl-hours</code> <code>24</code> Hours before exploration cache expires. Set to <code>0</code> to disable caching entirely <code>enable-checkpointing</code> <code>true</code> Write session checkpoints at phase boundaries for crash recovery <code>enable-progress-indicators</code> <code>true</code> Display <code>[Phase N/6]</code> progress messages during execution"},{"location":"plugins/core-tools/#session-recovery","title":"Session Recovery","text":"<p>When checkpointing is enabled and a run is interrupted, the next invocation detects the incomplete session and offers to resume:</p> Interrupted At Recovery Strategy Phase 1 Restart from Phase 1 (reconnaissance is fast, ~1-2 min) Phase 2 Load saved <code>team_plan.md</code>, re-present for approval Phase 3 Load approved plan, restart team assembly Phase 4 Load completed explorer findings, only re-run missing explorers Phase 5 Load all explorer findings, spawn fresh synthesizer Phase 6 Load <code>synthesis.md</code>, skip to present results and cleanup <p>Disabling Session Features</p> <p>For lightweight runs where persistence overhead isn't wanted, set both <code>cache-ttl-hours: 0</code> and <code>enable-checkpointing: false</code>. Phase 0 will be skipped entirely.</p>"},{"location":"plugins/core-tools/#error-handling","title":"Error Handling","text":"<p>Deep-analysis includes structured error handling at every phase:</p> Failure Response Settings file malformed Warn user, proceed with defaults Reconnaissance fails Fall back to static focus area templates Max approval cycles exhausted Offer \"Approve current\" or \"Abort\" Single worker fails Create follow-up task for the missed area Two workers fail Attempt follow-ups; if those fail, synthesize with partial results All workers fail Inform user, offer retry or abort Synthesizer fails Present raw exploration results directly"},{"location":"plugins/core-tools/#directory-structure","title":"Directory Structure","text":"<pre><code>claude/core-tools/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 code-architect.md             # Opus \u2014 blueprint design agent\n\u2502   \u251c\u2500\u2500 code-explorer.md              # Sonnet \u2014 exploration worker\n\u2502   \u2514\u2500\u2500 code-synthesizer.md           # Opus \u2014 synthesis agent\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 hooks.json                    # Hook registration\n\u2502   \u2514\u2500\u2500 auto-approve-da-session.sh    # Auto-approve session file ops\n\u251c\u2500\u2500 skills/\n\u2502   \u251c\u2500\u2500 deep-analysis/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md                  # Keystone skill (521 lines)\n\u2502   \u251c\u2500\u2500 codebase-analysis/\n\u2502   \u2502   \u251c\u2500\u2500 SKILL.md                  # 3-phase analysis wrapper\n\u2502   \u2502   \u2514\u2500\u2500 references/\n\u2502   \u2502       \u251c\u2500\u2500 report-template.md    # Structured report format\n\u2502   \u2502       \u2514\u2500\u2500 actionable-insights-template.md\n\u2502   \u251c\u2500\u2500 language-patterns/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md                  # TS/Python/React patterns\n\u2502   \u2514\u2500\u2500 project-conventions/\n\u2502       \u2514\u2500\u2500 SKILL.md                  # Convention discovery guide\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"plugins/dev-tools/","title":"Dev Tools","text":"<p>Version: 0.3.0 | Skills: 9 | Agents: 4</p> <p>Dev Tools provides the development lifecycle toolkit \u2014 from feature implementation through code review, documentation, and changelog management.</p>"},{"location":"plugins/dev-tools/#skills","title":"Skills","text":""},{"location":"plugins/dev-tools/#feature-dev-feature-development-workflow","title":"<code>/feature-dev</code> \u2014 Feature Development Workflow","text":"<p>The primary skill for implementing new features or significant changes. Runs a structured 7-phase workflow:</p> <ol> <li>Discovery \u2014 Understand feature requirements from user input</li> <li>Codebase Exploration \u2014 Deep-analysis maps relevant code areas (loads Core Tools deep-analysis)</li> <li>Clarifying Questions \u2014 Resolve ambiguities with the user</li> <li>Architecture Design \u2014 Spawn code-architect agents (Opus) to design implementation blueprints</li> <li>Implementation \u2014 Build the feature following the approved architecture</li> <li>Quality Review \u2014 Spawn code-reviewer agents (Opus) for correctness, security, and maintainability review</li> <li>Summary \u2014 Document what was accomplished</li> </ol> <pre><code># Usage\n/feature-dev Add dark mode toggle to the settings page\n/feature-dev Implement WebSocket support for real-time notifications\n</code></pre> <p>Composition Chain</p> <p>feature-dev orchestrates multiple agent teams:</p> <ul> <li>Phase 2: Loads deep-analysis for codebase exploration (code-explorer x N + code-synthesizer x 1)</li> <li>Phase 4: Spawns 2-3 code-architect agents (from core-tools) for blueprint design</li> <li>Phase 6: Spawns 3 code-reviewer agents for quality review</li> </ul>"},{"location":"plugins/dev-tools/#docs-manager-documentation-management","title":"<code>/docs-manager</code> \u2014 Documentation Management","text":"<p>Manages MkDocs sites, standalone markdown files, and change summaries through a 6-phase interactive workflow. Supports generating new documentation, updating existing pages, and creating changelogs.</p> <pre><code>/docs-manager                    # Interactive discovery\n/docs-manager README             # Generate a README.md\n/docs-manager mkdocs             # Set up MkDocs site\n/docs-manager changelog          # Create change summary\n</code></pre>"},{"location":"plugins/dev-tools/#bug-killer-hypothesis-driven-debugging","title":"<code>/bug-killer</code> \u2014 Hypothesis-Driven Debugging","text":"<p>A systematic debugging skill that enforces investigation before fixes. Every bug gets a hypothesis journal, evidence gathering, and root cause confirmation before any code changes are applied.</p> <pre><code>/bug-killer TypeError: Cannot read property 'id' of undefined\n/bug-killer tests/test_auth.py::test_login_fails --deep\n</code></pre> <p>5-Phase Workflow:</p> <ol> <li>Triage &amp; Reproduction \u2014 Reproduce the bug, form an initial hypothesis, route to quick or deep track</li> <li>Investigation \u2014 Gather evidence with language-specific debugging techniques</li> <li>Root Cause Analysis \u2014 Confirm root cause through hypothesis testing</li> <li>Fix &amp; Verify \u2014 Apply minimal fix, run tests, write regression test</li> <li>Wrap-up &amp; Report \u2014 Document the investigation trail, capture project learnings</li> </ol>"},{"location":"plugins/dev-tools/#track-routing","title":"Track Routing","text":"<p>The triage phase routes bugs to one of two investigation tracks:</p> Track Trigger Investigation Agents Quick Localized bug (1-2 files), clear error, obvious fix Read error location + immediate callers None Deep Multi-file bug, unclear root cause, concurrency/state issues, <code>--deep</code> flag 2-3 code-explorer agents (core-tools) + 1-3 bug-investigator agents Sonnet workers <p>Auto-Escalation</p> <p>If 2 hypotheses are rejected during the quick track, the workflow automatically escalates to the deep track. All hypothesis journal entries are preserved across escalation.</p>"},{"location":"plugins/dev-tools/#hypothesis-journal","title":"Hypothesis Journal","text":"<p>The core artifact of every debugging session. Each hypothesis follows a structured format with evidence for/against, a test plan, and status (Pending/Confirmed/Rejected). Rejected hypotheses are never deleted \u2014 they provide context for the investigation trail.</p>"},{"location":"plugins/dev-tools/#deep-track-agent-teams","title":"Deep Track Agent Teams","text":"<p>On the deep track, bug-killer orchestrates two types of agent teams:</p> <ul> <li>Phase 2: Spawns 2-3 <code>code-explorer</code> agents (from core-tools, Sonnet) to explore focus areas related to the bug</li> <li>Phase 3: Spawns 1-3 <code>bug-investigator</code> agents (Sonnet) to test specific hypotheses in parallel</li> <li>Phase 4: Loads <code>code-quality</code> skill for fix validation and scans for related issues across the codebase</li> </ul> <p>After the fix, bug-killer loads the <code>project-learnings</code> skill to evaluate whether the bug reveals project-specific knowledge worth capturing in CLAUDE.md.</p>"},{"location":"plugins/dev-tools/#document-changes-session-change-reports","title":"<code>/document-changes</code> \u2014 Session Change Reports","text":"<p>Generates a structured markdown report documenting codebase changes from the current working session. Captures files added, modified, and deleted, along with commit history and a human-readable summary.</p> <pre><code>/document-changes                    # Auto-infer scope from changes\n/document-changes auth refactor      # Specify scope for the report\n</code></pre> <p>4-Step Workflow:</p> <ol> <li>Validate \u2014 Confirm the directory is a git repository</li> <li>Gather \u2014 Collect uncommitted changes, staged changes, and recent commits via git</li> <li>Locate \u2014 Determine report path (default: <code>internal/reports/&lt;scope&gt;-YYYY-MM-DD.md</code>)</li> <li>Generate \u2014 Write a structured markdown report with metadata, file table, change details, git status, and commit log</li> </ol> <p>The report is suitable for team reviews, handoff documentation, or personal session records.</p>"},{"location":"plugins/dev-tools/#release-python-package-release","title":"<code>/release</code> \u2014 Python Package Release","text":"<p>Automates Python package releases using <code>uv</code> and <code>ruff</code>. Handles version calculation, changelog updates, and tag creation. Runs on the Haiku model for speed.</p> <pre><code>/release              # Auto-calculate next version\n/release 1.2.0        # Specify version override\n</code></pre>"},{"location":"plugins/dev-tools/#supporting-skills-agent-loaded","title":"Supporting Skills (Agent-loaded)","text":"<p>These skills are not directly invoked \u2014 they're loaded by agents as reference knowledge:</p> Skill Purpose Used By <code>architecture-patterns</code> MVC, event-driven, microservices, CQRS pattern knowledge code-architect agent <code>code-quality</code> SOLID, DRY, testing strategies, review best practices code-reviewer agent, bug-killer (deep track) <code>changelog-format</code> Keep a Changelog specification and entry writing guidelines changelog-manager agent <code>project-learnings</code> Captures project-specific patterns and anti-patterns into CLAUDE.md bug-killer (Phase 5), feature-dev"},{"location":"plugins/dev-tools/#agents","title":"Agents","text":"Agent Model Tools Purpose code-reviewer Opus Read, Glob, Grep (read-only) Reviews code for correctness, security, maintainability with confidence scores bug-investigator Sonnet Read, Glob, Grep, Bash (read-only) Executes diagnostic investigation tasks to test debugging hypotheses changelog-manager Sonnet Bash, Read, Edit, Glob, Grep Analyzes git history and updates CHANGELOG.md docs-writer Opus Read, Glob, Grep, Bash Generates MkDocs or GitHub-flavored markdown documentation <p>Note: <code>code-architect</code> (Opus, read-only) has moved to Core Tools. Feature-dev spawns it cross-plugin using the qualified name <code>agent-alchemy-core-tools:code-architect</code>.</p> <p>Read-Only Enforcement</p> <p>The code-reviewer agent intentionally has no write tools. This enforces separation of concerns \u2014 reviewers audit but don't modify code directly. The code-architect agent (now in core-tools) follows the same pattern. Only the lead (feature-dev) applies changes.</p>"},{"location":"plugins/dev-tools/#composition-chains","title":"Composition Chains","text":"<pre><code>graph LR\n    FD[\"/feature-dev\"] --&gt; DA[\"deep-analysis\"]\n    DA --&gt; CE[\"code-explorer x N\"]\n    DA --&gt; CS[\"code-synthesizer x 1\"]\n    FD --&gt; CA[\"code-architect x 2-3&lt;br/&gt;(core-tools)\"]\n    FD --&gt; CR[\"code-reviewer x 3\"]\n    DM[\"/docs-manager\"] --&gt; DA\n    DM --&gt; DW[\"docs-writer x N\"]\n    BK[\"/bug-killer\"] --&gt; CE2[\"code-explorer x 2-3&lt;br/&gt;(core-tools)\"]\n    BK --&gt; BI[\"bug-investigator x 1-3\"]\n    BK --&gt; CQ[\"code-quality\"]\n    BK --&gt; PL[\"project-learnings\"]</code></pre>"},{"location":"plugins/git-tools/","title":"Git Tools","text":"<p>Version: 0.1.0 | Skills: 1 | Agents: 0</p> <p>Git Tools provides lightweight git automation \u2014 currently a single skill for conventional commit message generation.</p>"},{"location":"plugins/git-tools/#skills","title":"Skills","text":""},{"location":"plugins/git-tools/#git-commit-conventional-commit-automation","title":"<code>/git-commit</code> \u2014 Conventional Commit Automation","text":"<p>Analyzes staged changes and generates a Conventional Commits message. Runs on the Haiku model for fast, low-cost execution.</p> <pre><code>/git-commit           # Analyze staged changes and commit\n</code></pre> <p>Workflow:</p> <ol> <li>Check Repository State \u2014 Runs <code>git status --porcelain</code>. If clean, reports nothing to commit.</li> <li>Stage Changes \u2014 Stages all modified and untracked files (<code>git add -A</code>).</li> <li>Analyze Diff \u2014 Reads the staged diff to understand what changed.</li> <li> <p>Generate Message \u2014 Creates a conventional commit message following the format:</p> <pre><code>type(scope): description\n</code></pre> <p>Types: <code>feat</code>, <code>fix</code>, <code>docs</code>, <code>style</code>, <code>refactor</code>, <code>test</code>, <code>chore</code></p> </li> <li> <p>User Confirmation \u2014 Presents the message for approval via <code>AskUserQuestion</code>.</p> </li> <li>Commit \u2014 Executes <code>git commit</code> with the approved message.</li> </ol> <p>Model Choice</p> <p>Git-commit uses Haiku intentionally \u2014 commit message generation is a quick, focused task that doesn't need the reasoning power of Sonnet or Opus. This keeps the operation fast and cost-effective.</p>"},{"location":"plugins/plugin-tools/","title":"Plugin Tools","text":"<p>Plugin Tools provides lifecycle management for cross-platform plugin porting, adapter validation, incremental updates to ported plugins, and ecosystem health analysis. It uses an extensible adapter framework with real-time platform research and interactive workflows.</p> <p>Plugin: <code>agent-alchemy-plugin-tools</code> | Version: 0.1.1 | Skills: 5 | Agents: 2</p>"},{"location":"plugins/plugin-tools/#plugin-inventory","title":"Plugin Inventory","text":"Component Type Model Description <code>port-plugin</code> Skill -- Guided conversion wizard for porting plugins to target platforms <code>validate-adapter</code> Skill -- Validates adapter files against live platform documentation <code>update-ported-plugin</code> Skill -- Incremental updates when source plugins or target platforms change <code>dependency-checker</code> Skill -- Ecosystem health analysis with 7 detection passes and doc drift checks <code>bump-plugin-version</code> Skill -- Version bumping across all ecosystem files with drift detection and changelog <code>researcher</code> Agent Sonnet Investigates target platform plugin architectures via web search and documentation <code>port-converter</code> Agent Sonnet Converts a single plugin component to a target platform format"},{"location":"plugins/plugin-tools/#port-plugin-port-plugin","title":"Port Plugin (<code>/port-plugin</code>)","text":"<p>The flagship skill. A guided conversion wizard that ports Agent Alchemy plugins to target platforms using an extensible adapter framework. The adapter defines mapping rules between Claude Code's plugin format and the target platform's architecture.</p>"},{"location":"plugins/plugin-tools/#workflow-overview","title":"Workflow Overview","text":"<pre><code>flowchart TD\n    A[\"Phase 1: Configuration\"] --&gt; B[\"Phase 2: Selection Wizard\"]\n    B --&gt; C[\"Phase 3: Dependency Validation\"]\n    C --&gt; D[\"Phase 4: Platform Research\"]\n    D --&gt; E[\"Phase 4.5: Research Review\"]\n    E --&gt; F[\"Phase 5: Interactive Conversion\"]\n    F --&gt; G[\"Phase 6: Output &amp; Reporting\"]\n    G --&gt; H[\"Phase 7: Summary\"]\n\n    style D fill:#00bcd4,color:#fff\n    style F fill:#7c4dff,color:#fff</code></pre>"},{"location":"plugins/plugin-tools/#phase-details","title":"Phase Details","text":""},{"location":"plugins/plugin-tools/#phase-1-configuration","title":"Phase 1: Configuration","text":"<p>Parses arguments, loads settings, validates the target platform adapter, and loads the marketplace registry for plugin metadata.</p>"},{"location":"plugins/plugin-tools/#phase-2-selection-wizard","title":"Phase 2: Selection Wizard","text":"<p>Interactive component selection. Choose which plugin groups and individual components (skills, agents, hooks, references) to include in the conversion.</p>"},{"location":"plugins/plugin-tools/#phase-3-dependency-validation","title":"Phase 3: Dependency Validation","text":"<p>Builds a dependency graph of selected components, detects cross-plugin references, and alerts on missing dependencies that could cause the ported plugin to malfunction.</p>"},{"location":"plugins/plugin-tools/#phase-4-platform-research","title":"Phase 4: Platform Research","text":"<p>Spawns a <code>researcher</code> agent to investigate the target platform's latest plugin architecture using web search, documentation fetching, and Context7. Produces a structured platform profile.</p>"},{"location":"plugins/plugin-tools/#phase-45-research-review","title":"Phase 4.5: Research Review","text":"<p>Presents research findings for user review. The user can request additional research, clarify findings, or proceed with the conversion.</p>"},{"location":"plugins/plugin-tools/#phase-5-interactive-conversion","title":"Phase 5: Interactive Conversion","text":"<p>Converts components one at a time using the adapter framework. When incompatibilities are detected (features that don't map cleanly to the target platform), the workflow pauses for user decisions:</p> <ul> <li>Drop the feature</li> <li>Approximate with a workaround</li> <li>Defer for manual implementation</li> </ul>"},{"location":"plugins/plugin-tools/#phase-6-output-reporting","title":"Phase 6: Output &amp; Reporting","text":"<p>Writes converted files to the output directory, generates a <code>MIGRATION-GUIDE.md</code> with <code>PORT-METADATA</code> for future updates, and produces a gap report listing unsupported features.</p>"},{"location":"plugins/plugin-tools/#phase-7-summary","title":"Phase 7: Summary","text":"<p>Displays conversion results including fidelity scores (per-component and overall), file manifest, and recommended next steps.</p> <p>Adapter Framework</p> <p>The conversion engine is adapter-driven -- each target platform has a dedicated adapter file (<code>references/adapters/{platform}.md</code>) that defines 9 mapping sections: skills, agents, hooks, references, MCP configs, manifest format, directory structure, naming conventions, and feature parity. Adding a new target platform means adding a new adapter file.</p>"},{"location":"plugins/plugin-tools/#validate-adapter-validate-adapter","title":"Validate Adapter (<code>/validate-adapter</code>)","text":"<p>Validates adapter files against live platform documentation to detect stale mappings, missing features, and outdated version information. Can optionally apply updates in-place.</p>"},{"location":"plugins/plugin-tools/#four-phase-workflow","title":"Four-Phase Workflow","text":"<pre><code>flowchart LR\n    A[\"Load &amp; Parse\"] --&gt; B[\"Platform Research\"]\n    B --&gt; C[\"Compare &amp; Analyze\"]\n    C --&gt; D[\"Report &amp; Apply\"]\n\n    style B fill:#00bcd4,color:#fff</code></pre> <ol> <li>Load &amp; Parse -- Reads the adapter file, extracts all 9 mapping sections, and displays a summary of current content.</li> <li>Platform Research -- Spawns a <code>researcher</code> agent to fetch the target platform's latest documentation and compare against the adapter's claims.</li> <li> <p>Compare &amp; Analyze -- Diffs each section against research findings. Classifies each mapping as:</p> Status Meaning Current Mapping matches live docs Stale Mapping exists but is outdated Missing Feature exists on platform but not in adapter Removed Feature in adapter but removed from platform Uncertain Could not verify (research inconclusive) </li> <li> <p>Report &amp; Apply -- Presents a validation report with section-by-section findings. Optionally applies updates to the adapter file with user confirmation.</p> </li> </ol>"},{"location":"plugins/plugin-tools/#update-ported-plugin-update-ported-plugin","title":"Update Ported Plugin (<code>/update-ported-plugin</code>)","text":"<p>Updates previously-ported plugins when the source Agent Alchemy plugin changes or the target platform evolves. Uses dual-track change detection to identify what needs updating.</p>"},{"location":"plugins/plugin-tools/#five-phase-workflow","title":"Five-Phase Workflow","text":"<pre><code>flowchart LR\n    A[\"Load Context\"] --&gt; B[\"Detect Changes\"]\n    B --&gt; C[\"Apply Source Changes\"]\n    C --&gt; D[\"Apply Platform Changes\"]\n    D --&gt; E[\"Output &amp; Refresh\"]\n\n    style B fill:#f44336,color:#fff\n    style C fill:#7c4dff,color:#fff\n    style D fill:#00bcd4,color:#fff</code></pre> <ol> <li>Load Context -- Parses <code>MIGRATION-GUIDE.md</code> PORT-METADATA from the previous port, locates ported files, and validates metadata integrity.</li> <li>Detect Changes -- Dual-track detection:<ul> <li>Source track: Git diff between the original commit hash (from PORT-METADATA) and HEAD to find modified, added, or deleted components</li> <li>Platform track: Runs <code>validate-adapter</code> (phases 1-3) to detect stale or missing platform mappings</li> </ul> </li> <li>Apply Source Changes -- Re-converts modified components using the adapter framework. Handles new components (added since last port) and deleted components (removes ported equivalents).</li> <li>Apply Platform Changes -- Updates ported files to reflect stale adapter mappings and applies additive features newly available on the target platform.</li> <li>Output &amp; Refresh -- Writes updated files, refreshes PORT-METADATA with new commit hash and timestamp, and updates the gap report.</li> </ol>"},{"location":"plugins/plugin-tools/#dependency-checker-dependency-checker","title":"Dependency Checker (<code>/dependency-checker</code>)","text":"<p>Analyzes the entire Agent Alchemy plugin ecosystem to detect dependency issues, structural problems, and documentation drift. Reads all plugin groups and produces an interactive findings report.</p>"},{"location":"plugins/plugin-tools/#five-phase-workflow_1","title":"Five-Phase Workflow","text":"<pre><code>flowchart LR\n    A[\"Load &amp; Discover\"] --&gt; B[\"Build Graph\"]\n    B --&gt; C[\"Analyze\"]\n    C --&gt; D[\"Cross-Ref Docs\"]\n    D --&gt; E[\"Report\"]\n\n    style C fill:#f44336,color:#fff\n    style D fill:#ff9800,color:#fff</code></pre> <ol> <li>Load &amp; Discover -- Parses arguments, loads settings, enumerates all skills, agents, references, and hooks across every plugin group.</li> <li>Build Dependency Graph -- Extracts dependency edges from path patterns (<code>${CLAUDE_PLUGIN_ROOT}</code>), agent spawning declarations, skill bindings, and hook scripts.</li> <li> <p>Analyze -- Runs 7 detection passes:</p> Pass Detects 1 Circular dependencies 2 Missing dependencies (referenced but not found) 3 Broken paths (invalid <code>${CLAUDE_PLUGIN_ROOT}</code> references) 4 Orphaned components (defined but never referenced) 5 Agent-skill mismatches (agents referencing non-existent skills) 6 Marketplace inconsistencies (plugin.json vs actual components) 7 Hook integrity (hook scripts referencing missing files) </li> <li> <p>Cross-Reference Documentation -- Compares the dependency graph against <code>CLAUDE.md</code> and <code>README.md</code> files to detect inventory drift, composition chain drift, and line count drift.</p> </li> <li>Report -- Interactive findings browser with severity grouping, plugin filtering, graph visualization, and optional markdown export.</li> </ol>"},{"location":"plugins/plugin-tools/#configuration","title":"Configuration","text":"<p>All settings are under the <code>plugin-tools.dependency-checker</code> key in <code>.claude/agent-alchemy.local.md</code>:</p> Setting Default Options Description <code>severity-threshold</code> <code>low</code> <code>critical</code>, <code>high</code>, <code>medium</code>, <code>low</code> Minimum severity level to include in report <code>check-docs-drift</code> <code>true</code> <code>true</code>, <code>false</code> Run Phase 4 documentation cross-referencing <code>line-count-tolerance</code> <code>10</code> <code>0</code>-<code>100</code> Percentage tolerance for line count drift detection"},{"location":"plugins/plugin-tools/#bump-plugin-version-bump-plugin-version","title":"Bump Plugin Version (<code>/bump-plugin-version</code>)","text":"<p>Automates version bumping across all ecosystem files. Scans 5 version locations per plugin for drift, applies consistent updates, generates a CHANGELOG entry, and creates a conventional commit.</p>"},{"location":"plugins/plugin-tools/#six-phase-workflow","title":"Six-Phase Workflow","text":"<pre><code>flowchart LR\n    A[\"Discovery\"] --&gt; B[\"Drift Check\"]\n    B --&gt; C[\"Selection\"]\n    C --&gt; D[\"Bump\"]\n    D --&gt; E[\"Changelog\"]\n    E --&gt; F[\"Commit\"]\n\n    style B fill:#ff9800,color:#fff\n    style D fill:#7c4dff,color:#fff</code></pre> <ol> <li>Discovery -- Reads <code>marketplace.json</code> and builds a plugin inventory with current versions.</li> <li>Drift Check -- Scans all 5 version locations for inconsistencies against the marketplace registry. Offers to fix, skip, or abort on drift.</li> <li>Selection -- Multi-select plugins to bump and choose bump level (patch/minor/major). Computes new versions and displays a bump plan. Supports <code>--dry-run</code> to stop here.</li> <li>Bump -- Edits all 5 locations per plugin: marketplace.json, root CLAUDE.md, docs/index.md, docs/plugins/index.md, and per-plugin doc files.</li> <li>Changelog -- Adds grouped entries under <code>## [Unreleased]</code> in CHANGELOG.md.</li> <li>Commit -- Stages only modified files and creates a conventional commit (<code>chore(marketplace): bump ...</code>).</li> </ol>"},{"location":"plugins/plugin-tools/#agents","title":"Agents","text":""},{"location":"plugins/plugin-tools/#researcher-sonnet","title":"researcher (Sonnet)","text":"<p>A platform research specialist that investigates target platform plugin architectures. Spawned by <code>port-plugin</code>, <code>validate-adapter</code>, and <code>update-ported-plugin</code> to gather live documentation.</p> <p>Key characteristics:</p> <ul> <li>Model: Sonnet (parallelizable research tasks)</li> <li>Tools: WebSearch, WebFetch, Read, Glob, Grep, Context7</li> <li>Produces structured platform profiles with section-by-section findings</li> <li>Used by three of the five skills in this plugin</li> </ul>"},{"location":"plugins/plugin-tools/#port-converter-sonnet","title":"port-converter (Sonnet)","text":"<p>A component conversion specialist that transforms a single Claude Code plugin component to a target platform format. Spawned by <code>port-plugin</code> as part of a wave-based conversion team \u2014 multiple converters run in parallel for independent components.</p> <p>Key characteristics:</p> <ul> <li>Model: Sonnet (parallelizable conversion tasks)</li> <li>Tools: Read, Glob, Grep, Write</li> <li>Reads shared session files (<code>conversion_knowledge.md</code>, <code>resolution_cache.md</code>, <code>dependency_graph.md</code>) for conversion context</li> <li>Loads type-specific converter references on demand (agent-converter, hook-converter, reference-converter, mcp-converter)</li> <li>Handles 5 component types: skills, agents, hooks, references, and MCP configs</li> <li>Detects incompatibilities and classifies them by severity (critical, functional, cosmetic)</li> <li>Calculates per-component fidelity scores with a weighted formula</li> <li>Works autonomously \u2014 defers user decisions to the orchestrator via inline markers</li> </ul>"},{"location":"plugins/plugin-tools/#shared-references","title":"Shared References","text":"<p>Plugin Tools uses a shared <code>references/</code> directory containing the adapter framework and converter logic. These files are loaded by skills on demand during conversion workflows.</p> File Description <code>adapter-format.md</code> Adapter file format specification (9 mapping sections) <code>agent-converter.md</code> Agent conversion logic (frontmatter mapping, body transformation) <code>hook-converter.md</code> Hook conversion logic (event mapping, behavioral classification) <code>reference-converter.md</code> Reference file conversion logic (discovery, path transformation) <code>mcp-converter.md</code> MCP config conversion logic (server mapping, transport types) <code>incompatibility-resolver.md</code> Incompatibility detection, interactive resolution, decision tracking <code>adapters/</code> Per-platform adapter files (one markdown file per target platform) <p>MVP Target</p> <p>The initial release targets OpenCode as the first supported conversion target. The adapter framework is designed to support additional platforms by adding new adapter files to <code>references/adapters/</code>.</p>"},{"location":"plugins/plugin-tools/#directory-structure","title":"Directory Structure","text":"<pre><code>plugin-tools/\n\u251c\u2500\u2500 .claude-plugin/\n\u2502   \u2514\u2500\u2500 plugin.json             # Plugin manifest\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 port-converter.md       # Component conversion agent\n\u2502   \u2514\u2500\u2500 researcher.md           # Platform research agent\n\u251c\u2500\u2500 references/                 # Shared reference files\n\u2502   \u251c\u2500\u2500 adapter-format.md\n\u2502   \u251c\u2500\u2500 agent-converter.md\n\u2502   \u251c\u2500\u2500 hook-converter.md\n\u2502   \u251c\u2500\u2500 incompatibility-resolver.md\n\u2502   \u251c\u2500\u2500 mcp-converter.md\n\u2502   \u251c\u2500\u2500 reference-converter.md\n\u2502   \u2514\u2500\u2500 adapters/\n\u2502       \u2514\u2500\u2500 opencode.md         # OpenCode platform adapter\n\u251c\u2500\u2500 skills/\n\u2502   \u251c\u2500\u2500 port-plugin/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md            # Conversion wizard (~2,750 lines)\n\u2502   \u251c\u2500\u2500 validate-adapter/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md            # Adapter validation (~625 lines)\n\u2502   \u251c\u2500\u2500 update-ported-plugin/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md            # Incremental updater (~800 lines)\n\u2502   \u251c\u2500\u2500 dependency-checker/\n\u2502   \u2502   \u2514\u2500\u2500 SKILL.md            # Ecosystem health analyzer (~650 lines)\n\u2502   \u2514\u2500\u2500 bump-plugin-version/\n\u2502       \u2514\u2500\u2500 SKILL.md            # Version bumper (~380 lines)\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/","title":"SDD Tools Deep Dive","text":"<p>A comprehensive walkthrough of the Spec-Driven Development pipeline \u2014 from adaptive interview through wave-based autonomous execution. This deep dive covers internal architecture, data flow patterns, execution context sharing, and end-to-end workflow examples that go beyond the SDD Tools reference page.</p> <p>Plugin: <code>agent-alchemy-sdd-tools</code> | Version: 0.2.0 | Skills: 4 | Agents: 4</p>"},{"location":"plugins/sdd-tools-deep-dive/#executive-summary","title":"Executive Summary","text":"<p>The sdd-tools plugin implements a complete Spec-Driven Development (SDD) pipeline for Claude Code. It transforms the development process from ad-hoc prompting into a structured workflow: idea \u2192 spec \u2192 tasks \u2192 execution. The plugin is fully standalone (no external plugin dependencies) and provides 4 skills, 4 agents, and a lifecycle hook, enabling developers to go from a product idea to working code through an automated, verification-driven pipeline.</p>"},{"location":"plugins/sdd-tools-deep-dive/#what-is-spec-driven-development","title":"What is Spec-Driven Development?","text":"<p>Spec-Driven Development is a methodology where:</p> <ol> <li>Requirements are captured formally before any code is written</li> <li>Specifications are structured documents with testable acceptance criteria</li> <li>Tasks are derived algorithmically from specs, with automatic dependency inference</li> <li>Implementation is verified against spec-defined acceptance criteria</li> <li>The spec is the single source of truth throughout the development lifecycle</li> </ol> <p>This contrasts with the typical AI-assisted development pattern where users describe features in natural language and the AI generates code directly \u2014 often losing requirements, skipping edge cases, and producing code that's hard to verify.</p> <pre><code>graph LR\n    A[\"\ud83d\udca1 Idea\"] --&gt; B[\"\ud83d\udccb Spec\"]\n    B --&gt; C[\"\ud83d\udd0d Analysis\"]\n    C --&gt; D[\"\u2705 Tasks\"]\n    D --&gt; E[\"\u26a1 Execution\"]\n    E --&gt; F[\"\u2714\ufe0f Verified Code\"]\n\n    style A fill:#7c4dff,color:#fff\n    style B fill:#7c4dff,color:#fff\n    style C fill:#f44336,color:#fff\n    style D fill:#4caf50,color:#fff\n    style E fill:#ff9800,color:#fff\n    style F fill:#00bcd4,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#plugin-architecture","title":"Plugin Architecture","text":""},{"location":"plugins/sdd-tools-deep-dive/#directory-structure","title":"Directory Structure","text":"<pre><code>sdd-tools/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 codebase-explorer.md    # Codebase exploration (Sonnet)\n\u2502   \u251c\u2500\u2500 researcher.md           # External research (Opus)\n\u2502   \u251c\u2500\u2500 spec-analyzer.md        # Spec quality analysis (Opus)\n\u2502   \u2514\u2500\u2500 task-executor.md        # Task implementation (Opus)\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 hooks.json              # PreToolUse hook configuration\n\u2502   \u2514\u2500\u2500 auto-approve-session.sh # Session directory auto-approve\n\u251c\u2500\u2500 skills/\n\u2502   \u251c\u2500\u2500 create-spec/\n\u2502   \u2502   \u251c\u2500\u2500 SKILL.md            # Interview workflow (660 lines)\n\u2502   \u2502   \u2514\u2500\u2500 references/\n\u2502   \u2502       \u251c\u2500\u2500 codebase-exploration.md\n\u2502   \u2502       \u251c\u2500\u2500 interview-questions.md\n\u2502   \u2502       \u251c\u2500\u2500 recommendation-triggers.md\n\u2502   \u2502       \u251c\u2500\u2500 recommendation-format.md\n\u2502   \u2502       \u2514\u2500\u2500 templates/\n\u2502   \u2502           \u251c\u2500\u2500 high-level.md\n\u2502   \u2502           \u251c\u2500\u2500 detailed.md\n\u2502   \u2502           \u2514\u2500\u2500 full-tech.md\n\u2502   \u251c\u2500\u2500 analyze-spec/\n\u2502   \u2502   \u251c\u2500\u2500 SKILL.md            # Analysis workflow\n\u2502   \u2502   \u251c\u2500\u2500 references/\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 analysis-criteria.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 common-issues.md\n\u2502   \u2502   \u2502   \u251c\u2500\u2500 html-review-guide.md\n\u2502   \u2502   \u2502   \u2514\u2500\u2500 report-template.md\n\u2502   \u2502   \u2514\u2500\u2500 templates/\n\u2502   \u2502       \u2514\u2500\u2500 review-template.html\n\u2502   \u251c\u2500\u2500 create-tasks/\n\u2502   \u2502   \u251c\u2500\u2500 SKILL.md            # Task decomposition (653 lines)\n\u2502   \u2502   \u2514\u2500\u2500 references/\n\u2502   \u2502       \u251c\u2500\u2500 decomposition-patterns.md\n\u2502   \u2502       \u251c\u2500\u2500 dependency-inference.md\n\u2502   \u2502       \u2514\u2500\u2500 testing-requirements.md\n\u2502   \u2514\u2500\u2500 execute-tasks/\n\u2502       \u251c\u2500\u2500 SKILL.md            # Execution orchestrator (262 lines)\n\u2502       \u251c\u2500\u2500 references/\n\u2502       \u2502   \u251c\u2500\u2500 execution-workflow.md\n\u2502       \u2502   \u251c\u2500\u2500 orchestration.md\n\u2502       \u2502   \u2514\u2500\u2500 verification-patterns.md\n\u2502       \u2514\u2500\u2500 scripts/\n\u2502           \u2514\u2500\u2500 poll-for-results.sh\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#component-summary","title":"Component Summary","text":"Component Count Description Skills 4 create-spec, analyze-spec, create-tasks, execute-tasks Agents 4 codebase-explorer, researcher, spec-analyzer, task-executor Hooks 1 auto-approve-session (PreToolUse) Reference files 14 Question banks, templates, criteria, patterns Spec templates 3 High-level, detailed, full-tech"},{"location":"plugins/sdd-tools-deep-dive/#the-sdd-pipeline","title":"The SDD Pipeline","text":"<p>The complete SDD pipeline flows through four skills in sequence. Each skill produces artifacts that feed into the next.</p> <pre><code>flowchart TD\n    subgraph Phase1[\"Phase 1: Specification\"]\n        CS[\"/create-spec\"]\n        CS --&gt;|\"writes\"| SPEC[\"specs/SPEC-{name}.md\"]\n    end\n\n    subgraph Phase2[\"Phase 2: Quality Gate\"]\n        AS[\"/analyze-spec\"]\n        SPEC --&gt;|\"reads\"| AS\n        AS --&gt;|\"writes\"| REPORT[\"specs/{name}.analysis.md\"]\n        AS --&gt;|\"writes\"| HTML[\"specs/{name}.analysis.html\"]\n        AS --&gt;|\"may update\"| SPEC\n    end\n\n    subgraph Phase3[\"Phase 3: Decomposition\"]\n        CT[\"/create-tasks\"]\n        SPEC --&gt;|\"reads\"| CT\n        CT --&gt;|\"creates\"| TASKS[\"~/.claude/tasks/{list}/*.json\"]\n    end\n\n    subgraph Phase4[\"Phase 4: Execution\"]\n        ET[\"/execute-tasks\"]\n        TASKS --&gt;|\"reads\"| ET\n        ET --&gt;|\"spawns\"| AGENTS[\"task-executor agents \u00d7 N\"]\n        AGENTS --&gt;|\"writes\"| CODE[\"Implementation + Tests\"]\n        AGENTS --&gt;|\"writes\"| CTX[\".claude/sessions/__live_session__/\"]\n        ET --&gt;|\"updates\"| TASKS\n    end\n\n    subgraph External[\"External: Real-Time Monitoring\"]\n        TASKS --&gt;|\"watched by\"| TM[\"Task Manager Dashboard\"]\n    end\n\n    style CS fill:#7c4dff,color:#fff\n    style SPEC fill:#00bcd4,color:#fff\n    style AS fill:#7c4dff,color:#fff\n    style REPORT fill:#00bcd4,color:#fff\n    style HTML fill:#00bcd4,color:#fff\n    style CT fill:#7c4dff,color:#fff\n    style TASKS fill:#00bcd4,color:#fff\n    style ET fill:#7c4dff,color:#fff\n    style AGENTS fill:#ff9800,color:#fff\n    style CODE fill:#4caf50,color:#fff\n    style CTX fill:#4caf50,color:#fff\n    style TM fill:#00bcd4,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#pipeline-artifacts","title":"Pipeline Artifacts","text":"Phase Input Output Format create-spec User interview answers <code>specs/SPEC-{name}.md</code> Structured markdown PRD analyze-spec Spec file <code>.analysis.md</code> + <code>.analysis.html</code> Report + interactive HTML create-tasks Spec file Task JSON files Claude Code native tasks execute-tasks Task list Code changes + session artifacts Source code + execution logs"},{"location":"plugins/sdd-tools-deep-dive/#skill-1-create-spec-adaptive-interview","title":"Skill 1: create-spec -- Adaptive Interview","text":""},{"location":"plugins/sdd-tools-deep-dive/#purpose","title":"Purpose","text":"<p>Transforms a product idea into a structured specification through an adaptive, multi-round interview process. The skill adjusts its questioning depth, provides proactive recommendations, and can explore the existing codebase for context.</p>"},{"location":"plugins/sdd-tools-deep-dive/#workflow-6-phases","title":"Workflow (6 Phases)","text":"<pre><code>flowchart TD\n    P1[\"Phase 1: Settings Check\"] --&gt; P2[\"Phase 2: Initial Inputs\"]\n    P2 --&gt; |\"Name, Type, Depth, Description\"| P3[\"Phase 3: Adaptive Interview\"]\n\n    P3 --&gt; |\"For 'new feature' type\"| CE[\"Codebase Exploration\"]\n    CE --&gt; |\"findings\"| P3\n\n    P3 --&gt; |\"Trigger detected\"| RES[\"External Research\"]\n    RES --&gt; |\"findings\"| P3\n\n    P3 --&gt; |\"2-5 rounds\"| P4[\"Phase 4: Recommendations Round\"]\n    P4 --&gt; P5[\"Phase 5: Pre-Compilation Summary\"]\n    P5 --&gt; |\"User confirms\"| P6[\"Phase 6: Spec Compilation\"]\n    P6 --&gt; SPEC[\"specs/SPEC-{name}.md\"]\n\n    style P3 fill:#7c4dff,color:#fff\n    style CE fill:#ff9800,color:#fff\n    style RES fill:#7c4dff,color:#fff\n    style SPEC fill:#4caf50,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#depth-levels","title":"Depth Levels","text":"<p>The interview adapts based on the requested depth level:</p> Level Rounds Questions Focus Output High-level overview 2-3 6-10 Problem, goals, key features, success metrics Executive summary Detailed specifications 3-4 12-18 Balanced coverage, acceptance criteria, technical constraints Standard PRD Full technical documentation 4-5 18-25 Deep probing, API endpoints, data models, performance Comprehensive tech spec"},{"location":"plugins/sdd-tools-deep-dive/#question-categories","title":"Question Categories","text":"<p>Each interview round covers four categories (depth-adjusted):</p> <ol> <li>Problem &amp; Goals -- Problem statement, success metrics, user personas, business value</li> <li>Functional Requirements -- Features, user stories, acceptance criteria, workflows</li> <li>Technical Specs -- Architecture, tech stack, data models, APIs, constraints</li> <li>Implementation -- Phases, dependencies, risks, out-of-scope items</li> </ol>"},{"location":"plugins/sdd-tools-deep-dive/#proactive-features","title":"Proactive Features","text":"<ul> <li>Recommendation triggers: Scans user responses for patterns that suggest best-practice recommendations (e.g., mentioning \"auth\" triggers authentication pattern suggestions)</li> <li>External research: Can invoke the <code>researcher</code> agent for technical documentation, competitive analysis, or compliance requirements</li> <li>Codebase exploration: For \"new feature\" type specs, spawns <code>codebase-explorer</code> agents (Sonnet) in parallel to discover existing architecture, patterns, and integration points</li> <li>Early exit support: Users can wrap up early; spec is marked as <code>Draft (Partial)</code></li> </ul> <p>Recommendation Triggers</p> <p>The interview skill monitors user responses for keyword patterns (e.g., \"authentication\", \"scale\", \"real-time\", \"compliance\") and proactively surfaces best-practice recommendations. This bridges the gap between user intent and implementation knowledge.</p>"},{"location":"plugins/sdd-tools-deep-dive/#spec-templates","title":"Spec Templates","text":"<p>Three templates matched to depth levels:</p> Template File Use Case High-level <code>references/templates/high-level.md</code> Executive summaries, stakeholder alignment Detailed <code>references/templates/detailed.md</code> Standard development specs Full-tech <code>references/templates/full-tech.md</code> API specs, data models, architecture"},{"location":"plugins/sdd-tools-deep-dive/#skill-2-analyze-spec-quality-gate","title":"Skill 2: analyze-spec -- Quality Gate","text":""},{"location":"plugins/sdd-tools-deep-dive/#purpose_1","title":"Purpose","text":"<p>Performs systematic quality analysis on an existing spec, identifying inconsistencies, missing information, ambiguities, and structure issues. Provides both a markdown report and an interactive HTML review interface.</p>"},{"location":"plugins/sdd-tools-deep-dive/#analysis-categories","title":"Analysis Categories","text":"Category What It Catches Example Inconsistencies Internal contradictions Feature named \"Search\" in one section, \"Find\" in another Missing Information Expected content absent for depth level Full-tech spec with no API definitions Ambiguities Vague or multi-interpretable statements \"Users should be able to search quickly\" Structure Issues Formatting and organization problems Missing required sections, orphaned references"},{"location":"plugins/sdd-tools-deep-dive/#severity-levels","title":"Severity Levels","text":"Severity Definition Example Critical Would cause implementation failure Circular dependencies, undefined core requirements Warning Could cause confusion or problems Vague acceptance criteria, unnamed dependencies Suggestion Quality improvement, not blocking Inconsistent formatting, missing glossary"},{"location":"plugins/sdd-tools-deep-dive/#output-formats","title":"Output Formats","text":"<ol> <li>Markdown report (<code>{name}.analysis.md</code>) -- Structured findings with severity, location, and recommendations</li> <li>Interactive HTML review (<code>{name}.analysis.html</code>) -- Browser-based UI for approving/rejecting findings with copy-prompt workflow</li> </ol>"},{"location":"plugins/sdd-tools-deep-dive/#review-modes","title":"Review Modes","text":"<pre><code>flowchart TD\n    A[\"Spec Analyzed\"] --&gt; B{\"Choose Review Mode\"}\n    B --&gt; C[\"Interactive HTML Review\"]\n    B --&gt; D[\"CLI Update Mode\"]\n    B --&gt; E[\"Reports Only\"]\n\n    C --&gt; F[\"Open in Browser\"]\n    F --&gt; G[\"Approve/Reject Findings\"]\n    G --&gt; H[\"Copy Prompt\"]\n    H --&gt; I[\"Paste Back \u2192 Apply Changes\"]\n\n    D --&gt; J[\"Walk Through Each Finding\"]\n    J --&gt; K{\"Apply / Modify / Skip\"}\n    K --&gt; |\"Apply\"| L[\"Edit spec directly\"]\n    K --&gt; |\"Modify\"| M[\"User provides text \u2192 Edit\"]\n    K --&gt; |\"Skip\"| N[\"Record reason, move on\"]\n\n    E --&gt; O[\"Keep reports as-is\"]\n\n    style C fill:#7c4dff,color:#fff\n    style D fill:#ff9800,color:#fff\n    style E fill:#455a64,color:#fff</code></pre> <p>Depth-Aware Analysis</p> <p>The analyzer detects the spec's depth level (high-level, detailed, or full-tech) and only flags issues appropriate to that level. A high-level spec is never penalized for missing API specifications.</p>"},{"location":"plugins/sdd-tools-deep-dive/#skill-3-create-tasks-spec-decomposition","title":"Skill 3: create-tasks -- Spec Decomposition","text":""},{"location":"plugins/sdd-tools-deep-dive/#purpose_2","title":"Purpose","text":"<p>Transforms a specification into a dependency-ordered set of Claude Code native Tasks, each with categorized acceptance criteria, testing requirements, and metadata for tracking.</p>"},{"location":"plugins/sdd-tools-deep-dive/#workflow-8-phases","title":"Workflow (8 Phases)","text":"<pre><code>flowchart TD\n    P1[\"Phase 1: Validate &amp; Load\"] --&gt; P2[\"Phase 2: Detect Depth &amp; Check Existing\"]\n    P2 --&gt; P3[\"Phase 3: Analyze Spec\"]\n    P3 --&gt; P4[\"Phase 4: Decompose Tasks\"]\n    P4 --&gt; P5[\"Phase 5: Infer Dependencies\"]\n    P5 --&gt; P6[\"Phase 6: Preview &amp; Confirm\"]\n    P6 --&gt; |\"User approves\"| P7{\"Existing tasks?\"}\n    P7 --&gt; |\"No\"| P7A[\"Phase 7a: Fresh Create\"]\n    P7 --&gt; |\"Yes\"| P7B[\"Phase 7b: Merge Mode\"]\n    P7A --&gt; P8[\"Phase 8: Report\"]\n    P7B --&gt; P8\n\n    style P4 fill:#7c4dff,color:#fff\n    style P5 fill:#ff9800,color:#fff\n    style P7B fill:#f44336,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#task-decomposition-pattern","title":"Task Decomposition Pattern","text":"<p>Each feature is decomposed using a standard layer pattern:</p> <pre><code>flowchart TD\n    F[\"Feature from Spec\"] --&gt; DM[\"1. Data Model Tasks\"]\n    F --&gt; API[\"2. API/Service Tasks\"]\n    F --&gt; BL[\"3. Business Logic Tasks\"]\n    F --&gt; UI[\"4. UI/Frontend Tasks\"]\n    F --&gt; TEST[\"5. Test Tasks\"]\n\n    DM --&gt; |\"blocks\"| API\n    API --&gt; |\"blocks\"| UI\n    BL --&gt; |\"blocks\"| TEST\n\n    style DM fill:#4caf50,color:#fff\n    style API fill:#7c4dff,color:#fff\n    style BL fill:#ff9800,color:#fff\n    style UI fill:#f44336,color:#fff\n    style TEST fill:#00bcd4,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#depth-based-granularity","title":"Depth-Based Granularity","text":"Spec Depth Tasks per Feature Granularity Example High-level 1-2 Feature-level \"Implement user authentication\" Detailed 3-5 Functional decomposition \"Implement login endpoint\", \"Add password validation\" Full-tech 5-10 Technical decomposition \"Create User model\", \"Implement POST /auth/login\", \"Add auth middleware\""},{"location":"plugins/sdd-tools-deep-dive/#task-structure","title":"Task Structure","text":"<p>Each generated task includes:</p> <pre><code>subject: \"Create User data model\"              # Imperative mood\ndescription: |\n  {What needs to be done}\n\n  **Acceptance Criteria:**\n\n  _Functional:_\n  - [ ] Core behavior criteria\n\n  _Edge Cases:_\n  - [ ] Boundary condition criteria\n\n  _Error Handling:_\n  - [ ] Error scenario criteria\n\n  _Performance:_ (if applicable)\n  - [ ] Performance target criteria\n\n  **Testing Requirements:**\n  - Unit: Schema validation\n  - Integration: Database persistence\n\n  Source: specs/SPEC-Auth.md Section 7.3\nactiveForm: \"Creating User data model\"\nmetadata:\n  priority: critical|high|medium|low\n  complexity: XS|S|M|L|XL\n  spec_path: \"specs/SPEC-Auth.md\"\n  feature_name: \"User Authentication\"\n  task_uid: \"specs/SPEC-Auth.md:user-auth:model:001\"\n  task_group: \"user-authentication\"\n</code></pre> <p>task_group is Required</p> <p>The <code>task_group</code> field must be set on every task. The <code>/execute-tasks</code> skill relies on <code>metadata.task_group</code> for <code>--task-group</code> filtering and session ID generation. Tasks without <code>task_group</code> will be invisible to group-filtered execution runs.</p>"},{"location":"plugins/sdd-tools-deep-dive/#merge-mode","title":"Merge Mode","text":"<p>When re-running on an updated spec, tasks are intelligently merged:</p> <pre><code>flowchart TD\n    RE[\"Re-run /create-tasks\"] --&gt; MATCH{\"Match by task_uid\"}\n    MATCH --&gt; |\"Match found\"| STATUS{\"Task status?\"}\n    STATUS --&gt; |\"completed\"| PRESERVE[\"Preserve \u2014 never modify\"]\n    STATUS --&gt; |\"in_progress\"| SKIP[\"Preserve status, optionally update description\"]\n    STATUS --&gt; |\"pending\"| UPDATE[\"Update description if changed\"]\n    MATCH --&gt; |\"No match (new)\"| CREATE[\"Create new task\"]\n    MATCH --&gt; |\"No match (existing)\"| OBSOLETE{\"Potentially obsolete\"}\n    OBSOLETE --&gt; KEEP[\"Keep if user confirms\"]\n    OBSOLETE --&gt; MARK[\"Mark completed if user confirms\"]\n\n    style PRESERVE fill:#4caf50,color:#fff\n    style SKIP fill:#ff9800,color:#fff\n    style UPDATE fill:#7c4dff,color:#fff\n    style CREATE fill:#1565c0,color:#fff\n    style OBSOLETE fill:#f44336,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#dependency-inference","title":"Dependency Inference","text":"<p>Dependencies are automatically inferred from three sources:</p> <ol> <li>Layer dependencies: Data Model \u2192 API \u2192 UI \u2192 Tests</li> <li>Phase dependencies: Phase 2 tasks blocked by Phase 1 completion</li> <li>Explicit spec dependencies: Section 10 of spec (\"requires X\" \u2192 blockedBy X)</li> <li>Cross-feature dependencies: Shared data models, services, auth</li> </ol> <p>Circular Dependency Handling</p> <p>If a circular dependency is detected during task creation, the system breaks the cycle at the weakest link (scored by relationship type) and flags the affected task with <code>needs_review: true</code> in metadata. See the SDD Tools reference for the full inference rules.</p>"},{"location":"plugins/sdd-tools-deep-dive/#skill-4-execute-tasks-autonomous-execution","title":"Skill 4: execute-tasks -- Autonomous Execution","text":""},{"location":"plugins/sdd-tools-deep-dive/#purpose_3","title":"Purpose","text":"<p>Orchestrates autonomous task execution with wave-based parallelism, session management, shared execution context, and adaptive verification. After user confirmation, it runs without further interaction until all tasks are complete.</p>"},{"location":"plugins/sdd-tools-deep-dive/#core-principles","title":"Core Principles","text":"<ol> <li>Understand before implementing -- Read context, conventions, and earlier task learnings</li> <li>Follow existing patterns -- Match the codebase's coding style and conventions</li> <li>Verify against criteria -- Walk through each acceptance criterion, run tests</li> <li>Report honestly -- PASS only when all Functional criteria and tests pass</li> </ol>"},{"location":"plugins/sdd-tools-deep-dive/#orchestration-loop-10-steps","title":"Orchestration Loop (10 Steps)","text":"<pre><code>flowchart TD\n    S1[\"Step 1: Load Task List\"] --&gt; S2[\"Step 2: Validate State\"]\n    S2 --&gt; S3[\"Step 3: Build Execution Plan\"]\n    S3 --&gt; S4[\"Step 4: Check Settings\"]\n    S4 --&gt; S5[\"Step 5: Initialize Session\"]\n    S5 --&gt; S6[\"Step 6: Present Plan &amp; Confirm\"]\n    S6 --&gt; |\"User confirms\"| S7[\"Step 7: Initialize Context\"]\n    S7 --&gt; S8[\"Step 8: Execute Loop\"]\n    S8 --&gt; S9[\"Step 9: Session Summary\"]\n    S9 --&gt; S10[\"Step 10: Update CLAUDE.md\"]\n\n    subgraph ExecuteLoop[\"Step 8: Wave Execution Loop\"]\n        W1[\"Snapshot execution_context.md\"] --&gt; W2[\"Mark tasks in_progress\"]\n        W2 --&gt; W3[\"Launch N background agents\"]\n        W3 --&gt; W4[\"Poll for result files\"]\n        W4 --&gt; W5{\"All complete?\"}\n        W5 --&gt; |\"No\"| W4\n        W5 --&gt; |\"Yes\"| W6[\"Batch-read results\"]\n        W6 --&gt; W7[\"Reap agents via TaskOutput\"]\n        W7 --&gt; W8{\"Failed tasks with retries?\"}\n        W8 --&gt; |\"Yes\"| W9[\"Re-launch as background agents\"]\n        W9 --&gt; W4\n        W8 --&gt; |\"No\"| W10[\"Merge context files\"]\n        W10 --&gt; W11[\"Refresh TaskList\"]\n        W11 --&gt; W12{\"More waves?\"}\n        W12 --&gt; |\"Yes\"| W1\n        W12 --&gt; |\"No\"| DONE[\"Exit loop\"]\n    end\n\n    S8 --&gt; ExecuteLoop\n\n    style W3 fill:#7c4dff,color:#fff\n    style W9 fill:#f44336,color:#fff\n    style DONE fill:#4caf50,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#wave-based-parallelism","title":"Wave-Based Parallelism","text":"<p>Tasks are organized into waves using topological sort:</p> <pre><code>flowchart LR\n    subgraph Wave1[\"Wave 1 (No Dependencies)\"]\n        T1[\"Task 1: Create User model\"]\n        T2[\"Task 2: Create Config model\"]\n    end\n\n    subgraph Wave2[\"Wave 2 (Depends on Wave 1)\"]\n        T3[\"Task 3: Implement /auth/login\"]\n        T4[\"Task 4: Implement /auth/register\"]\n    end\n\n    subgraph Wave3[\"Wave 3 (Depends on Wave 2)\"]\n        T5[\"Task 5: Build Login UI\"]\n        T6[\"Task 6: Add auth middleware\"]\n    end\n\n    subgraph Wave4[\"Wave 4 (Depends on Wave 3)\"]\n        T7[\"Task 7: Integration tests\"]\n    end\n\n    T1 --&gt; T3\n    T1 --&gt; T4\n    T2 --&gt; T3\n    T3 --&gt; T5\n    T3 --&gt; T6\n    T4 --&gt; T5\n    T5 --&gt; T7\n    T6 --&gt; T7\n\n    style T1 fill:#4caf50,color:#fff\n    style T2 fill:#4caf50,color:#fff\n    style T3 fill:#7c4dff,color:#fff\n    style T4 fill:#7c4dff,color:#fff\n    style T5 fill:#ff9800,color:#fff\n    style T6 fill:#ff9800,color:#fff\n    style T7 fill:#00bcd4,color:#fff</code></pre> <p>Wave Scheduling</p> <p>Tasks within a wave run in parallel (up to <code>max_parallel</code> concurrent agents). After each wave completes, newly unblocked tasks form the next wave. Within waves, tasks are sorted by priority (critical &gt; high &gt; medium &gt; low).</p>"},{"location":"plugins/sdd-tools-deep-dive/#task-executor-4-phase-workflow","title":"Task Executor 4-Phase Workflow","text":"<p>Each task is executed by a <code>task-executor</code> agent (Opus) through:</p> <pre><code>flowchart LR\n    P1[\"Phase 1\\nUnderstand\"] --&gt; P2[\"Phase 2\\nImplement\"]\n    P2 --&gt; P3[\"Phase 3\\nVerify\"]\n    P3 --&gt; P4[\"Phase 4\\nComplete\"]\n\n    P1 -.- N1[\"Read context\\nClassify task\\nExplore codebase\\nPlan implementation\"]\n    P2 -.- N2[\"Read target files\\nWrite code\\nWrite tests\\nRun linter\"]\n    P3 -.- N3[\"Check criteria\\nRun tests\\nDetermine status\"]\n    P4 -.- N4[\"Update task status\\nWrite learnings\\nWrite result file\"]\n\n    style P1 fill:#7c4dff,color:#fff\n    style P2 fill:#4caf50,color:#fff\n    style P3 fill:#ff9800,color:#fff\n    style P4 fill:#00bcd4,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#verification-status","title":"Verification Status","text":"Condition Status What Happens All Functional criteria pass + Tests pass PASS Task marked <code>completed</code> All Functional pass + Tests pass + Edge/Error/Perf issues PARTIAL Task stays <code>in_progress</code>, may retry Any Functional criterion fails FAIL Task stays <code>in_progress</code>, retry with failure context Any test failure FAIL Task stays <code>in_progress</code>, retry with failure context <p>Adaptive Verification</p> <p>The executor detects whether a task is spec-generated (has <code>**Acceptance Criteria:**</code> sections, <code>metadata.spec_path</code>, or <code>Source:</code> references) or a general task. Spec-generated tasks are verified criterion-by-criterion. General tasks use an inferred checklist based on the description.</p>"},{"location":"plugins/sdd-tools-deep-dive/#session-management","title":"Session Management","text":"<pre><code>flowchart TD\n    INIT[\"Initialize Session\"] --&gt; DIR[\".claude/sessions/__live_session__/\"]\n    DIR --&gt; EP[\"execution_plan.md\"]\n    DIR --&gt; EC[\"execution_context.md\"]\n    DIR --&gt; TL[\"task_log.md\"]\n    DIR --&gt; PR[\"progress.md\"]\n    DIR --&gt; TD[\"tasks/ (archived JSONs)\"]\n    DIR --&gt; LOCK[\".lock (concurrency guard)\"]\n\n    POINTER[\"~/.claude/tasks/{list}/execution_pointer.md\"] --&gt; DIR\n\n    COMPLETE[\"Session Complete\"] --&gt; ARCHIVE[\".claude/sessions/{execution_id}/\"]\n    DIR --&gt; |\"move contents\"| ARCHIVE\n\n    style DIR fill:#7c4dff,color:#fff\n    style POINTER fill:#ff9800,color:#fff\n    style ARCHIVE fill:#4caf50,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#key-execution-features","title":"Key Execution Features","text":"Feature Description Background agents Agents run via <code>run_in_background: true</code>, returning ~3 lines instead of full output Result file protocol Each agent writes a compact <code>result-task-{id}.md</code> (~18 lines) as completion signal Per-task context isolation Each agent writes to <code>context-task-{id}.md</code>, orchestrator merges after wave Configurable parallelism Default 5 concurrent agents; overridable via <code>--max-parallel</code> Configurable retries Default 3 attempts; overridable via <code>--retries</code> Retry with context Failed tasks include previous failure details for different approach Interrupted session recovery Stale sessions archived; in_progress tasks reset to pending Concurrency guard <code>.lock</code> file prevents concurrent execution sessions Token usage tracking Per-task <code>duration_ms</code> and <code>total_tokens</code> extracted via TaskOutput <p>Result File Protocol</p> <p>The result file protocol is a key optimization. Instead of consuming the full agent output (which can be thousands of tokens), the orchestrator polls for compact <code>result-task-{id}.md</code> files (~18 lines each). This achieves a 79% context reduction per wave \u2014 critical for keeping the orchestrator within its context window across many waves.</p>"},{"location":"plugins/sdd-tools-deep-dive/#agent-inventory","title":"Agent Inventory","text":"<pre><code>flowchart TD\n    subgraph Agents[\"SDD Tools Agents\"]\n        CE[\"codebase-explorer\\n(Sonnet)\"]\n        R[\"researcher\\n(Opus)\"]\n        SA[\"spec-analyzer\\n(Opus)\"]\n        TE[\"task-executor\\n(Opus)\"]\n    end\n\n    CS[\"/create-spec\"] --&gt; |\"spawns for 'new feature'\"| CE\n    CS --&gt; |\"spawns for research\"| R\n    AS[\"/analyze-spec\"] --&gt; |\"launches\"| SA\n    ET[\"/execute-tasks\"] --&gt; |\"launches \u00d7 N per wave\"| TE\n\n    CE --&gt; |\"Read, Glob, Grep, Bash\"| CODEBASE[\"Codebase\"]\n    R --&gt; |\"WebSearch, WebFetch, Context7\"| WEB[\"External Sources\"]\n    SA --&gt; |\"AskUserQuestion, Read, Write, Edit\"| SPEC[\"Spec Files\"]\n    TE --&gt; |\"Read, Write, Edit, Glob, Grep, Bash\"| CODE[\"Source Code\"]\n\n    style CE fill:#7c4dff,color:#fff\n    style R fill:#00bcd4,color:#fff\n    style SA fill:#f44336,color:#fff\n    style TE fill:#4caf50,color:#fff</code></pre> Agent Model Tools Role Spawned By codebase-explorer Sonnet Read, Glob, Grep, Bash Explores codebase for patterns and architecture <code>/create-spec</code> (parallel, for \"new feature\" type) researcher Opus WebSearch, WebFetch, Context7 Technical and domain research for specs <code>/create-spec</code> (on-demand or proactive) spec-analyzer Opus AskUserQuestion, Read, Write, Edit, Glob, Grep Quality analysis with interactive resolution <code>/analyze-spec</code> task-executor Opus Read, Write, Edit, Glob, Grep, Bash, TaskGet/Update/List Autonomous 4-phase task implementation <code>/execute-tasks</code> (N per wave, background) <p>Model Tiering Rationale</p> <p>Sonnet for codebase-explorer: These agents perform broad, parallelizable search work. Sonnet is cost-effective for exploration where reasoning depth is less critical than breadth. Opus for researcher, spec-analyzer, task-executor: These agents require deep reasoning \u2014 synthesizing research findings, analyzing spec quality, and implementing code with verification.</p>"},{"location":"plugins/sdd-tools-deep-dive/#hooks-automation","title":"Hooks &amp; Automation","text":""},{"location":"plugins/sdd-tools-deep-dive/#auto-approve-sessionsh","title":"auto-approve-session.sh","text":"Property Value Event <code>PreToolUse</code> Triggers Write, Edit, Bash operations Purpose Auto-approves file operations within <code>.claude/sessions/</code> directories Timeout 5 seconds <p>Why This Hook Exists</p> <p>This hook enables task-executor agents to write execution context files, result files, and session artifacts without requiring user approval for each operation. Without it, every file write during autonomous execution would pause for user confirmation \u2014 breaking the autonomous execution loop.</p>"},{"location":"plugins/sdd-tools-deep-dive/#end-to-end-workflow-walkthrough","title":"End-to-End Workflow Walkthrough","text":""},{"location":"plugins/sdd-tools-deep-dive/#example-building-a-user-authentication-feature","title":"Example: Building a User Authentication Feature","text":"<pre><code>sequenceDiagram\n    participant U as Developer\n    participant CS as /create-spec\n    participant CE as codebase-explorer\n    participant AS as /analyze-spec\n    participant SA as spec-analyzer\n    participant CT as /create-tasks\n    participant ET as /execute-tasks\n    participant TE as task-executor \u00d7 N\n    participant TM as Task Manager\n\n    Note over U,TM: Phase 1: Specification\n\n    U-&gt;&gt;CS: /create-spec\n    CS-&gt;&gt;U: What type? \"New feature\"\n    CS-&gt;&gt;U: What depth? \"Detailed\"\n    CS-&gt;&gt;CE: Explore auth patterns (Sonnet \u00d7 2)\n    CE--&gt;&gt;CS: Architecture findings\n    CS-&gt;&gt;U: Interview rounds (3-4 rounds, 12-18 questions)\n    CS-&gt;&gt;U: Recommendations round\n    CS-&gt;&gt;U: Pre-compilation summary \u2014 confirm?\n    U-&gt;&gt;CS: Confirmed\n    CS--&gt;&gt;U: specs/SPEC-User-Auth.md created\n\n    Note over U,TM: Phase 2: Quality Gate (Optional)\n\n    U-&gt;&gt;AS: /analyze-spec specs/SPEC-User-Auth.md\n    AS-&gt;&gt;SA: Analyze spec (Opus)\n    SA--&gt;&gt;AS: 8 findings (2 critical, 4 warning, 2 suggestion)\n    AS-&gt;&gt;U: Choose review mode\n    U-&gt;&gt;AS: CLI Update Mode\n    AS-&gt;&gt;U: Walk through each finding\n    U-&gt;&gt;AS: Apply 6, Skip 2\n    AS--&gt;&gt;U: Spec updated, report saved\n\n    Note over U,TM: Phase 3: Decomposition\n\n    U-&gt;&gt;CT: /create-tasks specs/SPEC-User-Auth.md\n    CT-&gt;&gt;CT: Detect depth: Detailed\n    CT-&gt;&gt;CT: Extract features, decompose, infer dependencies\n    CT-&gt;&gt;U: Preview: 15 tasks, 22 dependencies\n    U-&gt;&gt;CT: Confirmed\n    CT--&gt;&gt;U: 15 tasks created with dependency chains\n    CT--&gt;&gt;TM: Tasks visible in Kanban board\n\n    Note over U,TM: Phase 4: Execution\n\n    U-&gt;&gt;ET: /execute-tasks --task-group user-authentication\n    ET-&gt;&gt;ET: Build wave plan: Wave 1 (3 tasks), Wave 2 (5), Wave 3 (4), Wave 4 (3)\n    ET-&gt;&gt;U: Execution plan \u2014 confirm?\n    U-&gt;&gt;ET: Confirmed\n\n    loop Each Wave\n        ET-&gt;&gt;TE: Launch N background agents\n        TE-&gt;&gt;TE: Understand \u2192 Implement \u2192 Verify \u2192 Complete\n        TE--&gt;&gt;ET: result-task-{id}.md (PASS/PARTIAL/FAIL)\n        ET-&gt;&gt;ET: Merge context, form next wave\n        ET--&gt;&gt;TM: Task status updates (real-time)\n    end\n\n    ET--&gt;&gt;U: Session summary: 14 PASS, 1 PARTIAL</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#step-by-step","title":"Step-by-Step","text":"<ol> <li> <p><code>/create-spec</code> -- Developer initiates spec creation. The skill asks about type (\"new feature\"), depth (\"detailed\"), and runs a 3-4 round interview. For new features, it spawns codebase explorers to understand existing patterns. It produces <code>specs/SPEC-User-Auth.md</code>.</p> </li> <li> <p><code>/analyze-spec specs/SPEC-User-Auth.md</code> (optional but recommended) -- The spec is analyzed for quality issues. The developer reviews findings via CLI or HTML interface, fixing critical issues before task generation.</p> </li> <li> <p><code>/create-tasks specs/SPEC-User-Auth.md</code> -- The spec is decomposed into 15 dependency-ordered tasks. Each task has categorized acceptance criteria (Functional, Edge Cases, Error Handling, Performance), testing requirements, and metadata. The developer previews and confirms.</p> </li> <li> <p><code>/execute-tasks --task-group user-authentication</code> -- The orchestrator builds a wave plan and launches background task-executor agents in parallel. Each agent reads the execution context, implements the task, verifies against acceptance criteria, and reports results. The Task Manager dashboard shows real-time progress.</p> </li> </ol>"},{"location":"plugins/sdd-tools-deep-dive/#data-flow-diagrams","title":"Data Flow Diagrams","text":""},{"location":"plugins/sdd-tools-deep-dive/#artifact-flow-through-the-pipeline","title":"Artifact Flow Through the Pipeline","text":"<pre><code>flowchart TD\n    subgraph Inputs\n        USER[\"User's Idea\"]\n        CODEBASE[\"Existing Codebase\"]\n    end\n\n    subgraph SpecPhase[\"Specification Phase\"]\n        INTERVIEW[\"Interview Answers\"]\n        EXPLORE[\"Exploration Findings\"]\n        RESEARCH[\"Research Findings\"]\n        RECS[\"Recommendations\"]\n    end\n\n    subgraph Artifacts\n        SPEC[\"SPEC-{name}.md\"]\n        ANALYSIS[\"Analysis Report + HTML\"]\n        TASKS[\"Task JSON Files\"]\n        CONTEXT[\"Execution Context\"]\n        CODE[\"Implemented Code\"]\n        LOGS[\"Session Logs\"]\n    end\n\n    USER --&gt; INTERVIEW\n    CODEBASE --&gt; EXPLORE\n    INTERVIEW --&gt; SPEC\n    EXPLORE --&gt; SPEC\n    RESEARCH --&gt; SPEC\n    RECS --&gt; SPEC\n    SPEC --&gt; ANALYSIS\n    ANALYSIS --&gt; |\"fixes\"| SPEC\n    SPEC --&gt; TASKS\n    TASKS --&gt; CONTEXT\n    CONTEXT --&gt; CODE\n    CODE --&gt; LOGS\n\n    style SPEC fill:#7c4dff,color:#fff,stroke-width:3px\n    style TASKS fill:#4caf50,color:#fff,stroke-width:3px\n    style CODE fill:#ff9800,color:#fff,stroke-width:3px</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#execution-context-sharing","title":"Execution Context Sharing","text":"<pre><code>flowchart TD\n    subgraph Wave1[\"Wave 1\"]\n        A1[\"Agent 1\"] --&gt; |\"writes\"| C1[\"context-task-1.md\"]\n        A2[\"Agent 2\"] --&gt; |\"writes\"| C2[\"context-task-2.md\"]\n    end\n\n    subgraph Merge1[\"Between Waves\"]\n        C1 --&gt; EC[\"execution_context.md\"]\n        C2 --&gt; EC\n    end\n\n    subgraph Wave2[\"Wave 2\"]\n        EC --&gt; |\"snapshot read\"| A3[\"Agent 3\"]\n        EC --&gt; |\"snapshot read\"| A4[\"Agent 4\"]\n        A3 --&gt; |\"writes\"| C3[\"context-task-3.md\"]\n        A4 --&gt; |\"writes\"| C4[\"context-task-4.md\"]\n    end\n\n    subgraph Merge2[\"After Wave 2\"]\n        C3 --&gt; EC2[\"execution_context.md\\n(merged)\"]\n        C4 --&gt; EC2\n    end\n\n    style EC fill:#7c4dff,color:#fff,stroke-width:2px\n    style EC2 fill:#7c4dff,color:#fff,stroke-width:2px</code></pre> <p>Context Isolation Pattern</p> <p>Each agent writes to an isolated <code>context-task-{id}.md</code> file during execution. After all agents in a wave complete, the orchestrator merges per-task files into the shared <code>execution_context.md</code>. This eliminates write contention while letting later tasks benefit from earlier discoveries \u2014 a pattern also used by the core-tools deep-analysis skill.</p>"},{"location":"plugins/sdd-tools-deep-dive/#use-cases-benefits","title":"Use Cases &amp; Benefits","text":""},{"location":"plugins/sdd-tools-deep-dive/#use-cases","title":"Use Cases","text":"Use Case How SDD Tools Helps Greenfield feature development Structured spec \u2192 decomposed tasks \u2192 parallel autonomous execution Complex multi-component features Dependency inference ensures correct build order; wave parallelism maximizes throughput Team alignment Spec serves as single source of truth; analyze-spec catches ambiguities before coding starts Iterative spec refinement Merge mode preserves completed work when specs evolve; analyze-spec provides quality gate Compliance-sensitive projects Research agent gathers regulatory requirements; specs document acceptance criteria for audit Reducing rework Verification against acceptance criteria catches issues before they compound Onboarding new team members Specs document the \"why\" behind features; execution context captures implementation decisions"},{"location":"plugins/sdd-tools-deep-dive/#benefits-for-developers","title":"Benefits for Developers","text":"Benefit Without SDD Tools With SDD Tools Requirements capture Ad-hoc prompts, lost context Structured spec with testable criteria Task planning Manual decomposition Automatic dependency-aware decomposition Parallel execution Sequential, one task at a time Wave-based concurrent agent execution Verification Manual review or trust Automated criterion-by-criterion verification Knowledge sharing Each task starts from scratch Shared execution context across tasks Progress visibility Checking git log Real-time Task Manager dashboard Spec evolution Start over or manual diff Merge mode preserves completed work Quality assurance Post-hoc review Pre-implementation spec analysis"},{"location":"plugins/sdd-tools-deep-dive/#integration-with-other-plugins","title":"Integration with Other Plugins","text":""},{"location":"plugins/sdd-tools-deep-dive/#standalone-design","title":"Standalone Design","text":"<p>sdd-tools is a standalone plugin -- it has no external plugin dependencies. This was achieved by giving sdd-tools its own <code>codebase-explorer</code> agent instead of relying on core-tools.</p>"},{"location":"plugins/sdd-tools-deep-dive/#consumed-by-other-plugins","title":"Consumed By Other Plugins","text":"Plugin How It Uses sdd-tools tdd-tools <code>/execute-tdd-tasks</code> routes non-TDD tasks to the <code>task-executor</code> agent from sdd-tools tdd-tools <code>/create-tdd-tasks</code> reads tasks created by <code>/create-tasks</code> and generates TDD pairs <p>TDD Extension</p> <p>The SDD pipeline integrates seamlessly with the TDD Tools plugin. After <code>/create-tasks</code>, run <code>/create-tdd-tasks</code> to generate RED-GREEN test pairs, then <code>/execute-tdd-tasks</code> for TDD-aware execution. See the TDD Tools documentation for the full TDD workflow.</p>"},{"location":"plugins/sdd-tools-deep-dive/#integration-with-task-manager","title":"Integration with Task Manager","text":"<p>The Task Manager dashboard provides real-time visualization:</p> <pre><code>flowchart LR\n    ET[\"/execute-tasks\"] --&gt; |\"creates/updates\"| JSON[\"~/.claude/tasks/*.json\"]\n    JSON --&gt; |\"Chokidar watches\"| FW[\"FileWatcher\"]\n    FW --&gt; |\"EventEmitter\"| SSE[\"SSE Route\"]\n    SSE --&gt; |\"stream\"| CLIENT[\"Browser\"]\n    CLIENT --&gt; |\"invalidateQueries\"| TQ[\"TanStack Query\"]\n    TQ --&gt; KB[\"Kanban Board\"]\n\n    style ET fill:#ff9800,color:#fff\n    style JSON fill:#4caf50,color:#fff\n    style KB fill:#7c4dff,color:#fff</code></pre>"},{"location":"plugins/sdd-tools-deep-dive/#configuration-settings","title":"Configuration &amp; Settings","text":"<p>Settings are configured in <code>.claude/agent-alchemy.local.md</code> (not committed):</p> Setting Type Default Description <code>execute-tasks.max-parallel</code> number 5 Maximum concurrent agents per wave Custom output path string <code>specs/</code> Directory for spec output Author name string -- Attribution in spec metadata"},{"location":"plugins/sdd-tools-deep-dive/#command-line-arguments","title":"Command-Line Arguments","text":"Skill Arguments Description <code>/create-spec</code> (none) Starts interactive interview <code>/analyze-spec</code> <code>[spec-path]</code> Path to spec file <code>/create-tasks</code> <code>[spec-path]</code> Path to spec file <code>/execute-tasks</code> <code>[task-id] [--task-group &lt;group&gt;] [--retries &lt;n&gt;] [--max-parallel &lt;n&gt;]</code> Flexible execution control"},{"location":"plugins/sdd-tools-deep-dive/#reference-file-inventory","title":"Reference File Inventory","text":"Skill File Purpose Contents create-spec <code>interview-questions.md</code> Question bank Questions organized by category and depth create-spec <code>recommendation-triggers.md</code> Trigger patterns Keyword patterns for proactive recommendations create-spec <code>recommendation-format.md</code> Recommendation templates How to present recommendations to users create-spec <code>codebase-exploration.md</code> Exploration procedure 4-step codebase exploration workflow create-spec <code>templates/high-level.md</code> Spec template Streamlined executive overview create-spec <code>templates/detailed.md</code> Spec template Standard PRD with all sections create-spec <code>templates/full-tech.md</code> Spec template Extended with API specs, data models analyze-spec <code>analysis-criteria.md</code> Depth checklists What to check at each depth level analyze-spec <code>common-issues.md</code> Issue patterns Known issue patterns with examples analyze-spec <code>report-template.md</code> Report format Markdown report structure analyze-spec <code>html-review-guide.md</code> HTML generation Instructions for HTML review output create-tasks <code>decomposition-patterns.md</code> Decomposition rules Feature-to-task decomposition patterns create-tasks <code>dependency-inference.md</code> Dependency rules Automatic dependency inference logic create-tasks <code>testing-requirements.md</code> Test mappings Task type \u2192 test type mappings execute-tasks <code>orchestration.md</code> Orchestration loop Full 10-step execution procedure execute-tasks <code>execution-workflow.md</code> Phase workflow 4-phase agent workflow details execute-tasks <code>verification-patterns.md</code> Verification rules Task classification and pass/fail criteria"},{"location":"plugins/sdd-tools/","title":"SDD Tools","text":"<p>Spec-Driven Development (SDD) Tools is the core workflow engine of Agent Alchemy. It provides a structured pipeline that transforms ideas into specifications, decomposes specifications into executable tasks, and runs autonomous implementation with wave-based parallelism.</p> <p>Plugin: <code>agent-alchemy-sdd-tools</code> | Version: 0.2.0 | Skills: 4 | Agents: 4</p> <p>Deep Dive Available</p> <p>For a comprehensive walkthrough of the SDD pipeline \u2014 including end-to-end workflow examples, data flow diagrams, execution context sharing, and architectural deep-dives into each skill \u2014 see the SDD Tools Deep Dive.</p>"},{"location":"plugins/sdd-tools/#the-sdd-pipeline","title":"The SDD Pipeline","text":"<p>The SDD pipeline is a four-stage workflow. Each stage produces an artifact that feeds into the next, creating a traceable chain from requirements to working code.</p> <pre><code>graph LR\n    A[\"/create-spec\"] --&gt;|\"specs/SPEC-{name}.md\"| B[\"/analyze-spec\"]\n    B --&gt;|\"Quality-checked spec\"| C[\"/create-tasks\"]\n    C --&gt;|\"Claude Code Tasks\"| D[\"/execute-tasks\"]\n    D --&gt;|\"Implementation\"| E[\"Task Manager\"]\n\n    style A fill:#7c4dff,color:#fff\n    style B fill:#7c4dff,color:#fff\n    style C fill:#7c4dff,color:#fff\n    style D fill:#7c4dff,color:#fff\n    style E fill:#00bcd4,color:#fff</code></pre> Stage Skill Input Output 1. Specify <code>/create-spec</code> User interview <code>specs/SPEC-{name}.md</code> 2. Analyze <code>/analyze-spec</code> Spec file <code>.analysis.md</code> + <code>.analysis.html</code> 3. Decompose <code>/create-tasks</code> Spec file Claude Code Tasks with metadata 4. Execute <code>/execute-tasks</code> Task list Implemented code, session artifacts <p>TDD Variant (via tdd-tools)</p> <p>The <code>tdd-tools</code> plugin extends this pipeline with test-first development. After <code>/create-tasks</code>, run <code>/create-tdd-tasks</code> (tdd-tools) to generate RED-GREEN test pairs, then <code>/execute-tdd-tasks</code> (tdd-tools) for TDD-aware execution. See the TDD Tools documentation for details.</p>"},{"location":"plugins/sdd-tools/#skills","title":"Skills","text":""},{"location":"plugins/sdd-tools/#create-spec-adaptive-interview","title":"<code>/create-spec</code> -- Adaptive Interview","text":"<p>Creates structured specifications through a multi-round adaptive interview. The interview adjusts its depth, question count, and topic coverage based on the requested detail level.</p> <p>Invocation:</p> <pre><code>/agent-alchemy-sdd:create-spec\n</code></pre>"},{"location":"plugins/sdd-tools/#depth-levels","title":"Depth Levels","text":"Level Rounds Questions Focus High-level overview 2-3 6-10 Problem, goals, key features, success metrics Detailed specifications 3-4 12-18 Balanced coverage with acceptance criteria Full technical documentation 4-5 18-25 API endpoints, data models, architecture"},{"location":"plugins/sdd-tools/#six-phase-workflow","title":"Six-Phase Workflow","text":"<ol> <li>Settings Check -- Loads configuration from <code>.claude/agent-alchemy.local.md</code></li> <li>Initial Inputs -- Gathers spec name, type (new product or new feature), depth, and description</li> <li>Adaptive Interview -- Multi-round depth-aware interview with proactive recommendations</li> <li>Recommendations Round -- Dedicated round for accumulated best-practice suggestions</li> <li>Pre-Compilation Summary -- Presents gathered requirements for user confirmation</li> <li>Spec Compilation -- Generates spec from depth-appropriate template and writes to file</li> </ol>"},{"location":"plugins/sdd-tools/#key-features","title":"Key Features","text":"<ul> <li>Proactive recommendations -- Detects patterns in responses (authentication, scale, compliance) and suggests industry best practices</li> <li>Codebase exploration -- For \"new feature\" type specs, optionally runs <code>deep-analysis</code> from core-tools to understand existing patterns, conventions, and integration points</li> <li>External research -- Invokes the <code>researcher</code> agent for on-demand technical documentation lookup or proactive compliance/regulatory research (max 2 proactive calls per interview)</li> <li>Early exit -- Gracefully handles requests to wrap up early, generating a <code>Draft (Partial)</code> spec with available information</li> <li>Three spec templates -- Dedicated templates for each depth level: <code>high-level.md</code>, <code>detailed.md</code>, <code>full-tech.md</code></li> </ul> <p>Question Categories</p> <p>The interview covers four categories: Problem &amp; Goals, Functional Requirements, Technical Specs, and Implementation. The depth level determines how deeply each category is probed.</p>"},{"location":"plugins/sdd-tools/#output-format","title":"Output Format","text":"<p>Specs follow a structured format with prioritized requirements:</p> specs/SPEC-User-Auth.md<pre><code># User Authentication PRD\n\n**Status**: Draft\n**Spec Type**: New feature\n**Spec Depth**: Detailed specifications\n**Description**: OAuth2-based authentication for the dashboard\n\n## 1. Overview\n...\n\n### REQ-001: User Login\n\n**Priority**: P0 (Critical)\n\n**Description**: Users can authenticate via email/password or OAuth2 providers.\n\n**Acceptance Criteria**:\n- [ ] Login form validates email format\n- [ ] OAuth2 flow completes within 3 seconds\n- [ ] Failed attempts are rate-limited after 5 tries\n</code></pre>"},{"location":"plugins/sdd-tools/#analyze-spec-quality-review","title":"<code>/analyze-spec</code> -- Quality Review","text":"<p>Performs a comprehensive quality analysis of an existing spec, checking for inconsistencies, missing information, ambiguities, and structure issues. Generates both a markdown report and an interactive HTML review.</p> <p>Invocation:</p> <pre><code>/agent-alchemy-sdd:analyze-spec specs/SPEC-User-Authentication.md\n</code></pre>"},{"location":"plugins/sdd-tools/#analysis-categories","title":"Analysis Categories","text":"Category What It Checks Inconsistencies Contradictory requirements, naming mismatches, priority conflicts Missing Information Absent sections, undefined terms, features without acceptance criteria Ambiguities Vague quantifiers (\"fast\", \"scalable\"), ambiguous pronouns, open-ended lists Structure Issues Missing sections, misplaced content, formatting inconsistencies"},{"location":"plugins/sdd-tools/#severity-levels","title":"Severity Levels","text":"Severity Meaning Example Critical Would cause implementation to fail Auth required but no auth spec defined Warning Could cause confusion \"Search should be fast\" without metrics Suggestion Quality improvement Inconsistent user story formatting"},{"location":"plugins/sdd-tools/#depth-aware-analysis","title":"Depth-Aware Analysis","text":"<p>The analyzer detects the spec's depth level (high-level, detailed, or full-tech) and only flags issues appropriate to that level. A high-level spec is never penalized for missing API specifications.</p>"},{"location":"plugins/sdd-tools/#three-review-modes","title":"Three Review Modes","text":"<p>After generating the report, the analyzer offers three review modes:</p> <ol> <li>Interactive HTML Review -- Open <code>.analysis.html</code> in a browser, approve/reject findings, then copy a prompt back to apply changes</li> <li>CLI Update Mode -- Walk through each finding interactively with Apply, Modify, or Skip options</li> <li>Reports Only -- Keep the <code>.analysis.md</code> and <code>.analysis.html</code> files without interactive resolution</li> </ol>"},{"location":"plugins/sdd-tools/#output-files","title":"Output Files","text":"<ul> <li><code>specs/SPEC-{name}.analysis.md</code> -- Structured markdown report with findings</li> <li><code>specs/SPEC-{name}.analysis.html</code> -- Self-contained interactive HTML review page</li> </ul>"},{"location":"plugins/sdd-tools/#create-tasks-spec-to-task-decomposition","title":"<code>/create-tasks</code> -- Spec-to-Task Decomposition","text":"<p>Transforms a specification into dependency-ordered Claude Code Tasks with rich metadata, categorized acceptance criteria, and testing requirements.</p> <p>Invocation:</p> <pre><code>/agent-alchemy-sdd:create-tasks specs/SPEC-User-Authentication.md\n</code></pre>"},{"location":"plugins/sdd-tools/#eight-phase-workflow","title":"Eight-Phase Workflow","text":"<ol> <li>Validate &amp; Load -- Reads the spec, loads decomposition references</li> <li>Detect Depth &amp; Check Existing -- Detects spec depth, checks for existing tasks (merge mode)</li> <li>Analyze Spec -- Extracts features, requirements, priorities from each spec section</li> <li>Decompose Tasks -- Breaks features into atomic tasks using the layer pattern</li> <li>Infer Dependencies -- Maps blocking relationships between tasks</li> <li>Preview &amp; Confirm -- Shows a summary and gets user approval</li> <li>Create Tasks -- Creates tasks via <code>TaskCreate</code>/<code>TaskUpdate</code></li> <li>Error Handling -- Handles parsing issues, circular dependencies, missing information</li> </ol>"},{"location":"plugins/sdd-tools/#task-granularity-by-depth","title":"Task Granularity by Depth","text":"Spec Depth Tasks per Feature Granularity High-level 1-2 Feature-level deliverables Detailed 3-5 Functional decomposition Full-tech 5-10 Technical decomposition (models, endpoints, middleware)"},{"location":"plugins/sdd-tools/#layer-decomposition-pattern","title":"Layer Decomposition Pattern","text":"<p>Each feature is decomposed following a standard layer pattern:</p> <pre><code>graph TD\n    DM[\"1. Data Model Tasks\"] --&gt; API[\"2. API/Service Tasks\"]\n    API --&gt; BL[\"3. Business Logic Tasks\"]\n    BL --&gt; UI[\"4. UI/Frontend Tasks\"]\n    UI --&gt; T[\"5. Test Tasks\"]\n\n    style DM fill:#7c4dff,color:#fff\n    style API fill:#7c4dff,color:#fff\n    style BL fill:#7c4dff,color:#fff\n    style UI fill:#7c4dff,color:#fff\n    style T fill:#00bcd4,color:#fff</code></pre>"},{"location":"plugins/sdd-tools/#task-metadata","title":"Task Metadata","text":"<p>Every task carries structured metadata for filtering, execution, and traceability:</p> Field Description Example <code>priority</code> Mapped from spec P0-P3 <code>critical</code>, <code>high</code>, <code>medium</code>, <code>low</code> <code>complexity</code> Estimated size <code>XS</code>, <code>S</code>, <code>M</code>, <code>L</code>, <code>XL</code> <code>spec_path</code> Source specification <code>specs/SPEC-Auth.md</code> <code>source_section</code> Spec section reference <code>5.1 User Authentication</code> <code>feature_name</code> Parent feature <code>User Authentication</code> <code>task_uid</code> Unique ID for merge tracking <code>specs/SPEC-Auth.md:user-auth:api-login:001</code> <code>task_group</code> Group slug from spec title <code>user-authentication</code> <p>task_group is Required</p> <p>The <code>task_group</code> field must be set on every task. The <code>/execute-tasks</code> skill relies on <code>metadata.task_group</code> for <code>--task-group</code> filtering and session ID generation. Tasks without <code>task_group</code> will be invisible to group-filtered execution runs.</p>"},{"location":"plugins/sdd-tools/#acceptance-criteria-categories","title":"Acceptance Criteria Categories","text":"<p>Each task includes categorized acceptance criteria:</p> Category What It Covers Functional Core behavior, expected outputs, state changes Edge Cases Boundaries, empty/null values, max values, concurrent operations Error Handling Invalid input, failures, timeouts, graceful degradation Performance Response times, throughput, resource limits (when applicable)"},{"location":"plugins/sdd-tools/#merge-mode","title":"Merge Mode","text":"<p>When re-running <code>/create-tasks</code> on an updated spec, the skill uses <code>task_uid</code> to intelligently merge:</p> Existing Status Action <code>pending</code> Updated if spec changed <code>in_progress</code> Preserved, optionally updated <code>completed</code> Never modified New requirement Created as new task No longer in spec Flagged as potentially obsolete"},{"location":"plugins/sdd-tools/#execute-tasks-wave-based-execution","title":"<code>/execute-tasks</code> -- Wave-Based Execution","text":"<p>Orchestrates autonomous task execution with dependency-aware wave scheduling, per-task agent isolation, shared execution context, and adaptive verification.</p> <p>Invocation:</p> <pre><code>/agent-alchemy-sdd:execute-tasks --task-group user-authentication\n</code></pre> <p>Arguments:</p> Argument Default Description <code>[task-id]</code> -- Execute a single specific task <code>--task-group &lt;group&gt;</code> -- Filter to tasks matching this group <code>--retries &lt;n&gt;</code> 3 Retry attempts for failed tasks <code>--max-parallel &lt;n&gt;</code> 5 Max concurrent agents per wave"},{"location":"plugins/sdd-tools/#4-phase-task-workflow","title":"4-Phase Task Workflow","text":"<p>Each task is executed by a <code>task-executor</code> agent (Opus model) through four phases:</p> <pre><code>graph LR\n    U[\"Phase 1: Understand\"] --&gt; I[\"Phase 2: Implement\"]\n    I --&gt; V[\"Phase 3: Verify\"]\n    V --&gt; C[\"Phase 4: Complete\"]\n\n    style U fill:#7c4dff,color:#fff\n    style I fill:#7c4dff,color:#fff\n    style V fill:#7c4dff,color:#fff\n    style C fill:#7c4dff,color:#fff</code></pre> Phase What Happens Understand Load execution context, classify task, parse acceptance criteria, explore affected files, read <code>CLAUDE.md</code> for conventions Implement Read target files, make changes following project patterns (data -&gt; service -&gt; interface -&gt; tests), run mid-implementation checks Verify Walk acceptance criteria (spec-generated) or infer checklist (general), run tests, determine PASS/PARTIAL/FAIL Complete Update task status, write learnings to per-task context file, return structured verification report"},{"location":"plugins/sdd-tools/#verification-status-rules","title":"Verification Status Rules","text":"Condition Status All Functional criteria pass + Tests pass PASS All Functional pass + Tests pass + Edge/Error/Perf issues PARTIAL Any Functional criterion fails FAIL Any test failure FAIL <p>Adaptive Verification</p> <p>The executor detects whether a task is spec-generated (has <code>**Acceptance Criteria:**</code> sections, <code>metadata.spec_path</code>, or <code>Source:</code> references) or a general task. Spec-generated tasks are verified criterion-by-criterion. General tasks use an inferred checklist based on the description.</p>"},{"location":"plugins/sdd-tools/#wave-based-execution","title":"Wave-Based Execution","text":"<p>Tasks are organized into waves based on dependency levels:</p> <pre><code>graph TD\n    subgraph \"Wave 1 (no dependencies)\"\n        A1[\"Create User model\"]\n        A2[\"Create Session model\"]\n    end\n    subgraph \"Wave 2 (depends on Wave 1)\"\n        B1[\"Implement login endpoint\"]\n        B2[\"Implement register endpoint\"]\n    end\n    subgraph \"Wave 3 (depends on Wave 2)\"\n        C1[\"Build login UI\"]\n        C2[\"Add auth middleware\"]\n    end\n\n    A1 --&gt; B1\n    A1 --&gt; B2\n    A2 --&gt; B1\n    B1 --&gt; C1\n    B1 --&gt; C2</code></pre> <ul> <li>Tasks within a wave run in parallel (up to <code>max_parallel</code> concurrent agents)</li> <li>After each wave, newly unblocked tasks form the next wave</li> <li>Failed tasks with retries remaining are re-launched immediately within the wave</li> <li>Within waves, tasks are sorted by priority (critical &gt; high &gt; medium &gt; low)</li> </ul>"},{"location":"plugins/sdd-tools/#session-management","title":"Session Management","text":"<p>Each execution creates a session directory at <code>.claude/sessions/__live_session__/</code> containing:</p> File Purpose <code>execution_plan.md</code> Saved wave plan with task assignments <code>execution_context.md</code> Shared learnings: patterns, decisions, issues, file map <code>task_log.md</code> Per-task results with status, duration, and token usage <code>progress.md</code> Real-time progress tracking for the Task Manager <code>tasks/</code> Subdirectory for archived completed task files <p>Execution Context Sharing</p> <p>Each agent writes learnings to an isolated <code>context-task-{id}.md</code> file. After all agents in a wave complete, the orchestrator merges per-task files into the shared <code>execution_context.md</code>. This eliminates write contention while letting later tasks benefit from earlier discoveries.</p>"},{"location":"plugins/sdd-tools/#key-behaviors","title":"Key Behaviors","text":"<ul> <li>Autonomous execution loop -- After the user confirms the plan, the loop runs without interruption</li> <li>Configurable parallelism -- Set <code>--max-parallel 1</code> for sequential execution</li> <li>Retry with context -- Each retry includes the previous attempt's failure details</li> <li>Interrupted session recovery -- Stale sessions are detected, archived, and <code>in_progress</code> tasks reset to <code>pending</code></li> <li>Concurrency guard -- A <code>.lock</code> file prevents multiple execution sessions from running simultaneously</li> <li>CLAUDE.md updates -- After execution, meaningful project-wide changes are added to <code>CLAUDE.md</code></li> </ul>"},{"location":"plugins/sdd-tools/#dependency-inference","title":"Dependency Inference","text":"<p>The <code>/create-tasks</code> skill automatically infers blocking relationships between tasks using several strategies.</p>"},{"location":"plugins/sdd-tools/#layer-based-dependencies","title":"Layer-Based Dependencies","text":"<p>Higher layers depend on lower layers:</p> <pre><code>Layer 0: Infrastructure/Config\n    |\nLayer 1: Data Models\n    |\nLayer 2: API/Service\n    |\nLayer 3: Business Logic\n    |\nLayer 4: UI/Frontend\n    |\nLayer 5: Integration/E2E Tests\n</code></pre> Task Type Depends On Blocks Data Model Infrastructure tasks API tasks, Service tasks API Endpoint Data Model it uses UI tasks calling it UI Component API endpoint it calls E2E tests Unit Test Implementation it tests Nothing"},{"location":"plugins/sdd-tools/#phase-dependencies","title":"Phase Dependencies","text":"<p>When the spec defines implementation phases, all tasks in Phase N are blocked by completion of Phase N-1.</p>"},{"location":"plugins/sdd-tools/#cross-feature-dependencies","title":"Cross-Feature Dependencies","text":"<p>Tasks that share data models, services, or authentication requirements are linked through their common dependencies. For example, if both Feature A and Feature B use the User model, both depend on the \"Create User model\" task.</p>"},{"location":"plugins/sdd-tools/#keyword-based-detection","title":"Keyword-Based Detection","text":"<p>Dependency signals are detected from task descriptions:</p> <ul> <li><code>\"using {Entity}\"</code> -- depends on Entity model task</li> <li><code>\"calls {endpoint}\"</code> -- depends on endpoint task</li> <li><code>\"extends {Component}\"</code> -- depends on component task</li> <li><code>\"requires {Setup}\"</code> -- depends on setup task</li> </ul>"},{"location":"plugins/sdd-tools/#circular-dependency-handling","title":"Circular Dependency Handling","text":"<p>If a circular dependency is detected during task creation or TDD pair insertion, the system breaks the cycle at the weakest link (scored by relationship type) and flags the affected task with <code>needs_review: true</code> in metadata.</p>"},{"location":"plugins/sdd-tools/#agents","title":"Agents","text":""},{"location":"plugins/sdd-tools/#researcher","title":"researcher","text":"Property Value Model Opus Tools WebSearch, WebFetch, Context7 (resolve-library-id, query-docs) Used by <code>/create-spec</code> <p>Researches technical documentation, domain knowledge, competitive landscape, and compliance requirements during the spec interview. Uses Context7 as the primary source for library/framework documentation, falling back to web search for general topics.</p>"},{"location":"plugins/sdd-tools/#spec-analyzer","title":"spec-analyzer","text":"Property Value Model Opus Tools AskUserQuestion, Read, Write, Edit, Glob, Grep Used by <code>/analyze-spec</code> <p>Performs systematic analysis across four categories (inconsistencies, missing information, ambiguities, structure issues) and guides users through resolving findings interactively. Read-only access to the codebase with write access limited to the spec and report files.</p>"},{"location":"plugins/sdd-tools/#codebase-explorer","title":"codebase-explorer","text":"Property Value Model Sonnet Tools Read, Glob, Grep, Bash Used by <code>/create-spec</code> (optional, for new feature type specs) <p>Explores codebases to discover architecture, patterns, and feature-relevant code during spec creation. Spawned in parallel with specific focus areas when the user creates a spec for a new feature that needs codebase context. This is a lightweight, non-team agent distinct from core-tools' <code>code-explorer</code> \u2014 it works independently and returns its findings as a final message without team coordination.</p>"},{"location":"plugins/sdd-tools/#task-executor","title":"task-executor","text":"Property Value Model Opus Tools Read, Write, Edit, Glob, Grep, Bash, TaskGet, TaskUpdate, TaskList Used by <code>/execute-tasks</code>, <code>/execute-tdd-tasks</code> (for non-TDD tasks) <p>Executes a single task autonomously through the 4-phase workflow (Understand, Implement, Verify, Complete). Works without user interaction, writes learnings to per-task context files, and reports honest verification results.</p>"},{"location":"plugins/sdd-tools/#task-manager-integration","title":"Task Manager Integration","text":"<p>The <code>/execute-tasks</code> skill (and <code>/execute-tdd-tasks</code> from tdd-tools) produces session artifacts that integrate with the Agent Alchemy Task Manager -- a real-time Kanban dashboard.</p>"},{"location":"plugins/sdd-tools/#how-it-works","title":"How It Works","text":"<ol> <li>The execution orchestrator writes <code>progress.md</code> to <code>.claude/sessions/__live_session__/</code> as tasks execute</li> <li>Task status updates flow through Claude Code's native Task system (<code>~/.claude/tasks/</code>)</li> <li>An <code>execution_pointer.md</code> file at <code>~/.claude/tasks/{list_id}/</code> links the Task Manager to the active session</li> <li>The Task Manager watches <code>~/.claude/tasks/</code> via Chokidar and pushes updates to the browser via SSE</li> </ol>"},{"location":"plugins/sdd-tools/#what-you-see","title":"What You See","text":"<ul> <li>Task cards move between Pending, In Progress, and Completed columns in real time</li> <li>Wave progress shows which execution wave is active</li> <li>Session files (execution plan, context, task log) are accessible from the session directory</li> </ul> <p>Running the Task Manager</p> <p>Start the Task Manager alongside your execution session for real-time visibility:</p> <pre><code>pnpm dev:task-manager\n# Open http://localhost:3030\n</code></pre>"},{"location":"plugins/sdd-tools/#configuration","title":"Configuration","text":"<p>Settings are stored in <code>.claude/agent-alchemy.local.md</code> (not committed to version control).</p>"},{"location":"plugins/sdd-tools/#available-settings","title":"Available Settings","text":"Setting Default Description <code>author</code> -- Author name included in spec metadata <code>spec-output-path</code> <code>specs/</code> Directory for generated spec files <code>execute-tasks.max_parallel</code> <code>5</code> Max concurrent agents per wave (overridden by <code>--max-parallel</code>)"},{"location":"plugins/sdd-tools/#example-settings-file","title":"Example Settings File","text":".claude/agent-alchemy.local.md<pre><code># Agent Alchemy Settings\n\n## General\n- author: Jane Smith\n- spec-output-path: docs/specs/\n\n## Execution\n- execute-tasks.max_parallel: 3\n</code></pre>"},{"location":"plugins/sdd-tools/#hooks","title":"Hooks","text":"<p>SDD Tools includes a single PreToolUse hook that auto-approves file operations within execution session directories, enabling autonomous task execution without permission prompts.</p> Hook Event Matcher Timeout <code>auto-approve-session.sh</code> PreToolUse <code>Write\\|Edit\\|Bash</code> 5s <p>What it approves:</p> <ul> <li><code>Write</code>/<code>Edit</code> operations targeting <code>$HOME/.claude/tasks/*/execution_pointer.md</code></li> <li><code>Write</code>/<code>Edit</code> operations targeting any file inside <code>.claude/sessions/</code></li> <li><code>Bash</code> commands targeting <code>.claude/sessions/</code></li> </ul> <p>All other operations pass through to the normal permission flow.</p>"},{"location":"plugins/sdd-tools/#directory-structure","title":"Directory Structure","text":"<pre><code>sdd-tools/\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 researcher.md              # Technical/domain research agent\n\u2502   \u251c\u2500\u2500 spec-analyzer.md           # Spec quality analysis agent\n\u2502   \u2514\u2500\u2500 task-executor.md           # Autonomous implementation agent\n\u251c\u2500\u2500 hooks/\n\u2502   \u251c\u2500\u2500 hooks.json                 # PreToolUse hook configuration\n\u2502   \u2514\u2500\u2500 auto-approve-session.sh    # Session file auto-approve script\n\u2514\u2500\u2500 skills/\n    \u251c\u2500\u2500 create-spec/\n    \u2502   \u251c\u2500\u2500 SKILL.md               # Adaptive interview workflow (664 lines)\n    \u2502   \u2514\u2500\u2500 references/\n    \u2502       \u251c\u2500\u2500 interview-questions.md\n    \u2502       \u251c\u2500\u2500 recommendation-triggers.md\n    \u2502       \u251c\u2500\u2500 recommendation-format.md\n    \u2502       \u2514\u2500\u2500 templates/\n    \u2502           \u251c\u2500\u2500 high-level.md\n    \u2502           \u251c\u2500\u2500 detailed.md\n    \u2502           \u2514\u2500\u2500 full-tech.md\n    \u251c\u2500\u2500 analyze-spec/\n    \u2502   \u251c\u2500\u2500 SKILL.md               # Quality analysis workflow\n    \u2502   \u251c\u2500\u2500 references/\n    \u2502   \u2502   \u251c\u2500\u2500 analysis-criteria.md\n    \u2502   \u2502   \u251c\u2500\u2500 common-issues.md\n    \u2502   \u2502   \u251c\u2500\u2500 html-review-guide.md\n    \u2502   \u2502   \u2514\u2500\u2500 report-template.md\n    \u2502   \u2514\u2500\u2500 templates/\n    \u2502       \u2514\u2500\u2500 review-template.html\n    \u251c\u2500\u2500 create-tasks/\n    \u2502   \u251c\u2500\u2500 SKILL.md               # Task decomposition (653 lines)\n    \u2502   \u2514\u2500\u2500 references/\n    \u2502       \u251c\u2500\u2500 decomposition-patterns.md\n    \u2502       \u251c\u2500\u2500 dependency-inference.md\n    \u2502       \u2514\u2500\u2500 testing-requirements.md\n    \u2514\u2500\u2500 execute-tasks/\n        \u251c\u2500\u2500 SKILL.md               # Execution orchestrator (262 lines)\n        \u2514\u2500\u2500 references/\n            \u251c\u2500\u2500 orchestration.md\n            \u251c\u2500\u2500 execution-workflow.md\n            \u2514\u2500\u2500 verification-patterns.md\n</code></pre>"},{"location":"plugins/sdd-tools/#quick-reference","title":"Quick Reference","text":""},{"location":"plugins/sdd-tools/#common-workflows","title":"Common Workflows","text":"Standard PipelineTDD Pipeline (via tdd-tools)Single TaskRe-run After Spec Update <pre><code># 1. Create a spec\n/agent-alchemy-sdd:create-spec\n\n# 2. Analyze for quality issues\n/agent-alchemy-sdd:analyze-spec specs/SPEC-My-Feature.md\n\n# 3. Generate tasks\n/agent-alchemy-sdd:create-tasks specs/SPEC-My-Feature.md\n\n# 4. Execute all tasks\n/agent-alchemy-sdd:execute-tasks --task-group my-feature\n</code></pre> <pre><code># 1-3. Same as standard pipeline\n/agent-alchemy-sdd:create-spec\n/agent-alchemy-sdd:analyze-spec specs/SPEC-My-Feature.md\n/agent-alchemy-sdd:create-tasks specs/SPEC-My-Feature.md\n\n# 4. Add TDD test pairs (tdd-tools plugin)\n/agent-alchemy-tdd:create-tdd-tasks --task-group my-feature\n\n# 5. Execute with TDD enforcement (tdd-tools plugin)\n/agent-alchemy-tdd:execute-tdd-tasks --task-group my-feature\n</code></pre> <pre><code># Execute one specific task\n/agent-alchemy-sdd:execute-tasks 5\n\n# Execute with extra retries\n/agent-alchemy-sdd:execute-tasks 5 --retries 5\n</code></pre> <pre><code># Merge mode: updates pending, preserves completed\n/agent-alchemy-sdd:create-tasks specs/SPEC-My-Feature.md\n\n# Execute newly created/updated tasks\n/agent-alchemy-sdd:execute-tasks --task-group my-feature\n</code></pre>"},{"location":"plugins/tdd-tools/","title":"TDD Tools","text":"<p>The TDD Tools plugin (<code>v0.2.0</code>) brings Test-Driven Development workflows to Agent Alchemy. It provides five skills and three agents that automate the RED-GREEN-REFACTOR cycle, generate behavior-driven tests, analyze test coverage, and orchestrate TDD task execution -- all with framework auto-detection and deep integration into the SDD pipeline.</p>"},{"location":"plugins/tdd-tools/#philosophy","title":"Philosophy","text":"<p>TDD Tools follows five core principles:</p> <ol> <li>Tests before implementation -- Tests define what the code should do. Implementation follows from tests, never the reverse.</li> <li>Minimal implementation -- Write only the code needed to make failing tests pass. No extra features, no premature optimization.</li> <li>Behavior over implementation -- Test what code does (inputs, outputs, side effects), not how it does it internally.</li> <li>Phase gate enforcement -- Each phase must complete and verify before the next begins. RED verification is mandatory. GREEN verification is mandatory.</li> <li>Regression protection -- Existing tests must continue passing at every phase. Zero tolerance for regressions.</li> </ol>"},{"location":"plugins/tdd-tools/#plugin-inventory","title":"Plugin Inventory","text":"Component Type Model Description <code>tdd-cycle</code> Skill -- Full 7-phase RED-GREEN-REFACTOR workflow <code>generate-tests</code> Skill -- Test generation from criteria or existing code <code>analyze-coverage</code> Skill -- Coverage analysis with gap identification <code>create-tdd-tasks</code> Skill -- Transform SDD tasks into test-first TDD task pairs <code>execute-tdd-tasks</code> Skill -- TDD-aware wave execution with agent routing <code>tdd-executor</code> Agent Opus Executes the 6-phase TDD cycle per task <code>test-writer</code> Agent Sonnet Generates test files (parallelizable) <code>test-reviewer</code> Agent Opus Evaluates test quality against a behavior-driven rubric"},{"location":"plugins/tdd-tools/#tdd-cycle-tdd-cycle","title":"TDD Cycle (<code>/tdd-cycle</code>)","text":"<p>The flagship skill. It drives the entire TDD lifecycle through 7 sequential phases, from understanding the feature to delivering a final compliance report.</p>"},{"location":"plugins/tdd-tools/#workflow-overview","title":"Workflow Overview","text":"<pre><code>flowchart TD\n    A[\"Phase 1: Parse Input\"] --&gt; B[\"Phase 2: Understand\"]\n    B --&gt; C[\"Phase 3: Plan\"]\n    C --&gt; D{User Confirms?}\n    D --&gt;|Modify| C\n    D --&gt;|Cancel| Z[\"Workflow Cancelled\"]\n    D --&gt;|Proceed| E[\"Phase 4: RED\"]\n    E --&gt; F[\"Phase 5: GREEN\"]\n    F --&gt; G[\"Phase 6: REFACTOR\"]\n    G --&gt; H[\"Phase 7: Report\"]\n\n    style E fill:#d32f2f,color:#fff\n    style F fill:#388e3c,color:#fff\n    style G fill:#1565c0,color:#fff</code></pre> <p>Autonomous After Confirmation</p> <p>The user confirms the plan once in Phase 3. After that, Phases 4 through 7 run autonomously without interruption.</p>"},{"location":"plugins/tdd-tools/#phase-details","title":"Phase Details","text":""},{"location":"plugins/tdd-tools/#phase-1-parse-input","title":"Phase 1: Parse Input","text":"<p>Determines the input type and resolves context. Supports three input modes:</p> Input Type Trigger Example Feature description Free-text or file path <code>/tdd-cycle add user login with email validation</code> Task ID Numeric ID with optional prefix <code>/tdd-cycle #5</code> or <code>/tdd-cycle task-12</code> Spec section Spec file path with section ref <code>/tdd-cycle specs/SPEC-auth.md Section 5.1</code>"},{"location":"plugins/tdd-tools/#phase-2-understand","title":"Phase 2: Understand","text":"<p>Loads project conventions, detects the test framework, and explores the relevant codebase. This phase also snapshots the existing test suite to establish a baseline (total tests, pass count, fail count) used for regression detection in later phases.</p> <p>Key actions:</p> <ul> <li>Reads <code>CLAUDE.md</code> and TDD settings from <code>.claude/agent-alchemy.local.md</code></li> <li>Loads cross-plugin skills (<code>language-patterns</code>, <code>project-conventions</code>)</li> <li>Runs framework auto-detection (see Supported Frameworks)</li> <li>Reads 2-3 existing test files to learn project conventions</li> <li>Runs the existing test suite to record a baseline</li> </ul>"},{"location":"plugins/tdd-tools/#phase-3-plan","title":"Phase 3: Plan","text":"<p>Builds and presents a TDD plan covering feature scope, test cases (organized by Functional, Edge Cases, Error Handling), file locations, and implementation approach. The user confirms, modifies, or cancels via interactive prompt.</p>"},{"location":"plugins/tdd-tools/#phase-4-red","title":"Phase 4: RED","text":"<p>RED Phase</p> <p>Write failing tests, then verify they all fail. No implementation code is written during this phase.</p> <p>Tests are written from the planned requirements using the AAA pattern (Arrange-Act-Assert). After writing, the full test suite runs to confirm every new test fails with an appropriate error (<code>ImportError</code>, <code>AssertionError</code>, etc.).</p> <p>The strictness level controls what happens if tests pass unexpectedly:</p> Strictness If new tests pass Action <code>strict</code> Any test passes Abort the workflow <code>normal</code> Some tests pass Log warning, investigate, continue <code>relaxed</code> Any outcome Log results, continue"},{"location":"plugins/tdd-tools/#phase-5-green","title":"Phase 5: GREEN","text":"<p>GREEN Phase</p> <p>Implement the minimal code to make all failing tests pass. Fix the implementation, never the tests.</p> <p>Implementation follows dependency-aware order: data layer, service layer, API/interface layer, configuration. If tests still fail after 5 iterations, the workflow reports FAIL.</p> <p>Regressions (a previously-passing test now failing) take priority over making new tests pass.</p>"},{"location":"plugins/tdd-tools/#phase-6-refactor","title":"Phase 6: REFACTOR","text":"<p>REFACTOR Phase</p> <p>Clean up the implementation while keeping all tests green. Each refactoring change is individually verified.</p> <p>Looks for code duplication, unclear naming, overly complex logic, and missing abstractions. If a refactoring change breaks a test, it is reverted immediately -- no attempt to fix both simultaneously.</p>"},{"location":"plugins/tdd-tools/#phase-7-report","title":"Phase 7: Report","text":"<p>Collects results from all phases, optionally runs coverage tools, and presents a final TDD compliance report:</p> Example Report<pre><code>## TDD Cycle Complete: User Authentication\n\n**Status**: PASS\n**Strictness**: normal\n\n### Phase Results\n\n| Phase | Status | Details |\n|-------|--------|---------|\n| Understand | Complete | Framework: pytest, Baseline: 42 tests |\n| RED | Verified | 8/8 new tests failed as expected |\n| GREEN | Verified | 50/50 tests pass, 0 regressions |\n| REFACTOR | Complete | Extracted 2 helpers, improved naming |\n\n### TDD Compliance\n\n- RED verified: Yes\n- GREEN verified: Yes\n- Refactored: Yes\n</code></pre>"},{"location":"plugins/tdd-tools/#integration-modes","title":"Integration Modes","text":"<p>The TDD cycle supports three operating modes:</p> StandaloneSDD PipelineRetrofit <p>Invoked directly with a feature description:</p> <pre><code>/tdd-cycle add user login with email and password validation\n/tdd-cycle src/auth/login.py\n</code></pre> <p>Receives a task ID from <code>execute-tdd-tasks</code> or the user:</p> <pre><code>/tdd-cycle #5\n/tdd-cycle task-12\n</code></pre> <p>Loads task details via <code>TaskGet</code>, extracts acceptance criteria, and updates task status on completion.</p> <p>Adds tests to existing untested code:</p> <pre><code>/tdd-cycle --retrofit src/utils/helpers.py\n</code></pre> <p>Skips RED phase (implementation already exists), generates characterization tests, and uses relaxed strictness automatically.</p>"},{"location":"plugins/tdd-tools/#test-generation-generate-tests","title":"Test Generation (<code>/generate-tests</code>)","text":"<p>Generates high-quality, behavior-driven test files without running the full TDD cycle. Operates in two modes and spawns <code>test-writer</code> agents in parallel for multi-file generation.</p>"},{"location":"plugins/tdd-tools/#modes","title":"Modes","text":"Criteria-DrivenCode-Analysis <p>Generates tests from acceptance criteria in specs or tasks.</p> <pre><code>/generate-tests specs/SPEC-auth.md\n/generate-tests #5\n/generate-tests specs/SPEC-auth.md Section 5.1\n</code></pre> <p>Process:</p> <ol> <li>Parse acceptance criteria into categories (Functional, Edge Cases, Error Handling, Performance)</li> <li>Map each criterion to one or more test cases</li> <li>Spawn <code>test-writer</code> agents (one per feature) in parallel</li> <li>Validate syntax and convention compliance</li> <li>Report generated files and criteria coverage</li> </ol> <p>Generates characterization tests from existing source files.</p> <pre><code>/generate-tests src/utils.py\n/generate-tests src/services/\n</code></pre> <p>Process:</p> <ol> <li>Analyze source files for public functions, classes, and methods</li> <li>Generate tests for the public interface (inputs, outputs, side effects)</li> <li>Identify untested edge cases (boundary conditions, error paths)</li> <li>Preserve existing test files (writes supplementary files with <code>_additional</code> suffix)</li> </ol>"},{"location":"plugins/tdd-tools/#six-phase-workflow","title":"Six-Phase Workflow","text":"<pre><code>flowchart LR\n    A[\"Parse Input\"] --&gt; B[\"Detect Framework\"]\n    B --&gt; C[\"Load References\"]\n    C --&gt; D[\"Generate Tests\"]\n    D --&gt; E[\"Validate\"]\n    E --&gt; F[\"Report\"]</code></pre> <ol> <li>Parse Input -- Determine mode (criteria-driven or code-analysis) and resolve paths</li> <li>Detect Framework -- Auto-detect pytest, Jest, or Vitest from project configuration</li> <li>Load References -- Load test patterns, framework templates, and project conventions</li> <li>Generate Tests -- Spawn <code>test-writer</code> agents to produce test files</li> <li>Validate -- Syntax check each generated file, verify convention compliance</li> <li>Report -- Present summary with file list, test counts, criteria coverage, and next steps</li> </ol> <p>RED State Awareness</p> <p>If no implementation exists, generated tests are flagged as being in RED state -- they will fail when run. If implementation already exists, a warning is displayed noting that tests may pass immediately.</p>"},{"location":"plugins/tdd-tools/#coverage-analysis-analyze-coverage","title":"Coverage Analysis (<code>/analyze-coverage</code>)","text":"<p>Runs real coverage tools, parses results into structured reports, and identifies gaps with actionable test suggestions. Optionally maps coverage against spec acceptance criteria.</p>"},{"location":"plugins/tdd-tools/#usage","title":"Usage","text":"<pre><code>/analyze-coverage                              # Current project, default threshold\n/analyze-coverage /path/to/project             # Specific project path\n/analyze-coverage --spec specs/SPEC-auth.md    # Map against spec criteria\n/analyze-coverage --threshold 90               # Override coverage threshold\n</code></pre>"},{"location":"plugins/tdd-tools/#six-phase-workflow_1","title":"Six-Phase Workflow","text":"<ol> <li>Detect Environment -- Auto-detect project type, test runner, coverage tool, and source package</li> <li>Run Coverage -- Execute the appropriate coverage command (<code>pytest --cov</code>, <code>npx jest --coverage</code>, etc.)</li> <li>Parse Results -- Parse JSON coverage reports into structured per-file data</li> <li>Analyze Gaps -- Identify uncovered files, functions, and branches; optionally map against spec criteria</li> <li>Generate Report -- Produce a structured markdown report with gap priorities (P0--P3)</li> <li>Suggest Next Steps -- Recommend specific <code>/generate-tests</code> and <code>/tdd-cycle</code> commands</li> </ol>"},{"location":"plugins/tdd-tools/#gap-priority-levels","title":"Gap Priority Levels","text":"Priority Description Example P0 Completely uncovered files (0%) New module with no tests P1 Uncovered functions/methods Public API with zero execution P2 Uncovered branches Partial coverage, untaken paths P3 Files below threshold 45% coverage vs 80% target"},{"location":"plugins/tdd-tools/#spec-to-coverage-mapping","title":"Spec-to-Coverage Mapping","text":"<p>When <code>--spec</code> is provided, each acceptance criterion is mapped to source code locations and classified:</p> <ul> <li>TESTED -- All mapped locations have coverage &gt; 0</li> <li>PARTIAL -- Some mapped locations covered, others not</li> <li>UNTESTED -- No coverage for mapped locations</li> </ul> <p>Coverage Tool Required</p> <p>If the coverage tool is not installed, the skill provides the exact install command (<code>pip install pytest-cov</code> or <code>npm install -D @vitest/coverage-v8</code>) and stops. It does not attempt to estimate coverage.</p>"},{"location":"plugins/tdd-tools/#agents","title":"Agents","text":""},{"location":"plugins/tdd-tools/#tdd-executor-opus","title":"tdd-executor (Opus)","text":"<p>The heavyweight agent that runs the complete 6-phase TDD workflow for a single task. It works autonomously without user interaction after being launched.</p> <pre><code>flowchart LR\n    A[\"Understand\"] --&gt; B[\"Write Tests\"]\n    B --&gt; C[\"RED\"]\n    C --&gt; D[\"Implement\"]\n    D --&gt; E[\"GREEN\"]\n    E --&gt; F[\"Complete\"]\n\n    style C fill:#d32f2f,color:#fff\n    style E fill:#388e3c,color:#fff</code></pre> <p>Key characteristics:</p> <ul> <li>Model: Opus (high-reasoning tasks)</li> <li>Full tool access: Read, Write, Edit, Glob, Grep, Bash, TaskGet, TaskUpdate, TaskList</li> <li>Loads <code>language-patterns</code> and <code>project-conventions</code> skills for project awareness</li> <li>Writes per-task learnings to execution context for downstream tasks</li> <li>Reports structured results with per-phase status and TDD compliance metrics</li> <li>Supports retry with context from previous failure</li> </ul>"},{"location":"plugins/tdd-tools/#test-writer-sonnet","title":"test-writer (Sonnet)","text":"<p>A test generation specialist spawned in parallel for multi-file test creation. Focused on producing a single, complete test file per invocation.</p> <p>Key characteristics:</p> <ul> <li>Model: Sonnet (parallelizable worker tasks)</li> <li>Tools: Read, Write, Edit, Glob, Grep, Bash</li> <li>Supports both criteria-driven and code-analysis modes</li> <li>Follows the AAA pattern (Arrange-Act-Assert)</li> <li>Flags RED state compliance -- warns if implementation already exists</li> <li>Loads <code>language-patterns</code> and <code>project-conventions</code> for consistency</li> </ul>"},{"location":"plugins/tdd-tools/#test-reviewer-opus","title":"test-reviewer (Opus)","text":"<p>A read-only agent that evaluates test quality across four weighted dimensions. It produces confidence-scored findings with line references.</p> <p>Key characteristics:</p> <ul> <li>Model: Opus (nuanced quality evaluation)</li> <li>Tools: Read, Glob, Grep (read-only -- cannot modify files)</li> <li>Scores four dimensions with explicit weights:</li> </ul> Dimension Weight Focus Meaningful Assertions 35% Behavior verification over implementation details Edge Case Coverage 25% Boundary conditions, error paths, unusual scenarios Test Independence 20% Isolation, no shared mutable state, order independence Readability 20% Clear names, AAA structure, consistent style <ul> <li>Overall score: weighted average (0--100)</li> <li>Only reports issues with confidence &gt;= 80 to avoid false positives</li> <li>Recognizes acceptable implementation-detail testing (security-critical algorithms, external service calls, protocol compliance)</li> </ul>"},{"location":"plugins/tdd-tools/#supported-frameworks","title":"Supported Frameworks","text":"<p>TDD Tools auto-detects the test framework using a four-level detection chain:</p>"},{"location":"plugins/tdd-tools/#detection-chain","title":"Detection Chain","text":"<pre><code>flowchart TD\n    A[\"Priority 1: Config Files\"] --&gt;|Not found| B[\"Priority 2: Existing Test Files\"]\n    B --&gt;|Not found| C[\"Priority 3: Settings Fallback\"]\n    C --&gt;|Not found| D[\"Priority 4: User Prompt\"]\n\n    A --&gt;|Found| R[\"Framework Detected\"]\n    B --&gt;|Found| R\n    C --&gt;|Found| R\n    D --&gt;|Selected| R</code></pre>"},{"location":"plugins/tdd-tools/#framework-details","title":"Framework Details","text":"pytest (Python)Jest (JavaScript/TypeScript)Vitest (JavaScript/TypeScript) <p>Detection signals:</p> <ul> <li><code>pyproject.toml</code> with <code>[tool.pytest.ini_options]</code></li> <li><code>setup.cfg</code> with <code>[tool:pytest]</code></li> <li><code>pytest.ini</code> or <code>conftest.py</code> present</li> <li><code>test_*.py</code> or <code>*_test.py</code> file patterns</li> </ul> <p>Test conventions:</p> tests/test_user_registration.py<pre><code>import pytest\n\nclass TestUserRegistration:\n    def test_register_creates_user_with_valid_email(self, db_session):\n        # Arrange\n        email = \"user@example.com\"\n        password = \"secure-password-123\"\n\n        # Act\n        user = register_user(email=email, password=password)\n\n        # Assert\n        assert user.email == email\n        assert user.id is not None\n\n    @pytest.mark.parametrize(\"invalid_email\", [\n        \"\", \"not-an-email\", \"@missing-local\", \"missing-domain@\",\n    ])\n    def test_register_rejects_invalid_email_formats(self, invalid_email):\n        with pytest.raises(InvalidEmailError):\n            register_user(email=invalid_email, password=\"any-password\")\n</code></pre> <p>Coverage command: <code>pytest --cov={package} --cov-report=term-missing --cov-report=json --cov-branch</code></p> <p>Detection signals:</p> <ul> <li><code>jest.config.*</code> exists</li> <li><code>package.json</code> with <code>jest</code> in dependencies/devDependencies</li> <li><code>package.json</code> with <code>\"jest\": {}</code> config section</li> </ul> <p>Test conventions:</p> src/__tests__/user-registration.test.ts<pre><code>describe(\"UserRegistration\", () =&gt; {\n  describe(\"register\", () =&gt; {\n    it(\"should create a user with a valid email\", async () =&gt; {\n      // Arrange\n      const email = \"user@example.com\";\n      const password = \"secure-password-123\";\n\n      // Act\n      const user = await register({ email, password });\n\n      // Assert\n      expect(user.email).toBe(email);\n      expect(user.id).toBeDefined();\n    });\n\n    it.each([\"\", \"not-an-email\", \"@missing-local\", \"missing-domain@\"])(\n      \"should reject invalid email format: %s\",\n      async (invalidEmail) =&gt; {\n        await expect(\n          register({ email: invalidEmail, password: \"any-password\" })\n        ).rejects.toThrow(\"Invalid email\");\n      }\n    );\n  });\n});\n</code></pre> <p>Coverage command: <code>npx jest --coverage --coverageReporters=json --coverageReporters=text</code></p> <p>Detection signals:</p> <ul> <li><code>vitest.config.*</code> exists (takes priority over Jest)</li> <li><code>package.json</code> with <code>vitest</code> in dependencies/devDependencies</li> <li><code>*.test.ts</code> / <code>*.spec.ts</code> with <code>vitest</code> imports</li> </ul> <p>Test conventions:</p> src/__tests__/user-registration.test.ts<pre><code>import { describe, it, expect, vi } from \"vitest\";\n\ndescribe(\"UserRegistration\", () =&gt; {\n  describe(\"register\", () =&gt; {\n    it(\"should create a user with a valid email\", async () =&gt; {\n      // Arrange\n      const email = \"user@example.com\";\n      const password = \"secure-password-123\";\n\n      // Act\n      const user = await register({ email, password });\n\n      // Assert\n      expect(user.email).toBe(email);\n      expect(user.id).toBeDefined();\n    });\n  });\n});\n</code></pre> <p>Key difference from Jest: Explicit imports from <code>vitest</code>, <code>vi.fn()</code> and <code>vi.mock()</code> instead of <code>jest.fn()</code> and <code>jest.mock()</code>.</p> <p>Coverage command: <code>npx vitest run --coverage --coverage.reporter=json --coverage.reporter=text</code></p> <p>Framework Override</p> <p>If auto-detection picks the wrong framework, override it in <code>.claude/agent-alchemy.local.md</code> with <code>tdd.framework: pytest | jest | vitest</code>.</p>"},{"location":"plugins/tdd-tools/#sdd-pipeline-integration","title":"SDD Pipeline Integration","text":"<p>TDD Tools extends the Spec-Driven Development pipeline with two skills that bridge SDD task generation and TDD execution.</p>"},{"location":"plugins/tdd-tools/#task-flow","title":"Task Flow","text":"<pre><code>flowchart LR\n    A[\"/create-tasks&lt;br/&gt;(sdd-tools)\"] --&gt; B[\"/create-tdd-tasks\"]\n    B --&gt; C[\"/execute-tdd-tasks\"]\n    C --&gt; D[\"tdd-executor\"]\n    C --&gt; E[\"task-executor&lt;br/&gt;(sdd-tools)\"]\n\n    style D fill:#7b1fa2,color:#fff\n    style E fill:#455a64,color:#fff</code></pre>"},{"location":"plugins/tdd-tools/#create-tdd-tasks","title":"<code>/create-tdd-tasks</code>","text":"<p>Transforms SDD implementation tasks into test-first TDD task pairs. For each implementation task, it creates a paired test task that blocks it -- enforcing test-first development at the pipeline level.</p> <ul> <li>Preserves existing SDD dependency chains</li> <li>Detects and skips existing TDD pairs (merge mode)</li> <li>Converts acceptance criteria into test descriptions for the paired test task</li> <li>Adds minimal metadata: <code>tdd_mode</code>, <code>tdd_phase</code>, <code>paired_task_id</code></li> </ul>"},{"location":"plugins/tdd-tools/#execute-tdd-tasks","title":"<code>/execute-tdd-tasks</code>","text":"<p>Orchestrates wave-based execution of TDD task pairs. Routes tasks to the appropriate agent:</p> Task Type Agent Source Workflow TDD task (<code>tdd_mode: true</code>) <code>tdd-executor</code> (Opus) Same plugin 6-phase RED-GREEN-REFACTOR Non-TDD task <code>task-executor</code> sdd-tools (cross-plugin) Standard implementation <p>Reports aggregate TDD compliance across all executed task pairs.</p> <p>Soft Dependency on sdd-tools</p> <p><code>execute-tdd-tasks</code> routes non-TDD tasks to the <code>task-executor</code> agent from <code>sdd-tools</code>. Since the TDD pipeline requires <code>/create-tasks</code> (sdd-tools) to generate tasks in the first place, sdd-tools is always installed when this skill runs. Claude Code resolves agent names globally across installed plugins.</p>"},{"location":"plugins/tdd-tools/#configuration","title":"Configuration","text":"<p>All TDD settings are stored in <code>.claude/agent-alchemy.local.md</code> (not committed to version control).</p>"},{"location":"plugins/tdd-tools/#settings-reference","title":"Settings Reference","text":"<pre><code>tdd:\n  framework: auto                    # auto | pytest | jest | vitest\n  coverage-threshold: 80             # Minimum coverage percentage (0-100)\n  strictness: normal                 # strict | normal | relaxed\n  test-review-threshold: 70          # Minimum test quality score (0-100)\n  test-review-on-generate: false     # Run test-reviewer after generate-tests\n</code></pre>"},{"location":"plugins/tdd-tools/#setting-details","title":"Setting Details","text":"Setting Default Used By Description <code>tdd.framework</code> <code>auto</code> All skills Override framework auto-detection. Set to <code>pytest</code>, <code>jest</code>, or <code>vitest</code> to skip the detection chain. <code>tdd.coverage-threshold</code> <code>80</code> <code>analyze-coverage</code>, <code>tdd-cycle</code> Target coverage percentage. Files below this threshold are flagged. <code>tdd.strictness</code> <code>normal</code> <code>tdd-cycle</code>, <code>tdd-executor</code> RED phase enforcement level. See Strictness Levels below. <code>tdd.test-review-threshold</code> <code>70</code> <code>test-reviewer</code> Minimum overall score (0--100) for tests to pass review. <code>tdd.test-review-on-generate</code> <code>false</code> <code>generate-tests</code> Automatically run <code>test-reviewer</code> after test generation completes."},{"location":"plugins/tdd-tools/#strictness-levels","title":"Strictness Levels","text":"<p>The strictness setting controls how the RED phase handles tests that pass before implementation exists.</p> StrictNormal (default)Relaxed <p>RED phase failure is mandatory. If any new test passes before implementation, the workflow aborts immediately.</p> <p>Best for: Greenfield development, enforcing rigorous TDD discipline.</p> <p>RED phase failure is expected. If tests pass, a warning is logged with details. The passing tests are investigated (existing implementation? weak tests?) before continuing.</p> <p>Best for: Standard development, iterating on existing features.</p> <p>RED phase is informational only. Results are recorded but the workflow proceeds regardless of pass/fail outcome.</p> <p>Best for: Retrofitting tests onto existing code, characterization testing.</p>"},{"location":"plugins/tdd-tools/#hooks","title":"Hooks","text":"<p>TDD Tools includes a PreToolUse hook that auto-approves file operations within execution session directories, enabling autonomous TDD task execution without permission prompts. This mirrors the same pattern used by SDD Tools and Core Tools.</p> Hook Event Matcher Timeout <code>auto-approve-session.sh</code> PreToolUse <code>Write\\|Edit\\|Bash</code> 5s <p>What it approves:</p> <ul> <li><code>Write</code>/<code>Edit</code> operations targeting files inside <code>.claude/sessions/</code></li> <li><code>Write</code>/<code>Edit</code> operations targeting <code>$HOME/.claude/tasks/*/execution_pointer.md</code></li> <li><code>Bash</code> commands targeting <code>.claude/sessions/</code></li> </ul> <p>All other operations pass through to the normal permission flow.</p>"},{"location":"plugins/tdd-tools/#reference-materials","title":"Reference Materials","text":"<p>TDD Tools includes extensive reference materials loaded by skills and agents during execution:</p> File Lines Loaded By Content <code>tdd-workflow.md</code> ~325 <code>tdd-cycle</code>, <code>tdd-executor</code> Phase definitions, verification rules, strictness levels <code>test-patterns.md</code> ~776 <code>tdd-cycle</code>, <code>generate-tests</code>, <code>tdd-executor</code> Framework-specific test patterns, behavior-driven guidance <code>framework-templates.md</code> \u2014 <code>generate-tests</code> Auto-detection chain, boilerplate templates <code>coverage-patterns.md</code> \u2014 <code>analyze-coverage</code> Coverage tool integration, JSON parsing, gap analysis"}]}